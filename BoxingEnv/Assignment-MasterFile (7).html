<!DOCTYPE html>

<html lang="en">
<head><meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Assignment-MasterFile</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script><script>
(function() {
  function addWidgetsRenderer() {
    var mimeElement = document.querySelector('script[type="application/vnd.jupyter.widget-view+json"]');
    var scriptElement = document.createElement('script');
    
    var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js';
    
    var widgetState;

    // Fallback for older version:
    try {
      widgetState = mimeElement && JSON.parse(mimeElement.innerHTML);

      if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) {
        
        var widgetRendererSrc = 'https://unpkg.com/@jupyter-js-widgets@*/dist/embed.js';
        
      }
    } catch(e) {}

    scriptElement.src = widgetRendererSrc;
    document.body.appendChild(scriptElement);
  }

  document.addEventListener('DOMContentLoaded', addWidgetsRenderer);
}());
</script>
<style type="text/css">
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
  scrollbar-width: thin;
}

/* tiny scrollbar */

.jp-scrollbar-tiny::-webkit-scrollbar,
.jp-scrollbar-tiny::-webkit-scrollbar-corner {
  background-color: transparent;
  height: 4px;
  width: 4px;
}

.jp-scrollbar-tiny::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal {
  border-left: 0 solid transparent;
  border-right: 0 solid transparent;
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:vertical {
  border-top: 0 solid transparent;
  border-bottom: 0 solid transparent;
}

/*
 * Lumino
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
}

.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.lm-AccordionPanel[data-orientation='horizontal'] > .lm-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-CommandPalette-search {
  flex: 0 0 auto;
}

.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}

.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}

.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}

.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-close-icon {
  border: 1px solid transparent;
  background-color: transparent;
  position: absolute;
  z-index: 1;
  right: 3%;
  top: 0;
  bottom: 0;
  margin: auto;
  padding: 7px 0;
  display: none;
  vertical-align: middle;
  outline: 0;
  cursor: pointer;
}
.lm-close-icon:after {
  content: 'X';
  display: block;
  width: 15px;
  height: 15px;
  text-align: center;
  color: #000;
  font-weight: normal;
  font-size: 12px;
  cursor: pointer;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-DockPanel {
  z-index: 0;
}

.lm-DockPanel-widget {
  z-index: 0;
}

.lm-DockPanel-tabBar {
  z-index: 1;
}

.lm-DockPanel-handle {
  z-index: 2;
}

.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}

.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}

.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}

.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}

.lm-Menu-item {
  display: table-row;
}

.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}

.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}

.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}

.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}

.lm-MenuBar-item {
  box-sizing: border-box;
}

.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}

.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}

.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}

.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}

.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-SplitPanel-child {
  z-index: 0;
}

.lm-SplitPanel-handle {
  z-index: 1;
}

.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
  align-items: flex-end;
}

.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
  align-items: flex-end;
}

.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}

.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}

.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}

.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
  touch-action: none; /* Disable native Drag/Drop */
}

.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}

.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}

.lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
}

.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar-addButton.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}

.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}

.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

.lm-TabBar-tabLabel .lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
  background: inherit;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabPanel-tabBar {
  z-index: 1;
}

.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
}

.jp-Collapse-header {
  padding: 1px 12px;
  background-color: var(--jp-layout-color1);
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  align-items: center;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  text-transform: uppercase;
  user-select: none;
}

.jp-Collapser-icon {
  height: 16px;
}

.jp-Collapse-header-collapsed .jp-Collapser-icon {
  transform: rotate(-90deg);
  margin: auto 0;
}

.jp-Collapser-title {
  line-height: 25px;
}

.jp-Collapse-contents {
  padding: 0 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add-above: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5MikiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik00Ljc1IDQuOTMwNjZINi42MjVWNi44MDU2NkM2LjYyNSA3LjAxMTkxIDYuNzkzNzUgNy4xODA2NiA3IDcuMTgwNjZDNy4yMDYyNSA3LjE4MDY2IDcuMzc1IDcuMDExOTEgNy4zNzUgNi44MDU2NlY0LjkzMDY2SDkuMjVDOS40NTYyNSA0LjkzMDY2IDkuNjI1IDQuNzYxOTEgOS42MjUgNC41NTU2NkM5LjYyNSA0LjM0OTQxIDkuNDU2MjUgNC4xODA2NiA5LjI1IDQuMTgwNjZINy4zNzVWMi4zMDU2NkM3LjM3NSAyLjA5OTQxIDcuMjA2MjUgMS45MzA2NiA3IDEuOTMwNjZDNi43OTM3NSAxLjkzMDY2IDYuNjI1IDIuMDk5NDEgNi42MjUgMi4zMDU2NlY0LjE4MDY2SDQuNzVDNC41NDM3NSA0LjE4MDY2IDQuMzc1IDQuMzQ5NDEgNC4zNzUgNC41NTU2NkM0LjM3NSA0Ljc2MTkxIDQuNTQzNzUgNC45MzA2NiA0Ljc1IDQuOTMwNjZaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC43Ii8+CjwvZz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTExLjUgOS41VjExLjVMMi41IDExLjVWOS41TDExLjUgOS41Wk0xMiA4QzEyLjU1MjMgOCAxMyA4LjQ0NzcyIDEzIDlWMTJDMTMgMTIuNTUyMyAxMi41NTIzIDEzIDEyIDEzTDIgMTNDMS40NDc3MiAxMyAxIDEyLjU1MjMgMSAxMlY5QzEgOC40NDc3MiAxLjQ0NzcxIDggMiA4TDEyIDhaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5MiI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KC0xIDAgMCAxIDEwIDEuNTU1NjYpIi8+CjwvY2xpcFBhdGg+CjwvZGVmcz4KPC9zdmc+Cg==);
  --jp-icon-add-below: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5OCkiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik05LjI1IDEwLjA2OTNMNy4zNzUgMTAuMDY5M0w3LjM3NSA4LjE5NDM0QzcuMzc1IDcuOTg4MDkgNy4yMDYyNSA3LjgxOTM0IDcgNy44MTkzNEM2Ljc5Mzc1IDcuODE5MzQgNi42MjUgNy45ODgwOSA2LjYyNSA4LjE5NDM0TDYuNjI1IDEwLjA2OTNMNC43NSAxMC4wNjkzQzQuNTQzNzUgMTAuMDY5MyA0LjM3NSAxMC4yMzgxIDQuMzc1IDEwLjQ0NDNDNC4zNzUgMTAuNjUwNiA0LjU0Mzc1IDEwLjgxOTMgNC43NSAxMC44MTkzTDYuNjI1IDEwLjgxOTNMNi42MjUgMTIuNjk0M0M2LjYyNSAxMi45MDA2IDYuNzkzNzUgMTMuMDY5MyA3IDEzLjA2OTNDNy4yMDYyNSAxMy4wNjkzIDcuMzc1IDEyLjkwMDYgNy4zNzUgMTIuNjk0M0w3LjM3NSAxMC44MTkzTDkuMjUgMTAuODE5M0M5LjQ1NjI1IDEwLjgxOTMgOS42MjUgMTAuNjUwNiA5LjYyNSAxMC40NDQzQzkuNjI1IDEwLjIzODEgOS40NTYyNSAxMC4wNjkzIDkuMjUgMTAuMDY5M1oiIGZpbGw9IiM2MTYxNjEiIHN0cm9rZT0iIzYxNjE2MSIgc3Ryb2tlLXdpZHRoPSIwLjciLz4KPC9nPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMi41IDUuNUwyLjUgMy41TDExLjUgMy41TDExLjUgNS41TDIuNSA1LjVaTTIgN0MxLjQ0NzcyIDcgMSA2LjU1MjI4IDEgNkwxIDNDMSAyLjQ0NzcyIDEuNDQ3NzIgMiAyIDJMMTIgMkMxMi41NTIzIDIgMTMgMi40NDc3MiAxMyAzTDEzIDZDMTMgNi41NTIyOSAxMi41NTIzIDcgMTIgN0wyIDdaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5OCI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KDEgMS43NDg0NmUtMDcgMS43NDg0NmUtMDcgLTEgNCAxMy40NDQzKSIvPgo8L2NsaXBQYXRoPgo8L2RlZnM+Cjwvc3ZnPgo=);
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bell: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE2IDE2IiB2ZXJzaW9uPSIxLjEiPgogICA8cGF0aCBjbGFzcz0ianAtaWNvbjIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMzMzMzMzIgogICAgICBkPSJtOCAwLjI5Yy0xLjQgMC0yLjcgMC43My0zLjYgMS44LTEuMiAxLjUtMS40IDMuNC0xLjUgNS4yLTAuMTggMi4yLTAuNDQgNC0yLjMgNS4zbDAuMjggMS4zaDVjMC4wMjYgMC42NiAwLjMyIDEuMSAwLjcxIDEuNSAwLjg0IDAuNjEgMiAwLjYxIDIuOCAwIDAuNTItMC40IDAuNi0xIDAuNzEtMS41aDVsMC4yOC0xLjNjLTEuOS0wLjk3LTIuMi0zLjMtMi4zLTUuMy0wLjEzLTEuOC0wLjI2LTMuNy0xLjUtNS4yLTAuODUtMS0yLjItMS44LTMuNi0xLjh6bTAgMS40YzAuODggMCAxLjkgMC41NSAyLjUgMS4zIDAuODggMS4xIDEuMSAyLjcgMS4yIDQuNCAwLjEzIDEuNyAwLjIzIDMuNiAxLjMgNS4yaC0xMGMxLjEtMS42IDEuMi0zLjQgMS4zLTUuMiAwLjEzLTEuNyAwLjMtMy4zIDEuMi00LjQgMC41OS0wLjcyIDEuNi0xLjMgMi41LTEuM3ptLTAuNzQgMTJoMS41Yy0wLjAwMTUgMC4yOCAwLjAxNSAwLjc5LTAuNzQgMC43OS0wLjczIDAuMDAxNi0wLjcyLTAuNTMtMC43NC0wLjc5eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-bug-dot: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiPgogICAgICAgIDxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMTcuMTkgOEgyMFYxMEgxNy45MUMxNy45NiAxMC4zMyAxOCAxMC42NiAxOCAxMVYxMkgyMFYxNEgxOC41SDE4VjE0LjAyNzVDMTUuNzUgMTQuMjc2MiAxNCAxNi4xODM3IDE0IDE4LjVDMTQgMTkuMjA4IDE0LjE2MzUgMTkuODc3OSAxNC40NTQ5IDIwLjQ3MzlDMTMuNzA2MyAyMC44MTE3IDEyLjg3NTcgMjEgMTIgMjFDOS43OCAyMSA3Ljg1IDE5Ljc5IDYuODEgMThINFYxNkg2LjA5QzYuMDQgMTUuNjcgNiAxNS4zNCA2IDE1VjE0SDRWMTJINlYxMUM2IDEwLjY2IDYuMDQgMTAuMzMgNi4wOSAxMEg0VjhINi44MUM3LjI2IDcuMjIgNy44OCA2LjU1IDguNjIgNi4wNEw3IDQuNDFMOC40MSAzTDEwLjU5IDUuMTdDMTEuMDQgNS4wNiAxMS41MSA1IDEyIDVDMTIuNDkgNSAxMi45NiA1LjA2IDEzLjQyIDUuMTdMMTUuNTkgM0wxNyA0LjQxTDE1LjM3IDYuMDRDMTYuMTIgNi41NSAxNi43NCA3LjIyIDE3LjE5IDhaTTEwIDE2SDE0VjE0SDEwVjE2Wk0xMCAxMkgxNFYxMEgxMFYxMloiIGZpbGw9IiM2MTYxNjEiLz4KICAgICAgICA8cGF0aCBkPSJNMjIgMTguNUMyMiAyMC40MzMgMjAuNDMzIDIyIDE4LjUgMjJDMTYuNTY3IDIyIDE1IDIwLjQzMyAxNSAxOC41QzE1IDE2LjU2NyAxNi41NjcgMTUgMTguNSAxNUMyMC40MzMgMTUgMjIgMTYuNTY3IDIyIDE4LjVaIiBmaWxsPSIjNjE2MTYxIi8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yMCA4aC0yLjgxYy0uNDUtLjc4LTEuMDctMS40NS0xLjgyLTEuOTZMMTcgNC40MSAxNS41OSAzbC0yLjE3IDIuMTdDMTIuOTYgNS4wNiAxMi40OSA1IDEyIDVjLS40OSAwLS45Ni4wNi0xLjQxLjE3TDguNDEgMyA3IDQuNDFsMS42MiAxLjYzQzcuODggNi41NSA3LjI2IDcuMjIgNi44MSA4SDR2MmgyLjA5Yy0uMDUuMzMtLjA5LjY2LS4wOSAxdjFINHYyaDJ2MWMwIC4zNC4wNC42Ny4wOSAxSDR2MmgyLjgxYzEuMDQgMS43OSAyLjk3IDMgNS4xOSAzczQuMTUtMS4yMSA1LjE5LTNIMjB2LTJoLTIuMDljLjA1LS4zMy4wOS0uNjYuMDktMXYtMWgydi0yaC0ydi0xYzAtLjM0LS4wNC0uNjctLjA5LTFIMjBWOHptLTYgOGgtNHYtMmg0djJ6bTAtNGgtNHYtMmg0djJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik05IDE2LjE3TDQuODMgMTJsLTEuNDIgMS40MUw5IDE5IDIxIDdsLTEuNDEtMS40MXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBzaGFwZS1yZW5kZXJpbmc9Imdlb21ldHJpY1ByZWNpc2lvbiI+CiAgICA8cGF0aCBkPSJNNi41OSwzLjQxTDIsOEw2LjU5LDEyLjZMOCwxMS4xOEw0LjgyLDhMOCw0LjgyTDYuNTksMy40MU0xMi40MSwzLjQxTDExLDQuODJMMTQuMTgsOEwxMSwxMS4xOEwxMi40MSwxMi42TDE3LDhMMTIuNDEsMy40MU0yMS41OSwxMS41OUwxMy41LDE5LjY4TDkuODMsMTZMOC40MiwxNy40MUwxMy41LDIyLjVMMjMsMTNMMjEuNTksMTEuNTlaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);
  --jp-icon-collapse-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNNiAxM3YyaDh2LTJ6IiAvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1jb25zb2xlLWljb24tYmFja2dyb3VuZC1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtY29uc29sZS1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIj4KICAgIDxwYXRoIGQ9Ik0xMDUgMTI3LjNoNDB2MTIuOGgtNDB6TTUxLjEgNzdMNzQgOTkuOWwtMjMuMyAyMy4zIDEwLjUgMTAuNSAyMy4zLTIzLjNMOTUgOTkuOSA4NC41IDg5LjQgNjEuNiA2Ni41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copyright: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+CiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0xMS44OCw5LjE0YzEuMjgsMC4wNiwxLjYxLDEuMTUsMS42MywxLjY2aDEuNzljLTAuMDgtMS45OC0xLjQ5LTMuMTktMy40NS0zLjE5QzkuNjQsNy42MSw4LDksOCwxMi4xNCBjMCwxLjk0LDAuOTMsNC4yNCwzLjg0LDQuMjRjMi4yMiwwLDMuNDEtMS42NSwzLjQ0LTIuOTVoLTEuNzljLTAuMDMsMC41OS0wLjQ1LDEuMzgtMS42MywxLjQ0QzEwLjU1LDE0LjgzLDEwLDEzLjgxLDEwLDEyLjE0IEMxMCw5LjI1LDExLjI4LDkuMTYsMTEuODgsOS4xNHogTTEyLDJDNi40OCwyLDIsNi40OCwyLDEyczQuNDgsMTAsMTAsMTBzMTAtNC40OCwxMC0xMFMxNy41MiwyLDEyLDJ6IE0xMiwyMGMtNC40MSwwLTgtMy41OS04LTggczMuNTktOCw4LThzOCwzLjU5LDgsOFMxNi40MSwyMCwxMiwyMHoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-delete: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2cHgiIGhlaWdodD0iMTZweCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIiAvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjI2MjYyIiBkPSJNNiAxOWMwIDEuMS45IDIgMiAyaDhjMS4xIDAgMi0uOSAyLTJWN0g2djEyek0xOSA0aC0zLjVsLTEtMWgtNWwtMSAxSDV2MmgxNFY0eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-duplicate: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTIuNzk5OTggMC44NzVIOC44OTU4MkM5LjIwMDYxIDAuODc1IDkuNDQ5OTggMS4xMzkxNCA5LjQ0OTk4IDEuNDYxOThDOS40NDk5OCAxLjc4NDgyIDkuMjAwNjEgMi4wNDg5NiA4Ljg5NTgyIDIuMDQ4OTZIMy4zNTQxNUMzLjA0OTM2IDIuMDQ4OTYgMi43OTk5OCAyLjMxMzEgMi43OTk5OCAyLjYzNTk0VjkuNjc5NjlDMi43OTk5OCAxMC4wMDI1IDIuNTUwNjEgMTAuMjY2NyAyLjI0NTgyIDEwLjI2NjdDMS45NDEwMyAxMC4yNjY3IDEuNjkxNjUgMTAuMDAyNSAxLjY5MTY1IDkuNjc5NjlWMi4wNDg5NkMxLjY5MTY1IDEuNDAzMjggMi4xOTA0IDAuODc1IDIuNzk5OTggMC44NzVaTTUuMzY2NjUgMTEuOVY0LjU1SDExLjA4MzNWMTEuOUg1LjM2NjY1Wk00LjE0MTY1IDQuMTQxNjdDNC4xNDE2NSAzLjY5MDYzIDQuNTA3MjggMy4zMjUgNC45NTgzMiAzLjMyNUgxMS40OTE3QzExLjk0MjcgMy4zMjUgMTIuMzA4MyAzLjY5MDYzIDEyLjMwODMgNC4xNDE2N1YxMi4zMDgzQzEyLjMwODMgMTIuNzU5NCAxMS45NDI3IDEzLjEyNSAxMS40OTE3IDEzLjEyNUg0Ljk1ODMyQzQuNTA3MjggMTMuMTI1IDQuMTQxNjUgMTIuNzU5NCA0LjE0MTY1IDEyLjMwODNWNC4xNDE2N1oiIGZpbGw9IiM2MTYxNjEiLz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNOS40MzU3NCA4LjI2NTA3SDguMzY0MzFWOS4zMzY1QzguMzY0MzEgOS40NTQzNSA4LjI2Nzg4IDkuNTUwNzggOC4xNTAwMiA5LjU1MDc4QzguMDMyMTcgOS41NTA3OCA3LjkzNTc0IDkuNDU0MzUgNy45MzU3NCA5LjMzNjVWOC4yNjUwN0g2Ljg2NDMxQzYuNzQ2NDUgOC4yNjUwNyA2LjY1MDAyIDguMTY4NjQgNi42NTAwMiA4LjA1MDc4QzYuNjUwMDIgNy45MzI5MiA2Ljc0NjQ1IDcuODM2NSA2Ljg2NDMxIDcuODM2NUg3LjkzNTc0VjYuNzY1MDdDNy45MzU3NCA2LjY0NzIxIDguMDMyMTcgNi41NTA3OCA4LjE1MDAyIDYuNTUwNzhDOC4yNjc4OCA2LjU1MDc4IDguMzY0MzEgNi42NDcyMSA4LjM2NDMxIDYuNzY1MDdWNy44MzY1SDkuNDM1NzRDOS41NTM2IDcuODM2NSA5LjY1MDAyIDcuOTMyOTIgOS42NTAwMiA4LjA1MDc4QzkuNjUwMDIgOC4xNjg2NCA5LjU1MzYgOC4yNjUwNyA5LjQzNTc0IDguMjY1MDdaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC41Ii8+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-error: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj48Y2lyY2xlIGN4PSIxMiIgY3k9IjE5IiByPSIyIi8+PHBhdGggZD0iTTEwIDNoNHYxMmgtNHoiLz48L2c+CjxwYXRoIGZpbGw9Im5vbmUiIGQ9Ik0wIDBoMjR2MjRIMHoiLz4KPC9zdmc+Cg==);
  --jp-icon-expand-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNMTEgMTBIOXYzSDZ2MmgzdjNoMnYtM2gzdi0yaC0zeiIgLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-dot: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWRvdCIgZmlsbD0iI0ZGRiI+CiAgICA8Y2lyY2xlIGN4PSIxOCIgY3k9IjE3IiByPSIzIj48L2NpcmNsZT4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-filter: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-folder-favorite: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgwVjB6IiBmaWxsPSJub25lIi8+PHBhdGggY2xhc3M9ImpwLWljb24zIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzYxNjE2MSIgZD0iTTIwIDZoLThsLTItMkg0Yy0xLjEgMC0yIC45LTIgMnYxMmMwIDEuMS45IDIgMiAyaDE2YzEuMSAwIDItLjkgMi0yVjhjMC0xLjEtLjktMi0yLTJ6bS0yLjA2IDExTDE1IDE1LjI4IDEyLjA2IDE3bC43OC0zLjMzLTIuNTktMi4yNCAzLjQxLS4yOUwxNSA4bDEuMzQgMy4xNCAzLjQxLjI5LTIuNTkgMi4yNC43OCAzLjMzeiIvPgo8L3N2Zz4K);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-home: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPjxwYXRoIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xMCAyMHYtNmg0djZoNXYtOGgzTDEyIDMgMiAxMmgzdjh6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-info: url(data:image/svg+xml;base64,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);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaW5zcGVjdG9yLWljb24tY29sb3IganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtanNvbi1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0Y5QTgyNSI+CiAgICA8cGF0aCBkPSJNMjAuMiAxMS44Yy0xLjYgMC0xLjcuNS0xLjcgMSAwIC40LjEuOS4xIDEuMy4xLjUuMS45LjEgMS4zIDAgMS43LTEuNCAyLjMtMy41IDIuM2gtLjl2LTEuOWguNWMxLjEgMCAxLjQgMCAxLjQtLjggMC0uMyAwLS42LS4xLTEgMC0uNC0uMS0uOC0uMS0xLjIgMC0xLjMgMC0xLjggMS4zLTItMS4zLS4yLTEuMy0uNy0xLjMtMiAwLS40LjEtLjguMS0xLjIuMS0uNC4xLS43LjEtMSAwLS44LS40LS43LTEuNC0uOGgtLjVWNC4xaC45YzIuMiAwIDMuNS43IDMuNSAyLjMgMCAuNC0uMS45LS4xIDEuMy0uMS41LS4xLjktLjEgMS4zIDAgLjUuMiAxIDEuNyAxdjEuOHpNMS44IDEwLjFjMS42IDAgMS43LS41IDEuNy0xIDAtLjQtLjEtLjktLjEtMS4zLS4xLS41LS4xLS45LS4xLTEuMyAwLTEuNiAxLjQtMi4zIDMuNS0yLjNoLjl2MS45aC0uNWMtMSAwLTEuNCAwLTEuNC44IDAgLjMgMCAuNi4xIDEgMCAuMi4xLjYuMSAxIDAgMS4zIDAgMS44LTEuMyAyQzYgMTEuMiA2IDExLjcgNiAxM2MwIC40LS4xLjgtLjEgMS4yLS4xLjMtLjEuNy0uMSAxIDAgLjguMy44IDEuNC44aC41djEuOWgtLjljLTIuMSAwLTMuNS0uNi0zLjUtMi4zIDAtLjQuMS0uOS4xLTEuMy4xLS41LjEtLjkuMS0xLjMgMC0uNS0uMi0xLTEuNy0xdi0xLjl6Ii8+CiAgICA8Y2lyY2xlIGN4PSIxMSIgY3k9IjEzLjgiIHI9IjIuMSIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSI4LjIiIHI9IjIuMSIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-julia: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDMyNSAzMDAiPgogIDxnIGNsYXNzPSJqcC1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjY2IzYzMzIj4KICAgIDxwYXRoIGQ9Ik0gMTUwLjg5ODQzOCAyMjUgQyAxNTAuODk4NDM4IDI2Ni40MjE4NzUgMTE3LjMyMDMxMiAzMDAgNzUuODk4NDM4IDMwMCBDIDM0LjQ3NjU2MiAzMDAgMC44OTg0MzggMjY2LjQyMTg3NSAwLjg5ODQzOCAyMjUgQyAwLjg5ODQzOCAxODMuNTc4MTI1IDM0LjQ3NjU2MiAxNTAgNzUuODk4NDM4IDE1MCBDIDExNy4zMjAzMTIgMTUwIDE1MC44OTg0MzggMTgzLjU3ODEyNSAxNTAuODk4NDM4IDIyNSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzM4OTgyNiI+CiAgICA8cGF0aCBkPSJNIDIzNy41IDc1IEMgMjM3LjUgMTE2LjQyMTg3NSAyMDMuOTIxODc1IDE1MCAxNjIuNSAxNTAgQyAxMjEuMDc4MTI1IDE1MCA4Ny41IDExNi40MjE4NzUgODcuNSA3NSBDIDg3LjUgMzMuNTc4MTI1IDEyMS4wNzgxMjUgMCAxNjIuNSAwIEMgMjAzLjkyMTg3NSAwIDIzNy41IDMzLjU3ODEyNSAyMzcuNSA3NSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzk1NThiMiI+CiAgICA8cGF0aCBkPSJNIDMyNC4xMDE1NjIgMjI1IEMgMzI0LjEwMTU2MiAyNjYuNDIxODc1IDI5MC41MjM0MzggMzAwIDI0OS4xMDE1NjIgMzAwIEMgMjA3LjY3OTY4OCAzMDAgMTc0LjEwMTU2MiAyNjYuNDIxODc1IDE3NC4xMDE1NjIgMjI1IEMgMTc0LjEwMTU2MiAxODMuNTc4MTI1IDIwNy42Nzk2ODggMTUwIDI0OS4xMDE1NjIgMTUwIEMgMjkwLjUyMzQzOCAxNTAgMzI0LjEwMTU2MiAxODMuNTc4MTI1IDMyNC4xMDE1NjIgMjI1Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgPGcgY2xhc3M9ImpwLWp1cHl0ZXItaWNvbi1jb2xvciIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyMDAiIHZpZXdCb3g9IjAgMCAxODYwLjggNDc1Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0RTRFNEUiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDQ4MC4xMzY0MDEsIDY0LjI3MTQ5MykiPgogICAgPGcgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMDAwMDAsIDU4Ljg3NTU2NikiPgogICAgICA8ZyB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA4NzYwMywgMC4xNDAyOTQpIj4KICAgICAgICA8cGF0aCBkPSJNLTQyNi45LDE2OS44YzAsNDguNy0zLjcsNjQuNy0xMy42LDc2LjRjLTEwLjgsMTAtMjUsMTUuNS0zOS43LDE1LjVsMy43LDI5IGMyMi44LDAuMyw0NC44LTcuOSw2MS45LTIzLjFjMTcuOC0xOC41LDI0LTQ0LjEsMjQtODMuM1YwSC00Mjd2MTcwLjFMLTQyNi45LDE2OS44TC00MjYuOSwxNjkuOHoiLz4KICAgICAgPC9nPgogICAgPC9nPgogICAgPGcgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMTU1LjA0NTI5NiwgNTYuODM3MTA0KSI+CiAgICAgIDxnIHRyYW5zZm9ybT0idHJhbnNsYXRlKDEuNTYyNDUzLCAxLjc5OTg0MikiPgogICAgICAgIDxwYXRoIGQ9Ik0tMzEyLDE0OGMwLDIxLDAsMzkuNSwxLjcsNTUuNGgtMzEuOGwtMi4xLTMzLjNoLTAuOGMtNi43LDExLjYtMTYuNCwyMS4zLTI4LDI3LjkgYy0xMS42LDYuNi0yNC44LDEwLTM4LjIsOS44Yy0zMS40LDAtNjktMTcuNy02OS04OVYwaDM2LjR2MTEyLjdjMCwzOC43LDExLjYsNjQuNyw0NC42LDY0LjdjMTAuMy0wLjIsMjAuNC0zLjUsMjguOS05LjQgYzguNS01LjksMTUuMS0xNC4zLDE4LjktMjMuOWMyLjItNi4xLDMuMy0xMi41LDMuMy0xOC45VjAuMmgzNi40VjE0OEgtMzEyTC0zMTIsMTQ4eiIvPgogICAgICA8L2c+CiAgICA8L2c+CiAgICA8ZyB0cmFuc2Zvcm09InRyYW5zbGF0ZSgzOTAuMDEzMzIyLCA1My40Nzk2MzgpIj4KICAgICAgPGcgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMS43MDY0NTgsIDAuMjMxNDI1KSI+CiAgICAgICAgPHBhdGggZD0iTS00NzguNiw3MS40YzAtMjYtMC44LTQ3LTEuNy02Ni43aDMyLjdsMS43LDM0LjhoMC44YzcuMS0xMi41LDE3LjUtMjIuOCwzMC4xLTI5LjcgYzEyLjUtNywyNi43LTEwLjMsNDEtOS44YzQ4LjMsMCw4NC43LDQxLjcsODQuNywxMDMuM2MwLDczLjEtNDMuNywxMDkuMi05MSwxMDkuMmMtMTIuMSwwLjUtMjQuMi0yLjItMzUtNy44IGMtMTAuOC01LjYtMTkuOS0xMy45LTI2LjYtMjQuMmgtMC44VjI5MWgtMzZ2LTIyMEwtNDc4LjYsNzEuNEwtNDc4LjYsNzEuNHogTS00NDIuNiwxMjUuNmMwLjEsNS4xLDAuNiwxMC4xLDEuNywxNS4xIGMzLDEyLjMsOS45LDIzLjMsMTkuOCwzMS4xYzkuOSw3LjgsMjIuMSwxMi4xLDM0LjcsMTIuMWMzOC41LDAsNjAuNy0zMS45LDYwLjctNzguNWMwLTQwLjctMjEuMS03NS42LTU5LjUtNzUuNiBjLTEyLjksMC40LTI1LjMsNS4xLTM1LjMsMTMuNGMtOS45LDguMy0xNi45LDE5LjctMTkuNiwzMi40Yy0xLjUsNC45LTIuMywxMC0yLjUsMTUuMVYxMjUuNkwtNDQyLjYsMTI1LjZMLTQ0Mi42LDEyNS42eiIvPgogICAgICA8L2c+CiAgICA8L2c+CiAgICA8ZyB0cmFuc2Zvcm09InRyYW5zbGF0ZSg2MDYuNzQwNzI2LCA1Ni44MzcxMDQpIj4KICAgICAgPGcgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC43NTEyMjYsIDEuOTg5Mjk5KSI+CiAgICAgICAgPHBhdGggZD0iTS00NDAuOCwwbDQzLjcsMTIwLjFjNC41LDEzLjQsOS41LDI5LjQsMTIuOCw0MS43aDAuOGMzLjctMTIuMiw3LjktMjcuNywxMi44LTQyLjQgbDM5LjctMTE5LjJoMzguNUwtMzQ2LjksMTQ1Yy0yNiw2OS43LTQzLjcsMTA1LjQtNjguNiwxMjcuMmMtMTIuNSwxMS43LTI3LjksMjAtNDQuNiwyMy45bC05LjEtMzEuMSBjMTEuNy0zLjksMjIuNS0xMC4xLDMxLjgtMTguMWMxMy4yLTExLjEsMjMuNy0yNS4yLDMwLjYtNDEuMmMxLjUtMi44LDIuNS01LjcsMi45LTguOGMtMC4zLTMuMy0xLjItNi42LTIuNS05LjdMLTQ4MC4yLDAuMSBoMzkuN0wtNDQwLjgsMEwtNDQwLjgsMHoiLz4KICAgICAgPC9nPgogICAgPC9nPgogICAgPGcgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoODIyLjc0ODEwNCwgMC4wMDAwMDApIj4KICAgICAgPGcgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMS40NjQwNTAsIDAuMzc4OTE0KSI+CiAgICAgICAgPHBhdGggZD0iTS00MTMuNywwdjU4LjNoNTJ2MjguMmgtNTJWMTk2YzAsMjUsNywzOS41LDI3LjMsMzkuNWM3LjEsMC4xLDE0LjItMC43LDIxLjEtMi41IGwxLjcsMjcuN2MtMTAuMywzLjctMjEuMyw1LjQtMzIuMiw1Yy03LjMsMC40LTE0LjYtMC43LTIxLjMtMy40Yy02LjgtMi43LTEyLjktNi44LTE3LjktMTIuMWMtMTAuMy0xMC45LTE0LjEtMjktMTQuMS01Mi45IFY4Ni41aC0zMVY1OC4zaDMxVjkuNkwtNDEzLjcsMEwtNDEzLjcsMHoiLz4KICAgICAgPC9nPgogICAgPC9nPgogICAgPGcgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOTc0LjQzMzI4NiwgNTMuNDc5NjM4KSI+CiAgICAgIDxnIHRyYW5zZm9ybT0idHJhbnNsYXRlKDAuOTkwMDM0LCAwLjYxMDMzOSkiPgogICAgICAgIDxwYXRoIGQ9Ik0tNDQ1LjgsMTEzYzAuOCw1MCwzMi4yLDcwLjYsNjguNiw3MC42YzE5LDAuNiwzNy45LTMsNTUuMy0xMC41bDYuMiwyNi40IGMtMjAuOSw4LjktNDMuNSwxMy4xLTY2LjIsMTIuNmMtNjEuNSwwLTk4LjMtNDEuMi05OC4zLTEwMi41Qy00ODAuMiw0OC4yLTQ0NC43LDAtMzg2LjUsMGM2NS4yLDAsODIuNyw1OC4zLDgyLjcsOTUuNyBjLTAuMSw1LjgtMC41LDExLjUtMS4yLDE3LjJoLTE0MC42SC00NDUuOEwtNDQ1LjgsMTEzeiBNLTMzOS4yLDg2LjZjMC40LTIzLjUtOS41LTYwLjEtNTAuNC02MC4xIGMtMzYuOCwwLTUyLjgsMzQuNC01NS43LDYwLjFILTMzOS4yTC0zMzkuMiw4Ni42TC0zMzkuMiw4Ni42eiIvPgogICAgICA8L2c+CiAgICA8L2c+CiAgICA8ZyB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjAxLjk2MTA1OCwgNTMuNDc5NjM4KSI+CiAgICAgIDxnIHRyYW5zZm9ybT0idHJhbnNsYXRlKDEuMTc5NjQwLCAwLjcwNTA2OCkiPgogICAgICAgIDxwYXRoIGQ9Ik0tNDc4LjYsNjhjMC0yMy45LTAuNC00NC41LTEuNy02My40aDMxLjhsMS4yLDM5LjloMS43YzkuMS0yNy4zLDMxLTQ0LjUsNTUuMy00NC41IGMzLjUtMC4xLDcsMC40LDEwLjMsMS4ydjM0LjhjLTQuMS0wLjktOC4yLTEuMy0xMi40LTEuMmMtMjUuNiwwLTQzLjcsMTkuNy00OC43LDQ3LjRjLTEsNS43LTEuNiwxMS41LTEuNywxNy4ydjEwOC4zaC0zNlY2OCBMLTQ3OC42LDY4eiIvPgogICAgICA8L2c+CiAgICA8L2c+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMCIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCBkPSJNMTM1Mi4zLDMyNi4yaDM3VjI4aC0zN1YzMjYuMnogTTE2MDQuOCwzMjYuMmMtMi41LTEzLjktMy40LTMxLjEtMy40LTQ4Ljd2LTc2IGMwLTQwLjctMTUuMS04My4xLTc3LjMtODMuMWMtMjUuNiwwLTUwLDcuMS02Ni44LDE4LjFsOC40LDI0LjRjMTQuMy05LjIsMzQtMTUuMSw1My0xNS4xYzQxLjYsMCw0Ni4yLDMwLjIsNDYuMiw0N3Y0LjIgYy03OC42LTAuNC0xMjIuMywyNi41LTEyMi4zLDc1LjZjMCwyOS40LDIxLDU4LjQsNjIuMiw1OC40YzI5LDAsNTAuOS0xNC4zLDYyLjItMzAuMmgxLjNsMi45LDI1LjZIMTYwNC44eiBNMTU2NS43LDI1Ny43IGMwLDMuOC0wLjgsOC0yLjEsMTEuOGMtNS45LDE3LjItMjIuNywzNC00OS4yLDM0Yy0xOC45LDAtMzQuOS0xMS4zLTM0LjktMzUuM2MwLTM5LjUsNDUuOC00Ni42LDg2LjItNDUuOFYyNTcuN3ogTTE2OTguNSwzMjYuMiBsMS43LTMzLjZoMS4zYzE1LjEsMjYuOSwzOC43LDM4LjIsNjguMSwzOC4yYzQ1LjQsMCw5MS4yLTM2LjEsOTEuMi0xMDguOGMwLjQtNjEuNy0zNS4zLTEwMy43LTg1LjctMTAzLjcgYy0zMi44LDAtNTYuMywxNC43LTY5LjMsMzcuNGgtMC44VjI4aC0zNi42djI0NS43YzAsMTguMS0wLjgsMzguNi0xLjcsNTIuNUgxNjk4LjV6IE0xNzA0LjgsMjA4LjJjMC01LjksMS4zLTEwLjksMi4xLTE1LjEgYzcuNi0yOC4xLDMxLjEtNDUuNCw1Ni4zLTQ1LjRjMzkuNSwwLDYwLjUsMzQuOSw2MC41LDc1LjZjMCw0Ni42LTIzLjEsNzguMS02MS44LDc4LjFjLTI2LjksMC00OC4zLTE3LjYtNTUuNS00My4zIGMtMC44LTQuMi0xLjctOC44LTEuNy0xMy40VjIwOC4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launch: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMzIgMzIiIHdpZHRoPSIzMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yNiwyOEg2YTIuMDAyNywyLjAwMjcsMCwwLDEtMi0yVjZBMi4wMDI3LDIuMDAyNywwLDAsMSw2LDRIMTZWNkg2VjI2SDI2VjE2aDJWMjZBMi4wMDI3LDIuMDAyNywwLDAsMSwyNiwyOFoiLz4KICAgIDxwb2x5Z29uIHBvaW50cz0iMjAgMiAyMCA0IDI2LjU4NiA0IDE4IDEyLjU4NiAxOS40MTQgMTQgMjggNS40MTQgMjggMTIgMzAgMTIgMzAgMiAyMCAyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4K);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-move-down: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMTIuNDcxIDcuNTI4OTlDMTIuNzYzMiA3LjIzNjg0IDEyLjc2MzIgNi43NjMxNiAxMi40NzEgNi40NzEwMVY2LjQ3MTAxQzEyLjE3OSA2LjE3OTA1IDExLjcwNTcgNi4xNzg4NCAxMS40MTM1IDYuNDcwNTRMNy43NSAxMC4xMjc1VjEuNzVDNy43NSAxLjMzNTc5IDcuNDE0MjEgMSA3IDFWMUM2LjU4NTc5IDEgNi4yNSAxLjMzNTc5IDYuMjUgMS43NVYxMC4xMjc1TDIuNTk3MjYgNi40NjgyMkMyLjMwMzM4IDYuMTczODEgMS44MjY0MSA2LjE3MzU5IDEuNTMyMjYgNi40Njc3NFY2LjQ2Nzc0QzEuMjM4MyA2Ljc2MTcgMS4yMzgzIDcuMjM4MyAxLjUzMjI2IDcuNTMyMjZMNi4yOTI4OSAxMi4yOTI5QzYuNjgzNDIgMTIuNjgzNCA3LjMxNjU4IDEyLjY4MzQgNy43MDcxMSAxMi4yOTI5TDEyLjQ3MSA3LjUyODk5WiIgZmlsbD0iIzYxNjE2MSIvPgo8L3N2Zz4K);
  --jp-icon-move-up: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMS41Mjg5OSA2LjQ3MTAxQzEuMjM2ODQgNi43NjMxNiAxLjIzNjg0IDcuMjM2ODQgMS41Mjg5OSA3LjUyODk5VjcuNTI4OTlDMS44MjA5NSA3LjgyMDk1IDIuMjk0MjYgNy44MjExNiAyLjU4NjQ5IDcuNTI5NDZMNi4yNSAzLjg3MjVWMTIuMjVDNi4yNSAxMi42NjQyIDYuNTg1NzkgMTMgNyAxM1YxM0M3LjQxNDIxIDEzIDcuNzUgMTIuNjY0MiA3Ljc1IDEyLjI1VjMuODcyNUwxMS40MDI3IDcuNTMxNzhDMTEuNjk2NiA3LjgyNjE5IDEyLjE3MzYgNy44MjY0MSAxMi40Njc3IDcuNTMyMjZWNy41MzIyNkMxMi43NjE3IDcuMjM4MyAxMi43NjE3IDYuNzYxNyAxMi40Njc3IDYuNDY3NzRMNy43MDcxMSAxLjcwNzExQzcuMzE2NTggMS4zMTY1OCA2LjY4MzQyIDEuMzE2NTggNi4yOTI4OSAxLjcwNzExTDEuNTI4OTkgNi40NzEwMVoiIGZpbGw9IiM2MTYxNjEiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtbm90ZWJvb2staWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-numbering: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-offline-bolt: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-pdf: url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);
  --jp-icon-python: url(data:image/svg+xml;base64,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);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-redo: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-share: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTSAxOCAyIEMgMTYuMzU0OTkgMiAxNSAzLjM1NDk5MDQgMTUgNSBDIDE1IDUuMTkwOTUyOSAxNS4wMjE3OTEgNS4zNzcxMjI0IDE1LjA1NjY0MSA1LjU1ODU5MzggTCA3LjkyMTg3NSA5LjcyMDcwMzEgQyA3LjM5ODUzOTkgOS4yNzc4NTM5IDYuNzMyMDc3MSA5IDYgOSBDIDQuMzU0OTkwNCA5IDMgMTAuMzU0OTkgMyAxMiBDIDMgMTMuNjQ1MDEgNC4zNTQ5OTA0IDE1IDYgMTUgQyA2LjczMjA3NzEgMTUgNy4zOTg1Mzk5IDE0LjcyMjE0NiA3LjkyMTg3NSAxNC4yNzkyOTcgTCAxNS4wNTY2NDEgMTguNDM5NDUzIEMgMTUuMDIxNTU1IDE4LjYyMTUxNCAxNSAxOC44MDgzODYgMTUgMTkgQyAxNSAyMC42NDUwMSAxNi4zNTQ5OSAyMiAxOCAyMiBDIDE5LjY0NTAxIDIyIDIxIDIwLjY0NTAxIDIxIDE5IEMgMjEgMTcuMzU0OTkgMTkuNjQ1MDEgMTYgMTggMTYgQyAxNy4yNjc0OCAxNiAxNi42MDE1OTMgMTYuMjc5MzI4IDE2LjA3ODEyNSAxNi43MjI2NTYgTCA4Ljk0MzM1OTQgMTIuNTU4NTk0IEMgOC45NzgyMDk1IDEyLjM3NzEyMiA5IDEyLjE5MDk1MyA5IDEyIEMgOSAxMS44MDkwNDcgOC45NzgyMDk1IDExLjYyMjg3OCA4Ljk0MzM1OTQgMTEuNDQxNDA2IEwgMTYuMDc4MTI1IDcuMjc5Mjk2OSBDIDE2LjYwMTQ2IDcuNzIyMTQ2MSAxNy4yNjc5MjMgOCAxOCA4IEMgMTkuNjQ1MDEgOCAyMSA2LjY0NTAwOTYgMjEgNSBDIDIxIDMuMzU0OTkwNCAxOS42NDUwMSAyIDE4IDIgeiBNIDE4IDQgQyAxOC41NjQxMjkgNCAxOSA0LjQzNTg3MDYgMTkgNSBDIDE5IDUuNTY0MTI5NCAxOC41NjQxMjkgNiAxOCA2IEMgMTcuNDM1ODcxIDYgMTcgNS41NjQxMjk0IDE3IDUgQyAxNyA0LjQzNTg3MDYgMTcuNDM1ODcxIDQgMTggNCB6IE0gNiAxMSBDIDYuNTY0MTI5NCAxMSA3IDExLjQzNTg3MSA3IDEyIEMgNyAxMi41NjQxMjkgNi41NjQxMjk0IDEzIDYgMTMgQyA1LjQzNTg3MDYgMTMgNSAxMi41NjQxMjkgNSAxMiBDIDUgMTEuNDM1ODcxIDUuNDM1ODcwNiAxMSA2IDExIHogTSAxOCAxOCBDIDE4LjU2NDEyOSAxOCAxOSAxOC40MzU4NzEgMTkgMTkgQyAxOSAxOS41NjQxMjkgMTguNTY0MTI5IDIwIDE4IDIwIEMgMTcuNDM1ODcxIDIwIDE3IDE5LjU2NDEyOSAxNyAxOSBDIDE3IDE4LjQzNTg3MSAxNy40MzU4NzEgMTggMTggMTggeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-table-rows: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-tag: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtdGV4dC1lZGl0b3ItaWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xNSAxNUgzdjJoMTJ2LTJ6bTAtOEgzdjJoMTJWN3pNMyAxM2gxOHYtMkgzdjJ6bTAgOGgxOHYtMkgzdjJ6TTMgM3YyaDE4VjNIM3oiLz4KPC9zdmc+Cg==);
  --jp-icon-toc: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik03LDVIMjFWN0g3VjVNNywxM1YxMUgyMVYxM0g3TTQsNC41QTEuNSwxLjUgMCAwLDEgNS41LDZBMS41LDEuNSAwIDAsMSA0LDcuNUExLjUsMS41IDAgMCwxIDIuNSw2QTEuNSwxLjUgMCAwLDEgNCw0LjVNNCwxMC41QTEuNSwxLjUgMCAwLDEgNS41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMy41QTEuNSwxLjUgMCAwLDEgMi41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMC41TTcsMTlWMTdIMjFWMTlIN000LDE2LjVBMS41LDEuNSAwIDAsMSA1LjUsMThBMS41LDEuNSAwIDAsMSA0LDE5LjVBMS41LDEuNSAwIDAsMSAyLjUsMThBMS41LDEuNSAwIDAsMSA0LDE2LjVaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tree-view: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-user: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE2IDdhNCA0IDAgMTEtOCAwIDQgNCAwIDAxOCAwek0xMiAxNGE3IDcgMCAwMC03IDdoMTRhNyA3IDAgMDAtNy03eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-users: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZlcnNpb249IjEuMSIgdmlld0JveD0iMCAwIDM2IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogPGcgY2xhc3M9ImpwLWljb24zIiB0cmFuc2Zvcm09Im1hdHJpeCgxLjczMjcgMCAwIDEuNzMyNyAtMy42MjgyIC4wOTk1NzcpIiBmaWxsPSIjNjE2MTYxIj4KICA8cGF0aCB0cmFuc2Zvcm09Im1hdHJpeCgxLjUsMCwwLDEuNSwwLC02KSIgZD0ibTEyLjE4NiA3LjUwOThjLTEuMDUzNSAwLTEuOTc1NyAwLjU2NjUtMi40Nzg1IDEuNDEwMiAwLjc1MDYxIDAuMzEyNzcgMS4zOTc0IDAuODI2NDggMS44NzMgMS40NzI3aDMuNDg2M2MwLTEuNTkyLTEuMjg4OS0yLjg4MjgtMi44ODA5LTIuODgyOHoiLz4KICA8cGF0aCBkPSJtMjAuNDY1IDIuMzg5NWEyLjE4ODUgMi4xODg1IDAgMCAxLTIuMTg4NCAyLjE4ODUgMi4xODg1IDIuMTg4NSAwIDAgMS0yLjE4ODUtMi4xODg1IDIuMTg4NSAyLjE4ODUgMCAwIDEgMi4xODg1LTIuMTg4NSAyLjE4ODUgMi4xODg1IDAgMCAxIDIuMTg4NCAyLjE4ODV6Ii8+CiAgPHBhdGggdHJhbnNmb3JtPSJtYXRyaXgoMS41LDAsMCwxLjUsMCwtNikiIGQ9Im0zLjU4OTggOC40MjE5Yy0xLjExMjYgMC0yLjAxMzcgMC45MDExMS0yLjAxMzcgMi4wMTM3aDIuODE0NWMwLjI2Nzk3LTAuMzczMDkgMC41OTA3LTAuNzA0MzUgMC45NTg5OC0wLjk3ODUyLTAuMzQ0MzMtMC42MTY4OC0xLjAwMzEtMS4wMzUyLTEuNzU5OC0xLjAzNTJ6Ii8+CiAgPHBhdGggZD0ibTYuOTE1NCA0LjYyM2ExLjUyOTQgMS41Mjk0IDAgMCAxLTEuNTI5NCAxLjUyOTQgMS41Mjk0IDEuNTI5NCAwIDAgMS0xLjUyOTQtMS41Mjk0IDEuNTI5NCAxLjUyOTQgMCAwIDEgMS41Mjk0LTEuNTI5NCAxLjUyOTQgMS41Mjk0IDAgMCAxIDEuNTI5NCAxLjUyOTR6Ii8+CiAgPHBhdGggZD0ibTYuMTM1IDEzLjUzNWMwLTMuMjM5MiAyLjYyNTktNS44NjUgNS44NjUtNS44NjUgMy4yMzkyIDAgNS44NjUgMi42MjU5IDUuODY1IDUuODY1eiIvPgogIDxjaXJjbGUgY3g9IjEyIiBjeT0iMy43Njg1IiByPSIyLjk2ODUiLz4KIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-word: url(data:image/svg+xml;base64,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);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddAboveIcon {
  background-image: var(--jp-icon-add-above);
}

.jp-AddBelowIcon {
  background-image: var(--jp-icon-add-below);
}

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}

.jp-BellIcon {
  background-image: var(--jp-icon-bell);
}

.jp-BugDotIcon {
  background-image: var(--jp-icon-bug-dot);
}

.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}

.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}

.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}

.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}

.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}

.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}

.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}

.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}

.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}

.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}

.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}

.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}

.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}

.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}

.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}

.jp-CodeCheckIcon {
  background-image: var(--jp-icon-code-check);
}

.jp-CodeIcon {
  background-image: var(--jp-icon-code);
}

.jp-CollapseAllIcon {
  background-image: var(--jp-icon-collapse-all);
}

.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}

.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}

.jp-CopyrightIcon {
  background-image: var(--jp-icon-copyright);
}

.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}

.jp-DeleteIcon {
  background-image: var(--jp-icon-delete);
}

.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}

.jp-DuplicateIcon {
  background-image: var(--jp-icon-duplicate);
}

.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}

.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}

.jp-ErrorIcon {
  background-image: var(--jp-icon-error);
}

.jp-ExpandAllIcon {
  background-image: var(--jp-icon-expand-all);
}

.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}

.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}

.jp-FileIcon {
  background-image: var(--jp-icon-file);
}

.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}

.jp-FilterDotIcon {
  background-image: var(--jp-icon-filter-dot);
}

.jp-FilterIcon {
  background-image: var(--jp-icon-filter);
}

.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}

.jp-FolderFavoriteIcon {
  background-image: var(--jp-icon-folder-favorite);
}

.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}

.jp-HomeIcon {
  background-image: var(--jp-icon-home);
}

.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}

.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}

.jp-InfoIcon {
  background-image: var(--jp-icon-info);
}

.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}

.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}

.jp-JuliaIcon {
  background-image: var(--jp-icon-julia);
}

.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}

.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}

.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}

.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}

.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}

.jp-LaunchIcon {
  background-image: var(--jp-icon-launch);
}

.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}

.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}

.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}

.jp-ListIcon {
  background-image: var(--jp-icon-list);
}

.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}

.jp-MoveDownIcon {
  background-image: var(--jp-icon-move-down);
}

.jp-MoveUpIcon {
  background-image: var(--jp-icon-move-up);
}

.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}

.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}

.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}

.jp-NumberingIcon {
  background-image: var(--jp-icon-numbering);
}

.jp-OfflineBoltIcon {
  background-image: var(--jp-icon-offline-bolt);
}

.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}

.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}

.jp-PdfIcon {
  background-image: var(--jp-icon-pdf);
}

.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}

.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}

.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}

.jp-RedoIcon {
  background-image: var(--jp-icon-redo);
}

.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}

.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}

.jp-RunIcon {
  background-image: var(--jp-icon-run);
}

.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}

.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}

.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}

.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}

.jp-ShareIcon {
  background-image: var(--jp-icon-share);
}

.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}

.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}

.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}

.jp-TableRowsIcon {
  background-image: var(--jp-icon-table-rows);
}

.jp-TagIcon {
  background-image: var(--jp-icon-tag);
}

.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}

.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}

.jp-TocIcon {
  background-image: var(--jp-icon-toc);
}

.jp-TreeViewIcon {
  background-image: var(--jp-icon-tree-view);
}

.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}

.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}

.jp-UserIcon {
  background-image: var(--jp-icon-user);
}

.jp-UsersIcon {
  background-image: var(--jp-icon-users);
}

.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}

.jp-WordIcon {
  background-image: var(--jp-icon-word);
}

.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.lm-TabBar .lm-TabBar-addButton {
  align-items: center;
  display: flex;
  padding: 4px;
  padding-bottom: 5px;
  margin-right: 1px;
  background-color: var(--jp-layout-color2);
}

.lm-TabBar .lm-TabBar-addButton:hover {
  background-color: var(--jp-layout-color1);
}

.lm-DockPanel-tabBar .lm-TabBar-tab {
  width: var(--jp-private-horizontal-tab-width);
}

.lm-DockPanel-tabBar .lm-TabBar-content {
  flex: unset;
}

.lm-DockPanel-tabBar[data-orientation='horizontal'] {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}

/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}

.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}

.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}

.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}

.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}

.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}

.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}

.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}

.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}

/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}

.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}

.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}

.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}

.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}

.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}

.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}

/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

.jp-icon-dot[fill] {
  fill: var(--jp-warn-color0);
}

.jp-jupyter-icon-color[fill] {
  fill: var(--jp-jupyter-icon-color, var(--jp-warn-color0));
}

.jp-notebook-icon-color[fill] {
  fill: var(--jp-notebook-icon-color, var(--jp-warn-color0));
}

.jp-json-icon-color[fill] {
  fill: var(--jp-json-icon-color, var(--jp-warn-color1));
}

.jp-console-icon-color[fill] {
  fill: var(--jp-console-icon-color, white);
}

.jp-console-icon-background-color[fill] {
  fill: var(--jp-console-icon-background-color, var(--jp-brand-color1));
}

.jp-terminal-icon-color[fill] {
  fill: var(--jp-terminal-icon-color, var(--jp-layout-color2));
}

.jp-terminal-icon-background-color[fill] {
  fill: var(
    --jp-terminal-icon-background-color,
    var(--jp-inverse-layout-color2)
  );
}

.jp-text-editor-icon-color[fill] {
  fill: var(--jp-text-editor-icon-color, var(--jp-inverse-layout-color3));
}

.jp-inspector-icon-color[fill] {
  fill: var(--jp-inspector-icon-color, var(--jp-inverse-layout-color3));
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* stylelint-disable selector-max-class, selector-max-compound-selectors */

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}

.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* stylelint-enable selector-max-class, selector-max-compound-selectors */

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) .jp-icon-hoverShow-content {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FormGroup-content fieldset {
  border: none;
  padding: 0;
  min-width: 0;
  width: 100%;
}

/* stylelint-disable selector-max-type */

.jp-FormGroup-content fieldset .jp-inputFieldWrapper input,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper select,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper textarea {
  font-size: var(--jp-content-font-size2);
  border-color: var(--jp-input-border-color);
  border-style: solid;
  border-radius: var(--jp-border-radius);
  border-width: 1px;
  padding: 6px 8px;
  background: none;
  color: var(--jp-ui-font-color0);
  height: inherit;
}

.jp-FormGroup-content fieldset input[type='checkbox'] {
  position: relative;
  top: 2px;
  margin-left: 0;
}

.jp-FormGroup-content button.jp-mod-styled {
  cursor: pointer;
}

.jp-FormGroup-content .checkbox label {
  cursor: pointer;
  font-size: var(--jp-content-font-size1);
}

.jp-FormGroup-content .jp-root > fieldset > legend {
  display: none;
}

.jp-FormGroup-content .jp-root > fieldset > p {
  display: none;
}

/** copy of `input.jp-mod-styled:focus` style */
.jp-FormGroup-content fieldset input:focus,
.jp-FormGroup-content fieldset select:focus {
  -moz-outline-radius: unset;
  outline: var(--jp-border-width) solid var(--md-blue-500);
  outline-offset: -1px;
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-FormGroup-content fieldset input:hover:not(:focus),
.jp-FormGroup-content fieldset select:hover:not(:focus) {
  background-color: var(--jp-border-color2);
}

/* stylelint-enable selector-max-type */

.jp-FormGroup-content .checkbox .field-description {
  /* Disable default description field for checkbox:
   because other widgets do not have description fields,
   we add descriptions to each widget on the field level.
  */
  display: none;
}

.jp-FormGroup-content #root__description {
  display: none;
}

.jp-FormGroup-content .jp-modifiedIndicator {
  width: 5px;
  background-color: var(--jp-brand-color2);
  margin-top: 0;
  margin-left: calc(var(--jp-private-settingeditor-modifier-indent) * -1);
  flex-shrink: 0;
}

.jp-FormGroup-content .jp-modifiedIndicator.jp-errorIndicator {
  background-color: var(--jp-error-color0);
  margin-right: 0.5em;
}

/* RJSF ARRAY style */

.jp-arrayFieldWrapper legend {
  font-size: var(--jp-content-font-size2);
  color: var(--jp-ui-font-color0);
  flex-basis: 100%;
  padding: 4px 0;
  font-weight: var(--jp-content-heading-font-weight);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-arrayFieldWrapper .field-description {
  padding: 4px 0;
  white-space: pre-wrap;
}

.jp-arrayFieldWrapper .array-item {
  width: 100%;
  border: 1px solid var(--jp-border-color2);
  border-radius: 4px;
  margin: 4px;
}

.jp-ArrayOperations {
  display: flex;
  margin-left: 8px;
}

.jp-ArrayOperationsButton {
  margin: 2px;
}

.jp-ArrayOperationsButton .jp-icon3[fill] {
  fill: var(--jp-ui-font-color0);
}

button.jp-ArrayOperationsButton.jp-mod-styled:disabled {
  cursor: not-allowed;
  opacity: 0.5;
}

/* RJSF form validation error */

.jp-FormGroup-content .validationErrors {
  color: var(--jp-error-color0);
}

/* Hide panel level error as duplicated the field level error */
.jp-FormGroup-content .panel.errors {
  display: none;
}

/* RJSF normal content (settings-editor) */

.jp-FormGroup-contentNormal {
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-FormGroup-contentItem {
  margin-left: 7px;
  color: var(--jp-ui-font-color0);
}

.jp-FormGroup-contentNormal .jp-FormGroup-description {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-default {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-fieldLabel {
  font-size: var(--jp-content-font-size1);
  font-weight: normal;
  min-width: 120px;
}

.jp-FormGroup-contentNormal fieldset:not(:first-child) {
  margin-left: 7px;
}

.jp-FormGroup-contentNormal .field-array-of-string .array-item {
  /* Display `jp-ArrayOperations` buttons side-by-side with content except
    for small screens where flex-wrap will place them one below the other.
  */
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-objectFieldWrapper .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

/* RJSF compact content (metadata-form) */

.jp-FormGroup-content.jp-FormGroup-contentCompact {
  width: 100%;
}

.jp-FormGroup-contentCompact .form-group {
  display: flex;
  padding: 0.5em 0.2em 0.5em 0;
}

.jp-FormGroup-contentCompact
  .jp-FormGroup-compactTitle
  .jp-FormGroup-description {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color2);
}

.jp-FormGroup-contentCompact .jp-FormGroup-fieldLabel {
  padding-bottom: 0.3em;
}

.jp-FormGroup-contentCompact .jp-inputFieldWrapper .form-control {
  width: 100%;
  box-sizing: border-box;
}

.jp-FormGroup-contentCompact .jp-arrayFieldWrapper .jp-FormGroup-compactTitle {
  padding-bottom: 7px;
}

.jp-FormGroup-contentCompact
  .jp-objectFieldWrapper
  .jp-objectFieldWrapper
  .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

.jp-FormGroup-contentCompact ul.error-detail {
  margin-block-start: 0.5em;
  margin-block-end: 0.5em;
  padding-inline-start: 1em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-SidePanel {
  display: flex;
  flex-direction: column;
  min-width: var(--jp-sidebar-min-width);
  overflow-y: auto;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size1);
}

.jp-SidePanel-header {
  flex: 0 0 auto;
  display: flex;
  border-bottom: var(--jp-border-width) solid var(--jp-border-color2);
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin: 0;
  padding: 2px;
  text-transform: uppercase;
}

.jp-SidePanel-toolbar {
  flex: 0 0 auto;
}

.jp-SidePanel-content {
  flex: 1 1 auto;
}

.jp-SidePanel-toolbar,
.jp-AccordionPanel-toolbar {
  height: var(--jp-private-toolbar-height);
}

.jp-SidePanel-toolbar.jp-Toolbar-micro {
  display: none;
}

.lm-AccordionPanel .jp-AccordionPanel-title {
  box-sizing: border-box;
  line-height: 25px;
  margin: 0;
  display: flex;
  align-items: center;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  font-size: var(--jp-ui-font-size0);
}

.jp-AccordionPanel-title {
  cursor: pointer;
  user-select: none;
  -moz-user-select: none;
  -webkit-user-select: none;
  text-transform: uppercase;
}

.lm-AccordionPanel[data-orientation='horizontal'] > .jp-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleLabel {
  user-select: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  overflow: hidden;
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleCollapser {
  transform: rotate(-90deg);
  margin: auto 0;
  height: 16px;
}

.jp-AccordionPanel-title.lm-mod-expanded .lm-AccordionPanel-titleCollapser {
  transform: rotate(0deg);
}

.lm-AccordionPanel .jp-AccordionPanel-toolbar {
  background: none;
  box-shadow: none;
  border: none;
  margin-left: auto;
}

.lm-AccordionPanel .lm-SplitPanel-handle:hover {
  background: var(--jp-layout-color3);
}

.jp-text-truncated {
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent::before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent::after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }

  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }

  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input[type='checkbox'].jp-mod-styled {
  appearance: checkbox;
  -webkit-appearance: checkbox;
  -moz-appearance: checkbox;
  height: auto;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper:not(.multiple) {
  height: 28px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

select.jp-mod-styled:not([multiple]) {
  height: 32px;
}

select.jp-mod-styled[multiple] {
  max-height: 200px;
  overflow-y: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-switch {
  display: flex;
  align-items: center;
  padding-left: 4px;
  padding-right: 4px;
  font-size: var(--jp-ui-font-size1);
  background-color: transparent;
  color: var(--jp-ui-font-color1);
  border: none;
  height: 20px;
}

.jp-switch:hover {
  background-color: var(--jp-layout-color2);
}

.jp-switch-label {
  margin-right: 5px;
  font-family: var(--jp-ui-font-family);
}

.jp-switch-track {
  cursor: pointer;
  background-color: var(--jp-switch-color, var(--jp-border-color1));
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 34px;
  height: 16px;
  width: 35px;
  position: relative;
}

.jp-switch-track::before {
  content: '';
  position: absolute;
  height: 10px;
  width: 10px;
  margin: 3px;
  left: 0;
  background-color: var(--jp-ui-inverse-font-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 50%;
}

.jp-switch[aria-checked='true'] .jp-switch-track {
  background-color: var(--jp-switch-true-position-color, var(--jp-warn-color0));
}

.jp-switch[aria-checked='true'] .jp-switch-track::before {
  /* track width (35) - margins (3 + 3) - thumb width (10) */
  left: 19px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 8;
  overflow-x: hidden;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0;
  margin: 0;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0 6px;
  margin: 0;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent > span {
  padding: 0;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar.jp-Toolbar-micro {
  padding: 0;
  min-height: 0;
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar {
  border: none;
  box-shadow: none;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-WindowedPanel-outer {
  position: relative;
  overflow-y: auto;
}

.jp-WindowedPanel-inner {
  position: relative;
}

.jp-WindowedPanel-window {
  position: absolute;
  left: 0;
  right: 0;
  overflow: visible;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

body {
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
}

/* Disable native link decoration styles everywhere outside of dialog boxes */
a {
  text-decoration: unset;
  color: unset;
}

a:hover {
  text-decoration: unset;
  color: unset;
}

/* Accessibility for links inside dialog box text */
.jp-Dialog-content a {
  text-decoration: revert;
  color: var(--jp-content-link-color);
}

.jp-Dialog-content a:hover {
  text-decoration: revert;
}

/* Styles for ui-components */
.jp-Button {
  color: var(--jp-ui-font-color2);
  border-radius: var(--jp-border-radius);
  padding: 0 12px;
  font-size: var(--jp-ui-font-size1);

  /* Copy from blueprint 3 */
  display: inline-flex;
  flex-direction: row;
  border: none;
  cursor: pointer;
  align-items: center;
  justify-content: center;
  text-align: left;
  vertical-align: middle;
  min-height: 30px;
  min-width: 30px;
}

.jp-Button:disabled {
  cursor: not-allowed;
}

.jp-Button:empty {
  padding: 0 !important;
}

.jp-Button.jp-mod-small {
  min-height: 24px;
  min-width: 24px;
  font-size: 12px;
  padding: 0 7px;
}

/* Use our own theme for hover styles */
.jp-Button.jp-mod-minimal:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Button.jp-mod-minimal {
  background: none;
}

.jp-InputGroup {
  display: block;
  position: relative;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border: none;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
  padding-bottom: 0;
  padding-top: 0;
  padding-left: 10px;
  padding-right: 28px;
  position: relative;
  width: 100%;
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  font-size: 14px;
  font-weight: 400;
  height: 30px;
  line-height: 30px;
  outline: none;
  vertical-align: middle;
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input:disabled {
  cursor: not-allowed;
  resize: block;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input:disabled ~ span {
  cursor: not-allowed;
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color2);
}

.jp-InputGroupAction {
  position: absolute;
  bottom: 1px;
  right: 0;
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
  cursor: not-allowed;
  resize: block;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled ~ span {
  cursor: not-allowed;
}

/* Use our own theme for hover and option styles */
/* stylelint-disable-next-line selector-max-type */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}

select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-StatusBar-Widget {
  display: flex;
  align-items: center;
  background: var(--jp-layout-color2);
  min-height: var(--jp-statusbar-height);
  justify-content: space-between;
  padding: 0 10px;
}

.jp-StatusBar-Left {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-StatusBar-Middle {
  display: flex;
  align-items: center;
}

.jp-StatusBar-Right {
  display: flex;
  align-items: center;
  flex-direction: row-reverse;
}

.jp-StatusBar-Item {
  max-height: var(--jp-statusbar-height);
  margin: 0 2px;
  height: var(--jp-statusbar-height);
  white-space: nowrap;
  text-overflow: ellipsis;
  color: var(--jp-ui-font-color1);
  padding: 0 6px;
}

.jp-mod-highlighted:hover {
  background-color: var(--jp-layout-color3);
}

.jp-mod-clicked {
  background-color: var(--jp-brand-color1);
}

.jp-mod-clicked:hover {
  background-color: var(--jp-brand-color0);
}

.jp-mod-clicked .jp-StatusBar-TextItem {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-StatusBar-HoverItem {
  box-shadow: '0px 4px 4px rgba(0, 0, 0, 0.25)';
}

.jp-StatusBar-TextItem {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  line-height: 24px;
  color: var(--jp-ui-font-color1);
}

.jp-StatusBar-GroupItem {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-Statusbar-ProgressCircle svg {
  display: block;
  margin: 0 auto;
  width: 16px;
  height: 24px;
  align-self: normal;
}

.jp-Statusbar-ProgressCircle path {
  fill: var(--jp-inverse-layout-color3);
}

.jp-Statusbar-ProgressBar-progress-bar {
  height: 10px;
  width: 100px;
  border: solid 0.25px var(--jp-brand-color2);
  border-radius: 3px;
  overflow: hidden;
  align-self: center;
}

.jp-Statusbar-ProgressBar-progress-bar > div {
  background-color: var(--jp-brand-color2);
  background-image: linear-gradient(
    -45deg,
    rgba(255, 255, 255, 0.2) 25%,
    transparent 25%,
    transparent 50%,
    rgba(255, 255, 255, 0.2) 50%,
    rgba(255, 255, 255, 0.2) 75%,
    transparent 75%,
    transparent
  );
  background-size: 40px 40px;
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 14px;
  color: #fff;
  text-align: center;
  animation: jp-Statusbar-ExecutionTime-progress-bar 2s linear infinite;
}

.jp-Statusbar-ProgressBar-progress-bar p {
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
  font-size: var(--jp-ui-font-size1);
  line-height: 10px;
  width: 100px;
}

@keyframes jp-Statusbar-ExecutionTime-progress-bar {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 40px 40px;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Modal variant
|----------------------------------------------------------------------------*/

.jp-ModalCommandPalette {
  position: absolute;
  z-index: 10000;
  top: 38px;
  left: 30%;
  margin: 0;
  padding: 4px;
  width: 40%;
  box-shadow: var(--jp-elevation-z4);
  border-radius: 4px;
  background: var(--jp-layout-color0);
}

.jp-ModalCommandPalette .lm-CommandPalette {
  max-height: 40vh;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon::after {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item {
  margin-left: 4px;
  margin-right: 4px;
}

.jp-ModalCommandPalette
  .lm-CommandPalette
  .lm-CommandPalette-item.lm-mod-disabled {
  display: none;
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-SearchIconGroup {
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  padding: 5px 5px 1px;
}

.jp-SearchIconGroup svg {
  height: 20px;
  width: 20px;
}

.jp-SearchIconGroup .jp-icon3[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color2);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item.lm-mod-active {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-inverse-font-color0);
}

.lm-CommandPalette-item.lm-mod-active .jp-icon-selectable[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.6;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty::after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0;
  left: 0;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px 24px 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
  resize: both;
}

.jp-Dialog-content.jp-Dialog-content-small {
  max-width: 500px;
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus {
  outline: 1px solid var(--jp-accept-color-normal, var(--jp-brand-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus {
  outline: 1px solid var(--jp-warn-color-normal, var(--jp-error-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline: 1px solid var(--jp-reject-color-normal, var(--md-grey-600));
}

button.jp-Dialog-close-button {
  padding: 0;
  height: 100%;
  min-width: unset;
  min-height: unset;
}

.jp-Dialog-header {
  display: flex;
  justify-content: space-between;
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  align-items: center;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-checkbox {
  padding-right: 5px;
}

.jp-Dialog-checkbox > input:focus-visible {
  outline: 1px solid var(--jp-input-active-border-color);
  outline-offset: 1px;
}

.jp-Dialog-spacer {
  flex: 1 1 auto;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Input-Boolean-Dialog {
  flex-direction: row-reverse;
  align-items: end;
  width: 100%;
}

.jp-Input-Boolean-Dialog > label {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error {
  padding: 6px;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error > pre {
  width: auto;
  padding: 10px;
  background: var(--jp-error-color3);
  border: var(--jp-border-width) solid var(--jp-error-color1);
  border-radius: var(--jp-border-radius);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  white-space: pre-wrap;
  word-wrap: break-word;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;
  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;
  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #a0f;
  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;
  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;
  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;
  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;
  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;
  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;
  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;
  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;
  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;
  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ff0;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;
  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;
  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;
  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;
  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;
  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;
  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

:root {
  /* This is the padding value to fill the gaps between lines containing spans with background color. */
  --jp-private-code-span-padding: calc(
    (var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2
  );
}

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0;
  padding: 0;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}

.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}

.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}

.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}

.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}

.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}

.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}

.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}

.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}

.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}

.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}

.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}

.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}

.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}

.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}

.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}

.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);

  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

/* stylelint-disable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0;
}

/* stylelint-enable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  table-layout: fixed;
  margin-left: auto;
  margin-bottom: 1em;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}

[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}

.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}

.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}

.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}

.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}

.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}

.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}

.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}

.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: var(--jp-ui-font-size0);
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-cursor-backdrop {
  position: fixed;
  width: 200px;
  height: 200px;
  margin-top: -100px;
  margin-left: -100px;
  will-change: transform;
  z-index: 100;
}

.lm-mod-drag-image {
  will-change: transform;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-lineFormSearch {
  padding: 4px 12px;
  background-color: var(--jp-layout-color2);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
  font-size: var(--jp-ui-font-size1);
}

.jp-lineFormCaption {
  font-size: var(--jp-ui-font-size0);
  line-height: var(--jp-ui-font-size1);
  margin-top: 4px;
  color: var(--jp-ui-font-color0);
}

.jp-baseLineForm {
  border: none;
  border-radius: 0;
  position: absolute;
  background-size: 16px;
  background-repeat: no-repeat;
  background-position: center;
  outline: none;
}

.jp-lineFormButtonContainer {
  top: 4px;
  right: 8px;
  height: 24px;
  padding: 0 12px;
  width: 12px;
}

.jp-lineFormButtonIcon {
  top: 0;
  right: 0;
  background-color: var(--jp-brand-color1);
  height: 100%;
  width: 100%;
  box-sizing: border-box;
  padding: 4px 6px;
}

.jp-lineFormButton {
  top: 0;
  right: 0;
  background-color: transparent;
  height: 100%;
  width: 100%;
  box-sizing: border-box;
}

.jp-lineFormWrapper {
  overflow: hidden;
  padding: 0 8px;
  border: 1px solid var(--jp-border-color0);
  background-color: var(--jp-input-active-background);
  height: 22px;
}

.jp-lineFormWrapperFocusWithin {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-lineFormInput {
  background: transparent;
  width: 200px;
  height: 100%;
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  line-height: 28px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/
.jp-DocumentSearch-input {
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  font-size: var(--jp-ui-font-size1);
  background-color: var(--jp-layout-color0);
  font-family: var(--jp-ui-font-family);
  padding: 2px 1px;
  resize: none;
}

.jp-DocumentSearch-overlay {
  position: absolute;
  background-color: var(--jp-toolbar-background);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  border-left: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  top: 0;
  right: 0;
  z-index: 7;
  min-width: 405px;
  padding: 2px;
  font-size: var(--jp-ui-font-size1);

  --jp-private-document-search-button-height: 20px;
}

.jp-DocumentSearch-overlay button {
  background-color: var(--jp-toolbar-background);
  outline: 0;
}

.jp-DocumentSearch-overlay button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-overlay button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-overlay-row {
  display: flex;
  align-items: center;
  margin-bottom: 2px;
}

.jp-DocumentSearch-button-content {
  display: inline-block;
  cursor: pointer;
  box-sizing: border-box;
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-button-content svg {
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-input-wrapper {
  border: var(--jp-border-width) solid var(--jp-border-color0);
  display: flex;
  background-color: var(--jp-layout-color0);
  margin: 2px;
}

.jp-DocumentSearch-input-wrapper:focus-within {
  border-color: var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper {
  all: initial;
  overflow: hidden;
  display: inline-block;
  border: none;
  box-sizing: border-box;
}

.jp-DocumentSearch-toggle-wrapper {
  width: 14px;
  height: 14px;
}

.jp-DocumentSearch-button-wrapper {
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
}

.jp-DocumentSearch-toggle-wrapper:focus,
.jp-DocumentSearch-button-wrapper:focus {
  outline: var(--jp-border-width) solid
    var(--jp-cell-editor-active-border-color);
  outline-offset: -1px;
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper,
.jp-DocumentSearch-button-content:focus {
  outline: none;
}

.jp-DocumentSearch-toggle-placeholder {
  width: 5px;
}

.jp-DocumentSearch-input-button::before {
  display: block;
  padding-top: 100%;
}

.jp-DocumentSearch-input-button-off {
  opacity: var(--jp-search-toggle-off-opacity);
}

.jp-DocumentSearch-input-button-off:hover {
  opacity: var(--jp-search-toggle-hover-opacity);
}

.jp-DocumentSearch-input-button-on {
  opacity: var(--jp-search-toggle-on-opacity);
}

.jp-DocumentSearch-index-counter {
  padding-left: 10px;
  padding-right: 10px;
  user-select: none;
  min-width: 35px;
  display: inline-block;
}

.jp-DocumentSearch-up-down-wrapper {
  display: inline-block;
  padding-right: 2px;
  margin-left: auto;
  white-space: nowrap;
}

.jp-DocumentSearch-spacer {
  margin-left: auto;
}

.jp-DocumentSearch-up-down-wrapper button {
  outline: 0;
  border: none;
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
  vertical-align: middle;
  margin: 1px 5px 2px;
}

.jp-DocumentSearch-up-down-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-up-down-button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-filter-button {
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-filter-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled:hover {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-search-options {
  padding: 0 8px;
  margin-left: 3px;
  width: 100%;
  display: grid;
  justify-content: start;
  grid-template-columns: 1fr 1fr;
  align-items: center;
  justify-items: stretch;
}

.jp-DocumentSearch-search-filter-disabled {
  color: var(--jp-ui-font-color2);
}

.jp-DocumentSearch-search-filter {
  display: flex;
  align-items: center;
  user-select: none;
}

.jp-DocumentSearch-regex-error {
  color: var(--jp-error-color0);
}

.jp-DocumentSearch-replace-button-wrapper {
  overflow: hidden;
  display: inline-block;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color0);
  margin: auto 2px;
  padding: 1px 4px;
  height: calc(var(--jp-private-document-search-button-height) + 2px);
}

.jp-DocumentSearch-replace-button-wrapper:focus {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-replace-button {
  display: inline-block;
  text-align: center;
  cursor: pointer;
  box-sizing: border-box;
  color: var(--jp-ui-font-color1);

  /* height - 2 * (padding of wrapper) */
  line-height: calc(var(--jp-private-document-search-button-height) - 2px);
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-replace-button:focus {
  outline: none;
}

.jp-DocumentSearch-replace-wrapper-class {
  margin-left: 14px;
  display: flex;
}

.jp-DocumentSearch-replace-toggle {
  border: none;
  background-color: var(--jp-toolbar-background);
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-replace-toggle:hover {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.cm-editor {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;

  /* Changed to auto to autogrow */
}

.cm-editor pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .cm-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

.jp-CodeMirrorEditor {
  cursor: text;
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.cm-editor.jp-mod-readOnly .cm-cursor {
  display: none;
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.cm-searching,
.cm-searching span {
  /* `.cm-searching span`: we need to override syntax highlighting */
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.cm-searching::selection,
.cm-searching span::selection {
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.jp-current-match > .cm-searching,
.jp-current-match > .cm-searching span,
.cm-searching > .jp-current-match,
.cm-searching > .jp-current-match span {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.jp-current-match > .cm-searching::selection,
.cm-searching > .jp-current-match::selection,
.jp-current-match > .cm-searching span::selection {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.cm-trailingspace {
  background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAYAAAB4ka1VAAAAsElEQVQIHQGlAFr/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7+r3zKmT0/+pk9P/7+r3zAAAAAAAAAAABAAAAAAAAAAA6OPzM+/q9wAAAAAA6OPzMwAAAAAAAAAAAgAAAAAAAAAAGR8NiRQaCgAZIA0AGR8NiQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQyoYJ/SY80UAAAAASUVORK5CYII=);
  background-position: center left;
  background-repeat: repeat-x;
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/* Styles for shared cursors (remote cursor locations and selected ranges) */
.jp-CodeMirrorEditor .cm-ySelectionCaret {
  position: relative;
  border-left: 1px solid black;
  margin-left: -1px;
  margin-right: -1px;
  box-sizing: border-box;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret > .cm-ySelectionInfo {
  white-space: nowrap;
  position: absolute;
  top: -1.15em;
  padding-bottom: 0.05em;
  left: -1px;
  font-size: 0.95em;
  font-family: var(--jp-ui-font-family);
  font-weight: bold;
  line-height: normal;
  user-select: none;
  color: white;
  padding-left: 2px;
  padding-right: 2px;
  z-index: 101;
  transition: opacity 0.3s ease-in-out;
}

.jp-CodeMirrorEditor .cm-ySelectionInfo {
  transition-delay: 0.7s;
  opacity: 0;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret:hover > .cm-ySelectionInfo {
  opacity: 1;
  transition-delay: 0s;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser .jp-SidePanel-content {
  display: flex;
  flex-direction: column;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  flex-wrap: wrap;
  row-gap: 12px;
  border-bottom: none;
  height: auto;
  margin: 8px 12px 0;
  box-shadow: none;
  padding: 0;
  justify-content: flex-start;
}

.jp-FileBrowser-Panel {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 8px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0 2px;
  padding: 0 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  padding-left: 0;
  padding-right: 2px;
  align-items: center;
  height: unset;
}

.jp-FileBrowser-toolbar > .jp-Toolbar-item .jp-ToolbarButtonComponent {
  width: 40px;
}

/*-----------------------------------------------------------------------------
| Other styles
|----------------------------------------------------------------------------*/

.jp-FileDialog.jp-mod-conflict input {
  color: var(--jp-error-color1);
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

.jp-LastModified-hidden {
  display: none;
}

.jp-FileSize-hidden {
  display: none;
}

.jp-FileBrowser .lm-AccordionPanel > h3:first-child {
  display: none;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  align-items: center;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-headerItem.jp-id-filesize {
  flex: 0 0 75px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-id-narrow {
  display: none;
  flex: 0 0 5px;
  padding: 4px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
  color: var(--jp-border-color2);
}

.jp-DirListing-narrow .jp-id-narrow {
  display: block;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-content mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.jp-DirListing-content .jp-DirListing-item.jp-mod-selected mark {
  color: var(--jp-ui-inverse-font-color0);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  align-items: center;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-checkboxWrapper {
  /* Increases hit area of checkbox. */
  padding: 4px;
}

.jp-DirListing-header
  .jp-DirListing-checkboxWrapper
  + .jp-DirListing-headerItem {
  padding-left: 4px;
}

.jp-DirListing-content .jp-DirListing-checkboxWrapper {
  position: relative;
  left: -4px;
  margin: -4px 0 -4px -8px;
}

.jp-DirListing-checkboxWrapper.jp-mod-visible {
  visibility: visible;
}

/* For devices that support hovering, hide checkboxes until hovered, selected...
*/
@media (hover: hover) {
  .jp-DirListing-checkboxWrapper {
    visibility: hidden;
  }

  .jp-DirListing-item:hover .jp-DirListing-checkboxWrapper,
  .jp-DirListing-item.jp-mod-selected .jp-DirListing-checkboxWrapper {
    visibility: visible;
  }
}

.jp-DirListing-item[data-is-dot] {
  opacity: 75%;
}

.jp-DirListing-item.jp-mod-selected {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemText:focus {
  outline-width: 2px;
  outline-color: var(--jp-inverse-layout-color1);
  outline-style: solid;
  outline-offset: 1px;
}

.jp-DirListing-item.jp-mod-selected .jp-DirListing-itemText:focus {
  outline-color: var(--jp-layout-color1);
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-itemFileSize {
  flex: 0 0 90px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon::before {
  color: var(--jp-success-color1);
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.jp-mod-running.jp-mod-selected
  .jp-DirListing-itemIcon::before {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-OutputPrompt {
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-prompt {
  display: table-cell;
  vertical-align: top;
}

.jp-OutputArea-output {
  display: table-cell;
  width: 100%;
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea .jp-RenderedText {
  padding-left: 1ch;
}

/**
 * Prompt overlay.
 */

.jp-OutputArea-promptOverlay {
  position: absolute;
  top: 0;
  width: var(--jp-cell-prompt-width);
  height: 100%;
  opacity: 0.5;
}

.jp-OutputArea-promptOverlay:hover {
  background: var(--jp-layout-color2);
  box-shadow: inset 0 0 1px var(--jp-inverse-layout-color0);
  cursor: zoom-out;
}

.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay:hover {
  cursor: zoom-in;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0;
  padding: 0;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

.jp-TrimmedOutputs pre {
  background: var(--jp-layout-color3);
  font-size: calc(var(--jp-code-font-size) * 1.4);
  text-align: center;
  text-transform: uppercase;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/* Hide empty lines in the output area, for instance due to cleared widgets */
.jp-OutputArea-prompt:empty {
  padding: 0;
  border: 0;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0;
  width: 100%;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
  border-top: var(--jp-border-width) solid transparent;
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;

  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;

  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0 0.25em;
  margin: 0 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input::placeholder {
  opacity: 0;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

.jp-Stdin-input:focus::placeholder {
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

@media print {
  .jp-OutputArea-child {
    break-inside: avoid-page;
  }
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-OutputPrompt {
    display: table-row;
    text-align: left;
  }

  .jp-OutputArea-child .jp-OutputArea-output {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }
}

/* Trimmed outputs warning */
.jp-TrimmedOutputs > a {
  margin: 10px;
  text-decoration: none;
  cursor: pointer;
}

.jp-TrimmedOutputs > a:hover {
  text-decoration: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Table of Contents
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toc-active-width: 4px;
}

.jp-TableOfContents {
  display: flex;
  flex-direction: column;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  height: 100%;
}

.jp-TableOfContents-placeholder {
  text-align: center;
}

.jp-TableOfContents-placeholderContent {
  color: var(--jp-content-font-color2);
  padding: 8px;
}

.jp-TableOfContents-placeholderContent > h3 {
  margin-bottom: var(--jp-content-heading-margin-bottom);
}

.jp-TableOfContents .jp-SidePanel-content {
  overflow-y: auto;
}

.jp-TableOfContents-tree {
  margin: 4px;
}

.jp-TableOfContents ol {
  list-style-type: none;
}

/* stylelint-disable-next-line selector-max-type */
.jp-TableOfContents li > ol {
  /* Align left border with triangle icon center */
  padding-left: 11px;
}

.jp-TableOfContents-content {
  /* left margin for the active heading indicator */
  margin: 0 0 0 var(--jp-private-toc-active-width);
  padding: 0;
  background-color: var(--jp-layout-color1);
}

.jp-tocItem {
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-tocItem-heading {
  display: flex;
  cursor: pointer;
}

.jp-tocItem-heading:hover {
  background-color: var(--jp-layout-color2);
}

.jp-tocItem-content {
  display: block;
  padding: 4px 0;
  white-space: nowrap;
  text-overflow: ellipsis;
  overflow-x: hidden;
}

.jp-tocItem-collapser {
  height: 20px;
  margin: 2px 2px 0;
  padding: 0;
  background: none;
  border: none;
  cursor: pointer;
}

.jp-tocItem-collapser:hover {
  background-color: var(--jp-layout-color3);
}

/* Active heading indicator */

.jp-tocItem-heading::before {
  content: ' ';
  background: transparent;
  width: var(--jp-private-toc-active-width);
  height: 24px;
  position: absolute;
  left: 0;
  border-radius: var(--jp-border-radius);
}

.jp-tocItem-heading.jp-tocItem-active::before {
  background-color: var(--jp-brand-color1);
}

.jp-tocItem-heading:hover.jp-tocItem-active::before {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;

  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0;
  bottom: 0;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Hiding collapsers in print mode.

Note: input and output wrappers have "display: block" propery in print mode.
*/

@media print {
  .jp-Collapser {
    display: none;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0;
  width: 100%;
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-InputArea-editor {
  display: table-cell;
  overflow: hidden;
  vertical-align: top;

  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  display: table-cell;
  vertical-align: top;
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-InputArea-editor {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }

  .jp-InputPrompt {
    display: table-row;
    text-align: left;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: table;
  table-layout: fixed;
  width: 100%;
}

.jp-Placeholder-prompt {
  display: table-cell;
  box-sizing: border-box;
}

.jp-Placeholder-content {
  display: table-cell;
  padding: 4px 6px;
  border: 1px solid transparent;
  border-radius: 0;
  background: none;
  box-sizing: border-box;
  cursor: pointer;
}

.jp-Placeholder-contentContainer {
  display: flex;
}

.jp-Placeholder-content:hover,
.jp-InputPlaceholder > .jp-Placeholder-content:hover {
  border-color: var(--jp-layout-color3);
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

.jp-PlaceholderText {
  white-space: nowrap;
  overflow-x: hidden;
  color: var(--jp-inverse-layout-color3);
  font-family: var(--jp-code-font-family);
}

.jp-InputPlaceholder > .jp-Placeholder-content {
  border-color: var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0;
  margin: 0;

  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 24em;
  margin-left: var(--jp-private-cell-scrolling-output-offset);
  resize: vertical;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea[style*='height'] {
  max-height: unset;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea::after {
  content: ' ';
  box-shadow: inset 0 0 6px 2px rgb(0 0 0 / 30%);
  width: 100%;
  height: 100%;
  position: sticky;
  bottom: 0;
  top: 0;
  margin-top: -50%;
  float: left;
  display: block;
  pointer-events: none;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-child {
  padding-top: 6px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  width: calc(
    var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset)
  );
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay {
  left: calc(-1 * var(--jp-private-cell-scrolling-output-offset));
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  display: table-cell;
  width: 100%;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/* collapseHeadingButton (show always if hiddenCellsButton is _not_ shown) */
.jp-collapseHeadingButton {
  display: flex;
  min-height: var(--jp-cell-collapser-min-height);
  font-size: var(--jp-code-font-size);
  position: absolute;
  background-color: transparent;
  background-size: 25px;
  background-repeat: no-repeat;
  background-position-x: center;
  background-position-y: top;
  background-image: var(--jp-icon-caret-down);
  right: 0;
  top: 0;
  bottom: 0;
}

.jp-collapseHeadingButton.jp-mod-collapsed {
  background-image: var(--jp-icon-caret-right);
}

/*
 set the container font size to match that of content
 so that the nested collapse buttons have the right size
*/
.jp-MarkdownCell .jp-InputPrompt {
  font-size: var(--jp-content-font-size1);
}

/*
  Align collapseHeadingButton with cell top header
  The font sizes are identical to the ones in packages/rendermime/style/base.css
*/
.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='1'] {
  font-size: var(--jp-content-font-size5);
  background-position-y: calc(0.3 * var(--jp-content-font-size5));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='2'] {
  font-size: var(--jp-content-font-size4);
  background-position-y: calc(0.3 * var(--jp-content-font-size4));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='3'] {
  font-size: var(--jp-content-font-size3);
  background-position-y: calc(0.3 * var(--jp-content-font-size3));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='4'] {
  font-size: var(--jp-content-font-size2);
  background-position-y: calc(0.3 * var(--jp-content-font-size2));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='5'] {
  font-size: var(--jp-content-font-size1);
  background-position-y: top;
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='6'] {
  font-size: var(--jp-content-font-size0);
  background-position-y: top;
}

/* collapseHeadingButton (show only on (hover,active) if hiddenCellsButton is shown) */
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-collapseHeadingButton {
  display: none;
}

.jp-Notebook.jp-mod-showHiddenCellsButton
  :is(.jp-MarkdownCell:hover, .jp-mod-active)
  .jp-collapseHeadingButton {
  display: flex;
}

/* showHiddenCellsButton (only show if jp-mod-showHiddenCellsButton is set, which
is a consequence of the showHiddenCellsButton option in Notebook Settings)*/
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton {
  margin-left: calc(var(--jp-cell-prompt-width) + 2 * var(--jp-code-padding));
  margin-top: var(--jp-code-padding);
  border: 1px solid var(--jp-border-color2);
  background-color: var(--jp-border-color3) !important;
  color: var(--jp-content-font-color0) !important;
  display: flex;
}

.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton:hover {
  background-color: var(--jp-border-color2) !important;
}

.jp-showHiddenCellsButton {
  display: none;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Using block instead of flex to allow the use of the break-inside CSS property for
cell outputs.
*/

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-notebook-toolbar-padding: 2px 5px 2px 2px;
}

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: var(--jp-notebook-toolbar-padding);

  /* disable paint containment from lumino 2.0 default strict CSS containment */
  contain: style size !important;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

.jp-Toolbar-responsive-popup {
  position: absolute;
  height: fit-content;
  display: flex;
  flex-direction: row;
  flex-wrap: wrap;
  justify-content: flex-end;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: var(--jp-notebook-toolbar-padding);
  z-index: 1;
  right: 0;
  top: 0;
}

.jp-Toolbar > .jp-Toolbar-responsive-opener {
  margin-left: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-Notebook-ExecutionIndicator {
  position: relative;
  display: inline-block;
  height: 100%;
  z-index: 9997;
}

.jp-Notebook-ExecutionIndicator-tooltip {
  visibility: hidden;
  height: auto;
  width: max-content;
  width: -moz-max-content;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color1);
  text-align: justify;
  border-radius: 6px;
  padding: 0 5px;
  position: fixed;
  display: table;
}

.jp-Notebook-ExecutionIndicator-tooltip.up {
  transform: translateX(-50%) translateY(-100%) translateY(-32px);
}

.jp-Notebook-ExecutionIndicator-tooltip.down {
  transform: translateX(calc(-100% + 16px)) translateY(5px);
}

.jp-Notebook-ExecutionIndicator-tooltip.hidden {
  display: none;
}

.jp-Notebook-ExecutionIndicator:hover .jp-Notebook-ExecutionIndicator-tooltip {
  visibility: visible;
}

.jp-Notebook-ExecutionIndicator span {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  color: var(--jp-ui-font-color1);
  line-height: 24px;
  display: block;
}

.jp-Notebook-ExecutionIndicator-progress-bar {
  display: flex;
  justify-content: center;
  height: 100%;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*
 * Execution indicator
 */
.jp-tocItem-content::after {
  content: '';

  /* Must be identical to form a circle */
  width: 12px;
  height: 12px;
  background: none;
  border: none;
  position: absolute;
  right: 0;
}

.jp-tocItem-content[data-running='0']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background: none;
}

.jp-tocItem-content[data-running='1']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background-color: var(--jp-inverse-layout-color3);
}

.jp-tocItem-content[data-running='0'],
.jp-tocItem-content[data-running='1'] {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Notebook-footer {
  height: 27px;
  margin-left: calc(
    var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
      var(--jp-cell-padding)
  );
  width: calc(
    100% -
      (
        var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
          var(--jp-cell-padding) + var(--jp-cell-padding)
      )
  );
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  color: var(--jp-ui-font-color3);
  margin-top: 6px;
  background: none;
  cursor: pointer;
}

.jp-Notebook-footer:focus {
  border-color: var(--jp-cell-editor-active-border-color);
}

/* For devices that support hovering, hide footer until hover */
@media (hover: hover) {
  .jp-Notebook-footer {
    opacity: 0;
  }

  .jp-Notebook-footer:focus,
  .jp-Notebook-footer:hover {
    opacity: 1;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-side-by-side-output-size: 1fr;
  --jp-side-by-side-resized-cell: var(--jp-side-by-side-output-size);
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

/* stylelint-disable selector-max-class */

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-MainAreaWidget-ContainStrict .jp-Notebook * {
  contain: strict;
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* cell is dirty */
.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt {
  color: var(--jp-warn-color1);
}

.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt::before {
  color: var(--jp-warn-color1);
  content: '';
}

.jp-Notebook .jp-Cell.jp-mod-active.jp-mod-dirty .jp-Collapser {
  background: var(--jp-warn-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: block;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-ActiveCellTool {
  padding: 12px 0;
  display: flex;
}

.jp-ActiveCellTool-Content {
  flex: 1 1 auto;
}

.jp-ActiveCellTool .jp-ActiveCellTool-CellContent {
  background: var(--jp-cell-editor-background);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  min-height: 29px;
}

.jp-ActiveCellTool .jp-InputPrompt {
  min-width: calc(var(--jp-cell-prompt-width) * 0.75);
}

.jp-ActiveCellTool-CellContent > pre {
  padding: 5px 4px;
  margin: 0;
  white-space: normal;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label,
.jp-NumberSetter label {
  line-height: 1.4;
}

.jp-NotebookTools .jp-select-wrapper {
  margin-top: 4px;
  margin-bottom: 0;
}

.jp-NumberSetter input {
  width: 100%;
  margin-top: 4px;
}

.jp-NotebookTools .jp-Collapse {
  margin-top: 16px;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Side-by-side Mode (.jp-mod-sideBySide)
|----------------------------------------------------------------------------*/
.jp-mod-sideBySide.jp-Notebook .jp-Notebook-cell {
  margin-top: 3em;
  margin-bottom: 3em;
  margin-left: 5%;
  margin-right: 5%;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell {
  display: grid;
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-output-size)
    );
  grid-template-rows: auto minmax(0, 1fr) auto;
  grid-template-areas:
    'header header header'
    'input handle output'
    'footer footer footer';
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell.jp-mod-resizedCell {
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-resized-cell)
    );
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellHeader {
  grid-area: header;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-inputWrapper {
  grid-area: input;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-outputWrapper {
  /* overwrite the default margin (no vertical separation needed in side by side move */
  margin-top: 0;
  grid-area: output;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellFooter {
  grid-area: footer;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle {
  grid-area: handle;
  user-select: none;
  display: block;
  height: 100%;
  cursor: ew-resize;
  padding: 0 var(--jp-cell-padding);
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle::after {
  content: '';
  display: block;
  background: var(--jp-border-color2);
  height: 100%;
  width: 5px;
}

.jp-mod-sideBySide.jp-Notebook
  .jp-CodeCell.jp-mod-resizedCell
  .jp-CellResizeHandle::after {
  background: var(--jp-border-color0);
}

.jp-CellResizeHandle {
  display: none;
}

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Cell-Placeholder {
  padding-left: 55px;
}

.jp-Cell-Placeholder-wrapper {
  background: #fff;
  border: 1px solid;
  border-color: #e5e6e9 #dfe0e4 #d0d1d5;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  margin: 10px 15px;
}

.jp-Cell-Placeholder-wrapper-inner {
  padding: 15px;
  position: relative;
}

.jp-Cell-Placeholder-wrapper-body {
  background-repeat: repeat;
  background-size: 50% auto;
}

.jp-Cell-Placeholder-wrapper-body div {
  background: #f6f7f8;
  background-image: -webkit-linear-gradient(
    left,
    #f6f7f8 0%,
    #edeef1 20%,
    #f6f7f8 40%,
    #f6f7f8 100%
  );
  background-repeat: no-repeat;
  background-size: 800px 104px;
  height: 104px;
  position: absolute;
  right: 15px;
  left: 15px;
  top: 15px;
}

div.jp-Cell-Placeholder-h1 {
  top: 20px;
  height: 20px;
  left: 15px;
  width: 150px;
}

div.jp-Cell-Placeholder-h2 {
  left: 15px;
  top: 50px;
  height: 10px;
  width: 100px;
}

div.jp-Cell-Placeholder-content-1,
div.jp-Cell-Placeholder-content-2,
div.jp-Cell-Placeholder-content-3 {
  left: 15px;
  right: 15px;
  height: 10px;
}

div.jp-Cell-Placeholder-content-1 {
  top: 100px;
}

div.jp-Cell-Placeholder-content-2 {
  top: 120px;
}

div.jp-Cell-Placeholder-content-3 {
  top: 140px;
}

</style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0 2px 1px -1px var(--jp-shadow-umbra-color),
    0 1px 1px 0 var(--jp-shadow-penumbra-color),
    0 1px 3px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0 3px 1px -2px var(--jp-shadow-umbra-color),
    0 2px 2px 0 var(--jp-shadow-penumbra-color),
    0 1px 5px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0 2px 4px -1px var(--jp-shadow-umbra-color),
    0 4px 5px 0 var(--jp-shadow-penumbra-color),
    0 1px 10px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0 3px 5px -1px var(--jp-shadow-umbra-color),
    0 6px 10px 0 var(--jp-shadow-penumbra-color),
    0 1px 18px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0 5px 5px -3px var(--jp-shadow-umbra-color),
    0 8px 10px 1px var(--jp-shadow-penumbra-color),
    0 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0 7px 8px -4px var(--jp-shadow-umbra-color),
    0 12px 17px 2px var(--jp-shadow-penumbra-color),
    0 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0 8px 10px -5px var(--jp-shadow-umbra-color),
    0 16px 24px 2px var(--jp-shadow-penumbra-color),
    0 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0 10px 13px -6px var(--jp-shadow-umbra-color),
    0 20px 31px 3px var(--jp-shadow-penumbra-color),
    0 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0 11px 15px -7px var(--jp-shadow-umbra-color),
    0 24px 38px 3px var(--jp-shadow-penumbra-color),
    0 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-inverse-border-color: var(--md-grey-600);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;
  --jp-ui-font-family: system-ui, -apple-system, blinkmacsystemfont, 'Segoe UI',
    helvetica, arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;
  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);
  --jp-content-link-color: var(--md-blue-900);
  --jp-content-font-family: system-ui, -apple-system, blinkmacsystemfont,
    'Segoe UI', helvetica, arial, sans-serif, 'Apple Color Emoji',
    'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: menlo, consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-900);
  --jp-brand-color1: var(--md-blue-700);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);
  --jp-accent-color0: var(--md-green-900);
  --jp-accent-color1: var(--md-green-700);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-900);
  --jp-warn-color1: var(--md-orange-700);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);
  --jp-error-color0: var(--md-red-900);
  --jp-error-color1: var(--md-red-700);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);
  --jp-success-color0: var(--md-green-900);
  --jp-success-color1: var(--md-green-700);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);
  --jp-info-color0: var(--md-cyan-900);
  --jp-info-color1: var(--md-cyan-700);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;
  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;
  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);
  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: var(--jp-code-font-family-default);
  --jp-cell-prompt-letter-spacing: 0;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);

  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;

  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Statusbar specific styles */

  --jp-statusbar-height: 24px;

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-inverse-border-color);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: rgb(0, 54, 109);
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #a2f;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #a2f;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /*
    RTC user specific colors.
    These colors are used for the cursor, username in the editor,
    and the icon of the user.
  */

  --jp-collaborator-color1: #ffad8e;
  --jp-collaborator-color2: #dac83d;
  --jp-collaborator-color3: #72dd76;
  --jp-collaborator-color4: #00e4d0;
  --jp-collaborator-color5: #45d4ff;
  --jp-collaborator-color6: #e2b1ff;
  --jp-collaborator-color7: #ff9de6;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 250px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);

  /* Button colors */
  --jp-accept-color-normal: var(--md-blue-700);
  --jp-accept-color-hover: var(--md-blue-800);
  --jp-accept-color-active: var(--md-blue-900);
  --jp-warn-color-normal: var(--md-red-700);
  --jp-warn-color-hover: var(--md-red-800);
  --jp-warn-color-active: var(--md-red-900);
  --jp-reject-color-normal: var(--md-grey-600);
  --jp-reject-color-hover: var(--md-grey-700);
  --jp-reject-color-active: var(--md-grey-800);

  /* File or activity icons and switch semantic variables */
  --jp-jupyter-icon-color: #f37626;
  --jp-notebook-icon-color: #f37626;
  --jp-json-icon-color: var(--md-orange-700);
  --jp-console-icon-background-color: var(--md-blue-700);
  --jp-console-icon-color: white;
  --jp-terminal-icon-background-color: var(--md-grey-800);
  --jp-terminal-icon-color: var(--md-grey-200);
  --jp-text-editor-icon-color: var(--md-grey-700);
  --jp-inspector-icon-color: var(--md-grey-700);
  --jp-switch-color: var(--md-grey-400);
  --jp-switch-true-position-color: var(--md-orange-900);
}
</style>
<style type="text/css">
/* Force rendering true colors when outputing to pdf */
* {
  -webkit-print-color-adjust: exact;
}

/* Misc */
a.anchor-link {
  display: none;
}

/* Input area styling */
.jp-InputArea {
  overflow: hidden;
}

.jp-InputArea-editor {
  overflow: hidden;
}

.cm-editor.cm-s-jupyter .highlight pre {
/* weird, but --jp-code-padding defined to be 5px but 4px horizontal padding is hardcoded for pre.cm-line */
  padding: var(--jp-code-padding) 4px;
  margin: 0;

  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
  color: inherit;

}

.jp-OutputArea-output pre {
  line-height: inherit;
  font-family: inherit;
}

.jp-RenderedText pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
}

/* Hiding the collapser by default */
.jp-Collapser {
  display: none;
}

@page {
    margin: 0.5in; /* Margin for each printed piece of paper */
}

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}
</style>
<!-- Load mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script>
<!-- MathJax configuration -->
<script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
<!-- End of mathjax configuration --><script type="module">
  document.addEventListener("DOMContentLoaded", async () => {
    const diagrams = document.querySelectorAll(".jp-Mermaid > pre.mermaid");
    // do not load mermaidjs if not needed
    if (!diagrams.length) {
      return;
    }
    const mermaid = (await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.6.0/mermaid.esm.min.mjs")).default;
    const parser = new DOMParser();

    mermaid.initialize({
      maxTextSize: 100000,
      startOnLoad: false,
      fontFamily: window
        .getComputedStyle(document.body)
        .getPropertyValue("--jp-ui-font-family"),
      theme: document.querySelector("body[data-jp-theme-light='true']")
        ? "default"
        : "dark",
    });

    let _nextMermaidId = 0;

    function makeMermaidImage(svg) {
      const img = document.createElement("img");
      const doc = parser.parseFromString(svg, "image/svg+xml");
      const svgEl = doc.querySelector("svg");
      const { maxWidth } = svgEl?.style || {};
      const firstTitle = doc.querySelector("title");
      const firstDesc = doc.querySelector("desc");

      img.setAttribute("src", `data:image/svg+xml,${encodeURIComponent(svg)}`);
      if (maxWidth) {
        img.width = parseInt(maxWidth);
      }
      if (firstTitle) {
        img.setAttribute("alt", firstTitle.textContent);
      }
      if (firstDesc) {
        const caption = document.createElement("figcaption");
        caption.className = "sr-only";
        caption.textContent = firstDesc.textContent;
        return [img, caption];
      }
      return [img];
    }

    async function makeMermaidError(text) {
      let errorMessage = "";
      try {
        await mermaid.parse(text);
      } catch (err) {
        errorMessage = `${err}`;
      }

      const result = document.createElement("details");
      result.className = 'jp-RenderedMermaid-Details';
      const summary = document.createElement("summary");
      summary.className = 'jp-RenderedMermaid-Summary';
      const pre = document.createElement("pre");
      const code = document.createElement("code");
      code.innerText = text;
      pre.appendChild(code);
      summary.appendChild(pre);
      result.appendChild(summary);

      const warning = document.createElement("pre");
      warning.innerText = errorMessage;
      result.appendChild(warning);
      return [result];
    }

    async function renderOneMarmaid(src) {
      const id = `jp-mermaid-${_nextMermaidId++}`;
      const parent = src.parentNode;
      let raw = src.textContent.trim();
      const el = document.createElement("div");
      el.style.visibility = "hidden";
      document.body.appendChild(el);
      let results = null;
      let output = null;
      try {
        const { svg } = await mermaid.render(id, raw, el);
        results = makeMermaidImage(svg);
        output = document.createElement("figure");
        results.map(output.appendChild, output);
      } catch (err) {
        parent.classList.add("jp-mod-warning");
        results = await makeMermaidError(raw);
        output = results[0];
      } finally {
        el.remove();
      }
      parent.classList.add("jp-RenderedMermaid");
      parent.appendChild(output);
    }

    void Promise.all([...diagrams].map(renderOneMarmaid));
  });
</script>
<style>
  .jp-Mermaid:not(.jp-RenderedMermaid) {
    display: none;
  }

  .jp-RenderedMermaid {
    overflow: auto;
    display: flex;
  }

  .jp-RenderedMermaid.jp-mod-warning {
    width: auto;
    padding: 0.5em;
    margin-top: 0.5em;
    border: var(--jp-border-width) solid var(--jp-warn-color2);
    border-radius: var(--jp-border-radius);
    color: var(--jp-ui-font-color1);
    font-size: var(--jp-ui-font-size1);
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .jp-RenderedMermaid figure {
    margin: 0;
    overflow: auto;
    max-width: 100%;
  }

  .jp-RenderedMermaid img {
    max-width: 100%;
  }

  .jp-RenderedMermaid-Details > pre {
    margin-top: 1em;
  }

  .jp-RenderedMermaid-Summary {
    color: var(--jp-warn-color2);
  }

  .jp-RenderedMermaid:not(.jp-mod-warning) pre {
    display: none;
  }

  .jp-RenderedMermaid-Summary > pre {
    display: inline-block;
    white-space: normal;
  }
</style>
<!-- End of mermaid configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<main>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=e1ba5814-1df6-4bee-a36a-f4ee77692be0">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Assignment-RL">Assignment RL<a class="anchor-link" href="#Assignment-RL"></a></h1><p>Structure:</p>
<ol>
<li><a href="#Environment-Explaination">Environment explaination</a></li>
</ol>
<hr/>
<ol start="2">
<li><a href="#Agent-Choice">Agent Choice</a></li>
</ol>
<hr/>
<ol start="3">
<li><a href="#Dependencies">Dependencies</a></li>
</ol>
<hr/>
<ol start="4">
<li><p><a href="#Implementations">Implementations</a></p>
<div class="alert alert-block alert-danger">
<ol>
<li><b><a href="#Deep-Q-Network">Deep-Q-Network</a></b><ol>
<li><b><a href="#Deep-Q-Network-Implementation">Deep-Q-Network</a></b><ol>
<li><b><a href="#Deep-Q-Network-RAM-Observations">RAM Observations</a></b></li>
<li><b><a href="#Deep-Q-Network-Image-Observations">Image Observations</a></b></li>
<li><b><a href="#Hyperparameter-Sweep-Deep-Q-Network-(RAM)">Hyper parameter sweep(RAM)</a></b></li>
</ol>
</li>
<li><b><a href="#Dueling-Double-DQN-Impementation">Dueling Double DQN Impementation</a></b><ol>
<li><b><a href="#Dueling-Double-DQN-RAM-Observations">RAM Observations</a></b></li>
<li><b><a href="#Dueling-Double-DQN-Image-Observations">Image Observations</a></b></li>
<li><b><a href="#Hyperparameter-Sweep-Dueling-Double-DQN-(RAM)">Hyper parameter sweep(RAM)</a></b></li>
</ol>
</li>
</ol>
</li>
</ol>
</div>
<div class="alert alert-block alert-warning">
<ol start="2">
<li><b><a href="#Soft-Actor-Critic-(SAC)">Soft-Actor-Critic-(SAC).</a></b><ol>
<li><b><a href="#Actor-Critic-Impementation">Actor-Critic Impementation</a></b><ol>
<li><b><a href="#Actor-Critic-Image-Observations">Image Observations</a></b></li>
</ol>
</li>
<li><b><a href="#Soft-Actor-Critic-(SAC)-Impementation">Soft Actor-Critic (SAC) Impementation</a></b><ol>
<li><b><a href="#Soft-Actor-Critic-(SAC)-RAM-Observations">RAM Observations</a></b></li>
<li><b><a href="#Soft-Actor-Critic-(SAC)-Image-Observations">Image Observations</a></b></li>
<li><b><a href="#Hyperparameter-Sweep-Soft-Actor-Critic-(SAC)(RAM)">Hyper parameter sweep(RAM)</a></b></li>
</ol>
</li>
</ol>
</li>
</ol>
</div>
<div class="alert alert-block alert-success">
<ol start="3">
<li><b><a href="#Proximal-Policy-Optimization-(PPO)">Proximal Policy Optimization (PPO)</a></b><ol>
<li><b><a href="#Proximal-Policy-Optimization-(PPO)-Impementation">Proximal Policy Optimization (PPO) Impementation</a></b><ol>
<li><b><a href="#Proximal-Policy-Optimization-(PPO)-RAM-Observations">RAM Observations</a></b></li>
<li><b><a href="#Proximal-Policy-Optimization-(PPO)-Image-Observations">Image Observations</a></b></li>
<li><b><a href="#Hyperparameter-Sweep-PPO-(RAM)">Hyper parameter sweep(RAM)</a></b></li>
</ol>
</li>
</ol>
</li>
</ol>
</div>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=37b74dd3-269d-4423-a71c-aae18763f085">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Environment-Explaination">Environment Explaination<a class="anchor-link" href="#Environment-Explaination"></a></h1>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=f2643182-8ef7-4e12-bd67-2bf9c6f98fa9">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>Overview <br/></li>
</ul>
<p>In the Boxing environment, the agent's task is to engage in a boxing match in a ring, where it must land punches on the opponent to score points. A knockout occurs when the agent scores 100 points, ending the match in victory. The environment provides a relatively simple yet challenging reinforcement learning problem, where strategic planning and control must be executed to maximize the score.</p>
<table>
<thead>
<tr>
<th>Attribute</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Action Space</td>
<td>Discrete(18) - 18 possible actions</td>
</tr>
<tr>
<td>Observation Space</td>
<td>Box(0, 255, (210, 160, 3), uint8)</td>
</tr>
<tr>
<td>RGB Shape</td>
<td>(210, 160, 3)</td>
</tr>
<tr>
<td>Grayscale Shape</td>
<td>(210, 160)</td>
</tr>
<tr>
<td>RAM Shape</td>
<td>(128,)</td>
</tr>
<tr>
<td>Reward</td>
<td>Points for landing punches (100 points = Knockout)</td>
</tr>
<tr>
<td>Frameskip</td>
<td>(2, 5) or 4 (depending on variant)</td>
</tr>
<tr>
<td>Repeat Action Probability</td>
<td>0.25 (default) or 0.0 (some variants)</td>
</tr>
<tr>
<td>Difficulty</td>
<td>[0, 1, 2, 3] (default: 0)</td>
</tr>
<tr>
<td>Mode</td>
<td>[0] (default: 0)</td>
</tr>
</tbody>
</table>
<p>strategies, and gene</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=86b74aba-19b0-47fb-b30b-16449610acd1">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>Action Space<br/></li>
</ul>
<p>The environment offers an action space of Discrete(18), meaning there are 18 possible actions that the agent can take. These actions cover various directions (e.g., moving up, down, left, or right) and combinations of actions with punching (e.g., UPFIRE, LEFTFIRE). The table below explains. Each action corresponds to a movement or punch combination, providing the agent with diverse strategies to interact with the environment.<br/></p>
<br/>
<table>
<thead>
<tr>
<th>Value</th>
<th>Meaning</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>NOOP</td>
<td>No operation, do nothing</td>
</tr>
<tr>
<td>1</td>
<td>FIRE</td>
<td>Press the fire button without updating the joystick position</td>
</tr>
<tr>
<td>2</td>
<td>UP</td>
<td>Apply a -movement upwards on the joystick</td>
</tr>
<tr>
<td>3</td>
<td>RIGHT</td>
<td>Apply a -movement rightward on the joystick</td>
</tr>
<tr>
<td>4</td>
<td>LEFT</td>
<td>Apply a -movement leftward on the joystick</td>
</tr>
<tr>
<td>5</td>
<td>DOWN</td>
<td>Apply a -movement downward on the joystick</td>
</tr>
<tr>
<td>6</td>
<td>UPRIGHT</td>
<td>Execute UP and RIGHT</td>
</tr>
<tr>
<td>7</td>
<td>UPLEFT</td>
<td>Execute UP and LEFT</td>
</tr>
<tr>
<td>8</td>
<td>DOWNRIGHT</td>
<td>Execute DOWN and RIGHT</td>
</tr>
<tr>
<td>9</td>
<td>DOWNLEFT</td>
<td>Execute DOWN and LEFT</td>
</tr>
<tr>
<td>10</td>
<td>UPFIRE</td>
<td>Execute UP and FIRE</td>
</tr>
<tr>
<td>11</td>
<td>RIGHTFIRE</td>
<td>Execute RIGHT and FIRE</td>
</tr>
<tr>
<td>12</td>
<td>LEFTFIRE</td>
<td>Execute LEFT and FIRE</td>
</tr>
<tr>
<td>13</td>
<td>DOWNFIRE</td>
<td>Execute DOWN and FIRE</td>
</tr>
<tr>
<td>14</td>
<td>UPRIGHTFIRE</td>
<td>Execute UP and RIGHT and FIRE</td>
</tr>
<tr>
<td>15</td>
<td>UPLEFTFIRE</td>
<td>Execute UP and LEFT and FIRE</td>
</tr>
<tr>
<td>16</td>
<td>DOWNRIGHTFIRE</td>
<td>Execute DOWN and RIGHT and FIRE</td>
</tr>
<tr>
<td>17</td>
<td>DOWNLEFTFIRE</td>
<td>Execute DOWN and LEFT and FIRE</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=b33203c1-4089-4511-8bb0-7ff224a5e7d0">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li><p>Observation Space
<br/>The observation space for the Boxing environment varies based on the configuration chosen (e.g., RGB, grayscale or RAM-based observations):</p>
<ul>
<li><p>RGB observations:
<br/>A color image of the boxing ring is provided with a dimension of 210 (height) x 160 (width) and 3 color channels, which is typical for Atari games. This provides rich visual information that the agent must interpret to learn meaningful behavior. <br/>
<code>obs_type="rgb" -&gt; observation_space=Box(0, 255, (210, 160, 3), np.uint8)</code></p>
</li>
<li><p>Grayscale Obsercations:
<br/>A grayscal image of the boxing ring is provided of dimenasion 210 height, 160 width and 1 channel rather than 3. This was used for all image experimaents as it provideds the required information withoughout the greater over head of 3 colour channels. <br/>
<code>obs_type="grayscale" -&gt; Box(0, 255, (210, 160), np.uint8)</code></p>
</li>
<li><p>RAM observations:
<br/>An alternative hich contrary to the other spaces that reliy on the game screen for data, the ram observation space uses the console's memory. Atari 2600 has 1024 bits of random access memory that stores the internal state of the gane, including posisitons of game entities, timers and health conditions or score for boxing.  This RAM observation space os Marlovian capturing the full state at any given time without the need for prior context. We us the npint8 adition as well and thus 1024 bits becomes 128 ints (1024/8). There is also some other processing such as applying linear function approximations to capture the values of the the multibit groups. Aswell as adding the logical-AND of every possible bit pair to the feature vector (Bellemare et al., 2013). Allowing the function to capture combinations of values, as the profuct of two multibit groupings can be represented as the sum of their bitwise product   (Bellemare et al., 2013). <br/>
<code>obs_type="ram" -&gt; observation_space=Box(0, 255, (128,), np.uint8)</code></p>
</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=35ae2f6c-99a8-4fe1-94c3-ed95b4df996f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>Rewards <br/></li>
</ul>
<p>The reward system in the Boxing environment is simple the agent receives points for each punch that successfully hits the opponent. A reward of 100 points triggers a knockout, and scoring higher overall leads to better performance. This aligns with the goal of maximizing cumulative rewards in reinforcement learning. If the Agent has scored a positive reward at the end of the run the agent has won.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=e3d3a014-7121-4a1d-bc06-54861cdc094f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p><img alt="RLassignment.png" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABWQAAAHxCAYAAADqabVSAAAAAXNSR0IArs4c6QAAAARnQU1BAACx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"/></p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=d2fdd699-f159-43d8-acfb-74a3636cf50f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p><cite id="gqmj4"><a href="#zotero%7C18759246%2FFUI8Z6RK">(Machado et al., 2018)</a></cite>
<cite id="zc629"><a href="#zotero%7C18759246%2FKRBTYLUS">(Bellemare et al., 2013)</a></cite></p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=d0ec5266-a9c5-4b89-8c3c-14e4985dda30">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<ul>
<li>Environment Variants <br/>
  Several variants of the Boxing environment exist, offering differences in terms of observation type, frame-skipping, and repeataction probability: <br/><ul>
<li>Boxing-v0: Uses "RGB" observations with frame-skipping values between 2 and 5 and a 0.25 action repeat probability.</li>
<li>Boxing-ram-v0: Uses RAM observations under the same conditions as Boxing-v0.</li>
<li>BoxingDeterministic-v0: A deterministic version using RGB observations with no randomness in frame-skipping and action selection.</li>
<li>BoxingNoFrameskip-v0: A variant where no frame-skipping is applied, making each action selection critical for performance.</li>
</ul>
</li>
</ul>
<br/>
<hr/>
<br/>
<ul>
<li>Difficulty and Modes <br/>
  Boxing includes adjustable difficulty settings and game modes to customize the agent's experience. The default difficulty is 0, and possible values for difficulty range from 0 to 3. Adjusting difficulty impacts the responsiveness and behavior of the opponent, making the environment more or less challenging depending on the choice.<br/></li>
</ul>
<br/>
<hr/>
<br/>
<ul>
<li>Research and Reinforcement Learning <br/>
      As explored in the Arcade Learning Environment by Bellemare et al., Boxing is one of the many Atari games used to benchmark AI agents, particularly those employing reinforcement learning techniques like SARSA(), Q-learning, or deep reinforcement learning models. The simplicity of the environment, combined with its discrete action space and challenging dynamics, makes it an excellent testbed for evaluating the general competency of agents. Researchers often use Boxing to analyze how well agents can learn to exploit the opponent's weaknesses and optimize long-term reward accumulation(Bellemare et al., 2013).</li>
</ul>
<p>In conclusion, the Boxing environment presents a straightforward, yet non-trivial task for RL agents, with its rich action space and varying observation types. It offers a useful benchmark for researeneral game-playing AI.on reinforcement learning, action selection strategies, and gene</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=36ad7f26-a53e-4fdf-92b7-3b9efe1295da">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Agent-Choice">Agent Choice<a class="anchor-link" href="#Agent-Choice"></a></h1>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=bb273728-e081-4725-a7a3-aed26a345c69">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>SAC</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=1b3b25fe-c37d-4bc9-b4cd-9b1dd9f46959">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">PPO</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=7ecd956e-c62a-4810-9cbc-25fbeb7f0330">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">DQN</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=0b38af1f-7398-4a81-a463-aadc0223219f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Dependencies">Dependencies<a class="anchor-link" href="#Dependencies"></a></h1>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=9d429774-8d48-4abf-b54b-1b2269d602b8">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>pyvirtualdisplay
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>opencv-python<span class="w"> </span>imageio<span class="o">[</span>ffmpeg<span class="o">]</span>
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>wandb
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span><span class="nv">docutils</span><span class="o">==</span><span class="m">0</span>.17.1
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>jupyterlab-citation-manager
<span class="o">!</span>wandb<span class="w"> </span>login
<span class="n">display</span> <span class="o">=</span> <span class="n">Display</span><span class="p">(</span><span class="n">visible</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">768</span><span class="p">))</span>
<span class="n">display</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">Latex</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=6128842e-a5a3-44ea-b611-204d779d61f7">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[2]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># import necessary libraries</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">'XDG_RUNTIME_DIR'</span><span class="p">]</span> <span class="o">=</span> <span class="s1">'/tmp/runtime-tristan'</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">'Agg'</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">from</span> <span class="nn">gymnasium</span> <span class="kn">import</span> <span class="n">spaces</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="kn">import</span> <span class="nn">moviepy.editor</span> <span class="k">as</span> <span class="nn">mpy</span>
<span class="kn">import</span> <span class="nn">ast</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="kn">import</span> <span class="nn">moviepy.editor</span> <span class="k">as</span> <span class="nn">mpy</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">wandb</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">ast</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">imageio</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">gymnasium.wrappers</span> <span class="kn">import</span> <span class="n">ResizeObservation</span>
<span class="kn">from</span> <span class="nn">gymnasium.wrappers</span> <span class="kn">import</span> <span class="n">NormalizeObservation</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">from</span> <span class="nn">gymnasium</span> <span class="kn">import</span> <span class="n">spaces</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="kn">import</span> <span class="nn">moviepy.editor</span> <span class="k">as</span> <span class="nn">mpy</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">wandb</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="kn">import</span> <span class="nn">moviepy.editor</span> <span class="k">as</span> <span class="nn">mpy</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">wandb</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">ast</span>  <span class="c1"># For safely evaluating tuple strings</span>

<span class="c1"># create random number generator</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=53e3f1df-85a4-4843-aea6-034a3f1bc168">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">Functions</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=ab0bf1ce-2047-4205-886d-b636246c17e3">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[55]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">VideoRecorderRAM</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dir_name</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="mi">30</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dir_name</span> <span class="o">=</span> <span class="n">dir_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fps</span> <span class="o">=</span> <span class="n">fps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">frames</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">frames</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">record</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">frame</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_name</span><span class="p">):</span>
        <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dir_name</span><span class="p">,</span> <span class="n">file_name</span><span class="p">)</span>
        <span class="n">imageio</span><span class="o">.</span><span class="n">mimsave</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">frames</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">fps</span><span class="p">,</span> <span class="n">macro_block_size</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>

<span class="c1">#v= VideoRecorderRAM('DQN')</span>
<span class="c1">#v.frames=frames</span>
<span class="c1">#v.save("prac_DQN.mp4")</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=4a39020e-0d60-40ff-a2f6-04040dc720e9">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">VideoRecorder</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dir_name</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="mi">30</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dir_name</span> <span class="o">=</span> <span class="n">dir_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fps</span> <span class="o">=</span> <span class="n">fps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">frames</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">frames</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">record</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">frame</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_name</span><span class="p">):</span>
        <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dir_name</span><span class="p">,</span> <span class="n">file_name</span><span class="p">)</span>
        <span class="n">frames_np</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span> <span class="k">for</span> <span class="n">frame</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">frames</span><span class="p">]</span>
        <span class="n">imageio</span><span class="o">.</span><span class="n">mimsave</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">frames_np</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">fps</span><span class="p">,</span> <span class="n">macro_block_size</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=91526f19-8ad7-43a8-8969-c4cfc3229391">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=7d746a58-6d5f-4aa1-8b79-5e53c770ddc5">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Implementations">Implementations<a class="anchor-link" href="#Implementations"></a></h1>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=e6211d06-f433-4a1c-bb25-ce922da97edb">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Deep-Q-Network">Deep-Q-Network<a class="anchor-link" href="#Deep-Q-Network"></a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=24df6ed5-eb64-4f42-9eac-1f00dc2de042">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Deep-Q-Network-Implementation">Deep-Q-Network Implementation<a class="anchor-link" href="#Deep-Q-Network-Implementation"></a></h3>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=0331d980-561b-4b66-ae13-7420e4ed63ff">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Practical-DQN">Practical DQN<a class="anchor-link" href="#Practical-DQN"></a></h4>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=f825841e-69a0-4d80-94a9-06c2a7438736">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Setup weights and bias to compare the original implementation seen in the practical and other implementations.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=b406aa3a-f6b0-4333-86fd-fca0724dc43e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>QNetwork</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=19e3958b-e479-4014-8f75-f67e9ac76ca3">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[11]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">PracQNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span> <span class="c1">#changed name to PracQNetwork for logging </span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># create network layers</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>

        <span class="c1"># input layer</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>

        <span class="c1"># hidden layers</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>

        <span class="c1"># output layer</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">output_size</span><span class="p">))</span>

        <span class="c1"># combine layers into feed-forward network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

        <span class="c1"># select loss function and optimizer</span>
        <span class="c1"># note: original paper uses modified MSE loss and RMSprop</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># return output of Q-network for the input x</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
        <span class="c1"># update network weights for a minibatch of inputs and targets:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">copy_from</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">qnetwork</span><span class="p">):</span>
        <span class="c1"># copy weights from another Q-network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">qnetwork</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=54e86b03-3c41-449f-b5ef-a7d770c902fe">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=52f38bf3-f72d-4130-aa27-f58ba5b68878">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[52]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">'ALE/Boxing-v5'</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">"rgb_array_list"</span><span class="p">,</span> <span class="n">obs_type</span><span class="o">=</span><span class="s2">"ram"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">high</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">low</span><span class="p">)</span>

<span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.99</span>
<span class="n">hidden_sizes</span> <span class="o">=</span> <span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">replay_size</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">minibatch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">target_update</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">max_episodes</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">max_steps</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">criterion_episodes</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1">#settings=wandb.Settings(start_method="fork")</span>

<span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">project</span><span class="o">=</span><span class="s1">'DQN-Original-comparison-Final'</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="p">{</span>
    <span class="s1">'gamma'</span><span class="p">:</span> <span class="n">gamma</span><span class="p">,</span>
    <span class="s1">'learning_rate'</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">,</span>
    <span class="s1">'epsilon'</span><span class="p">:</span> <span class="n">epsilon</span><span class="p">,</span>
    <span class="s1">'replay_size'</span><span class="p">:</span> <span class="n">replay_size</span><span class="p">,</span>
    <span class="s1">'minibatch_size'</span><span class="p">:</span> <span class="n">minibatch_size</span><span class="p">,</span>
    <span class="s1">'target_update_freq'</span><span class="p">:</span> <span class="n">target_update</span><span class="p">,</span>
    <span class="s1">'num_episodes'</span><span class="p">:</span> <span class="n">max_episodes</span><span class="p">,</span>
    <span class="s1">'max_steps_per_episode'</span><span class="p">:</span> <span class="n">max_steps</span><span class="p">,</span>
    <span class="s1">'criterion_episodes'</span><span class="p">:</span><span class="n">criterion_episodes</span>
<span class="p">})</span>

<span class="sd">'''DD=wandb.init(project='DQN-Original-comparison-Final', config={</span>
<span class="sd">    'gamma': gamma,</span>
<span class="sd">    'learning_rate': learning_rate,</span>
<span class="sd">    'epsilon': epsilon,</span>
<span class="sd">    'replay_size': replay_size,</span>
<span class="sd">    'minibatch_size': minibatch_size,</span>
<span class="sd">    'target_update_freq': target_update,</span>
<span class="sd">    'num_episodes': max_episodes,</span>
<span class="sd">    'max_steps_per_episode': max_steps,</span>
<span class="sd">    'criterion_episodes':criterion_episodes</span>
<span class="sd">})'''</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>128
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
Finishing last run (ID:17sp1bec) before initializing another...
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\r'), FloatProgress(value=1.0, max=1.0)))</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
<style>
    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}
    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }
    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }
    </style>
<div class="wandb-row"><div class="wandb-col"><h3>Run history:</h3><br><table class="wandb"><tr><td>episode</td><td></td></tr><tr><td>episode_num</td><td></td></tr><tr><td>episode_reward</td><td></td></tr><tr><td>epsilon</td><td></td></tr><tr><td>local reward</td><td></td></tr><tr><td>loss</td><td></td></tr><tr><td>steps</td><td></td></tr><tr><td>total steps</td><td></td></tr></table><br/></br></div><div class="wandb-col"><h3>Run summary:</h3><br><table class="wandb"><tr><td>episode</td><td>57</td></tr><tr><td>episode_num</td><td>58</td></tr><tr><td>episode_reward</td><td>-4</td></tr><tr><td>epsilon</td><td>0.2</td></tr><tr><td>local reward</td><td>0</td></tr><tr><td>loss</td><td>7.77793</td></tr><tr><td>steps</td><td>105145</td></tr><tr><td>total steps</td><td>103588</td></tr></table><br/></br></div></div>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
 View run <strong style="color:#cdcd00">sandy-morning-19</strong> at: <a href="https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final/runs/17sp1bec" target="_blank">https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final/runs/17sp1bec</a><br> View project at: <a href="https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final" target="_blank">https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final</a><br>Synced 5 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
</br></br></div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
Find logs at: <code>./wandb/run-20241016_180611-17sp1bec/logs</code>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
Successfully finished last run (ID:17sp1bec). Initializing new run:<br>
</br></div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
Tracking run with wandb version 0.18.3
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
Run data is saved locally in <code>/home/tristan/UniStuff/ReinforcementLearning/Assignment/wandb/run-20241016_183130-kqjpahr9</code>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
Syncing run <strong><a href="https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final/runs/kqjpahr9" target="_blank">cosmic-serenity-20</a></strong> to <a href="https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final" target="_blank">Weights &amp; Biases</a> (<a href="https://wandb.me/run" target="_blank">docs</a>)<br>
</br></div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
 View project at <a href="https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final" target="_blank">https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final</a>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
 View run at <a href="https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final/runs/kqjpahr9" target="_blank">https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final/runs/kqjpahr9</a>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[52]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>"DD=wandb.init(project='DQN-Original-comparison-Final', config={\n    'gamma': gamma,\n    'learning_rate': learning_rate,\n    'epsilon': epsilon,\n    'replay_size': replay_size,\n    'minibatch_size': minibatch_size,\n    'target_update_freq': target_update,\n    'num_episodes': max_episodes,\n    'max_steps_per_episode': max_steps,\n    'criterion_episodes':criterion_episodes\n})"</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=1c731031-5ee3-40fe-928a-9b7be13794fb">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>AgentClass</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=cf8fe8d4-5456-4886-8abd-4ac2280a1a19">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[54]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">wandb</span> #displays wand b plotting
class AgentDQN():
    def __init__(self, env, gamma,
                 hidden_sizes=(32, 32),
                 learning_rate=0.001,
                 epsilon=0.1,
                 replay_size=10000,
                 minibatch_size=32,
                 target_update=20
                 ):
        # check if the state space has correct type
        continuous = isinstance(env.observation_space, spaces.Box) and len(env.observation_space.shape) == 1
        assert continuous, 'Observation space must be continuous with shape (n,)'
        self.state_dims = env.observation_space.shape[0]

        # check if the action space has correct type
        assert isinstance(env.action_space, spaces.Discrete), 'Action space must be discrete'
        self.num_actions = env.action_space.n

        # create Q-networks for action-value function
        self.qnet = PracQNetwork(self.state_dims, hidden_sizes, self.num_actions, learning_rate)
        self.target_qnet = PracQNetwork(self.state_dims, hidden_sizes, self.num_actions, learning_rate)

        # copy weights from Q-network to target Q-network
        self.target_qnet.copy_from(self.qnet)

        # initialise replay buffer
        self.replay_buffer = deque(maxlen=replay_size)

        self.env = env
        self.gamma = gamma
        self.epsilon = epsilon
        self.minibatch_size = minibatch_size
        self.target_update = target_update
        self.target_update_idx = 0

    def behaviour(self, state):
        # exploratory behaviour policy
        if rng.uniform() &gt;= self.epsilon:
            # convert state to torch format
            if not torch.is_tensor(state):
                state = torch.tensor(state, dtype=torch.float)

            # exploitation with probability 1-epsilon; break ties randomly
            q = self.qnet(state).detach()
            j = rng.permutation(self.num_actions)
            return j[q[j].argmax().item()]
        else:
            # exploration with probability epsilon
            return self.env.action_space.sample()

    def policy(self, state):
        # convert state to torch format
        if not torch.is_tensor(state):
            state = torch.tensor(state, dtype=torch.float)

        # greedy policy
        q = self.qnet(state).detach()
        return q.argmax().item()

    def update(self):
        # update Q-network if there is enough experience
        if len(self.replay_buffer) &gt;= self.minibatch_size:
            # select mini-batch of experiences uniformly at random without replacement                                
            batch = rng.choice(len(self.replay_buffer), size=self.minibatch_size, replace=False)

            # calculate inputs and targets for the transitions in the mini-batch
            inputs = torch.zeros((self.minibatch_size, self.state_dims))
            targets = torch.zeros((self.minibatch_size, self.num_actions))

            for n, index in enumerate(batch):
                state, action, reward, next_state, terminated = self.replay_buffer[index]
                # inputs are states
                inputs[n, :] = state

                # targets are TD targets
                targets[n, :] = self.target_qnet(state).detach()

                if terminated:
                    targets[n, action] = reward
                else:
                    targets[n, action] = reward + self.gamma*self.target_qnet(next_state).detach().max()
            
            # train Q-network on the mini-batch
            logging_loss=self.qnet.update(inputs, targets)
            #print(logging_loss)
            return logging_loss
        # periodically copy weights from Q-network to target Q-network
        self.target_update_idx += 1
        if self.target_update_idx % self.target_update == 0:
            self.target_qnet.copy_from(self.qnet)
        return None
    def train(self, max_episodes, stop_criterion, criterion_episodes):
        # train the agent for a number of episodes
        rewards = []
        num_steps = 0
        
        for episode in range(max_episodes):
            steps=0
            state, _ = env.reset()
            # convert state to torch format
            state = torch.tensor(state, dtype=torch.float)
            terminated = False
            truncated = False
            rewards.append(0)
            while not (terminated or truncated):
                # select action by following behaviour policy
                action = self.behaviour(state)

                # send the action to the environment
                next_state, reward, terminated, truncated, _ = env.step(action)

                # convert next state to torch format and add experience to replay buffer
                next_state = torch.tensor(next_state, dtype=torch.float)
                self.replay_buffer.append((state, action, reward, next_state, terminated))

                # update Q-network
                logging_loss=self.update() #and log loss
                if logging_loss is not None:
                    wandb.log({
                    'episode_num': episode,
                    'loss':logging_loss,
                    'steps': steps,
                    'local reward':reward,

                })

                state = next_state
                rewards[-1] += reward
                num_steps += 1
                steps += 1
                

            print(f'\rEpisode {episode+1} done: steps = {num_steps}, rewards = {rewards[episode]}     ', end='')
            # Log metrics to W&amp;B
            wandb.log({
                    'episode': episode,
                    'total steps':num_steps,
                    'episode_reward': rewards[episode],
                    'epsilon': self.epsilon,
                })

            if episode &gt;= criterion_episodes-1 and stop_criterion(rewards[-criterion_episodes:]):
                print(f'\nStopping criterion satisfied after {episode} episodes')
                break

        
        # plot rewards received during training
        plt.figure(dpi=100)
        plt.plot(range(1, len(rewards)+1), rewards, label=f'Rewards')

        plt.xlabel('Episodes')
        plt.ylabel('Rewards per episode')
        plt.legend(loc='lower right')
        plt.grid()
        plt.show()
    # changed evaluationto a function just to help break it up, also added logging and changed video script as mpy doesnt work for me for some reason
    def evaluate(self, Run):
        state, _ = self.env.reset()
        state = state.flatten()
        terminated = False
        truncated = False
        total_reward = 0
        steps=0
        frames = []

        while not (terminated or truncated): #removed max steps, boxing is timed so it will end after 2 minutes of the game we want to see how the agent goes over the full game

            action = self.policy(state)
            state, reward, terminated, truncated, _ = self.env.step(action)
            total_reward += reward
            steps +=1 
        frame = self.env.render() # Render environment frame and store for video
        v= VideoRecorderRAM('DQN')
        v.frames=frame
        vfilename = f'DQN_Prac_RAM_run_{Run}.mp4'
        v.save(vfilename)
        video_path="DQN/" + vfilename
        # Save video of the evaluation episode
        #video = np.stack(frames)
        #video_path = f"evaluation_episode_{episode_num}.mp4"
        #mpy_clip = mpy.ImageSequenceClip(list(video), fps=30)
        #mpy_clip.write_videofile(video_path, codec="libx264")

        # Log evaluation results and video to W&amp;B
        wandb.log({
            'Evaluation Run': Run,
            'Evaluation Reward': total_reward,
            'Evaluation Video': wandb.Video(video_path, fps=30, format="mp4")
        })

        # Logging evaluation result
        print(f"Evaluation run: {Run} Total Reward = {total_reward}")
        env.close()

    def save(self, path):
        # save network weights to a file
        torch.save(self.qnet.state_dict(), path)

    def load(self, path):
        # load network weights from a file
        self.qnet.load_state_dict(torch.load(path))
        self.target_qnet.copy_from(self.qnet)


agent = AgentDQN(env,gamma=gamma, hidden_sizes=hidden_sizes,learning_rate=learning_rate,epsilon=epsilon,replay_size=replay_size,minibatch_size=minibatch_size,)

#agent.load('acrobot.128x128.DQN.pt')
agent.train(max_episodes, lambda x : min(x) &gt;= 100, criterion_episodes)
for x in range(5):
    agent.evaluate(Run=x)
wandb.finish()
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
<iframe src="https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final/runs/kqjpahr9?jupyter=true" style="border:none;width:100%;height:420px;"></iframe>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Episode 99 done: steps = 176814, rewards = -21.0     </pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>WARNING:py.warnings:/tmp/ipykernel_1537464/255753251.py:155: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown
  plt.show()

</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Episode 100 done: steps = 178600, rewards = -26.0     </pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[54], line 210</span>
<span class="ansi-green-intense-fg ansi-bold">    208</span> agent<span style="color: rgb(98,98,98)">.</span>train(max_episodes, <span class="ansi-bold" style="color: rgb(0,135,0)">lambda</span> x : <span style="color: rgb(0,135,0)">min</span>(x) <span style="color: rgb(98,98,98)">&gt;</span><span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(98,98,98)">100</span>, criterion_episodes)
<span class="ansi-green-intense-fg ansi-bold">    209</span> <span class="ansi-bold" style="color: rgb(0,135,0)">for</span> x <span class="ansi-bold" style="color: rgb(175,0,255)">in</span> <span style="color: rgb(0,135,0)">range</span>(<span style="color: rgb(98,98,98)">5</span>):
<span class="ansi-green-fg">--&gt; 210</span>     agent<span style="color: rgb(98,98,98)">.</span>evaluate(Run<span style="color: rgb(98,98,98)">=</span>x)
<span class="ansi-green-intense-fg ansi-bold">    211</span> wandb<span style="color: rgb(98,98,98)">.</span>finish()

Cell <span class="ansi-green-fg">In[54], line 173</span>, in <span class="ansi-cyan-fg">AgentDQN.evaluate</span><span class="ansi-blue-fg">(self, Run)</span>
<span class="ansi-green-intense-fg ansi-bold">    171</span>     steps <span style="color: rgb(98,98,98)">+</span><span style="color: rgb(98,98,98)">=</span><span style="color: rgb(98,98,98)">1</span> 
<span class="ansi-green-intense-fg ansi-bold">    172</span> frame <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>env<span style="color: rgb(98,98,98)">.</span>render() <span style="color: rgb(95,135,135)"># Render environment frame and store for video</span>
<span class="ansi-green-fg">--&gt; 173</span> v<span style="color: rgb(98,98,98)">=</span> VideoRecorderRAM(<span style="color: rgb(175,0,0)">'</span><span style="color: rgb(175,0,0)">DQN</span><span style="color: rgb(175,0,0)">'</span>)
<span class="ansi-green-intense-fg ansi-bold">    174</span> v<span style="color: rgb(98,98,98)">.</span>frames<span style="color: rgb(98,98,98)">=</span>frame
<span class="ansi-green-intense-fg ansi-bold">    175</span> vfilename <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(175,0,0)">f</span><span style="color: rgb(175,0,0)">'</span><span style="color: rgb(175,0,0)">DQN_Prac_RAM_run_</span><span class="ansi-bold" style="color: rgb(175,95,135)">{</span>Run<span class="ansi-bold" style="color: rgb(175,95,135)">}</span><span style="color: rgb(175,0,0)">.mp4</span><span style="color: rgb(175,0,0)">'</span>

<span class="ansi-red-fg">NameError</span>: name 'VideoRecorderRAM' is not defined</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=7f8c7ad2-63a0-4974-909d-f69452c40b05">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[56]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">agent</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">Run</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
<span class="n">wandb</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Evaluation run: 0 Total Reward = -49.0
Evaluation run: 1 Total Reward = -54.0
Evaluation run: 2 Total Reward = -54.0
Evaluation run: 3 Total Reward = -54.0
Evaluation run: 4 Total Reward = -47.0
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>VBox(children=(Label(value='1.120 MB of 1.120 MB uploaded\r'), FloatProgress(value=1.0, max=1.0)))</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
<style>
    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}
    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }
    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }
    </style>
<div class="wandb-row"><div class="wandb-col"><h3>Run history:</h3><br><table class="wandb"><tr><td>Evaluation Reward</td><td></td></tr><tr><td>Evaluation Run</td><td></td></tr><tr><td>episode</td><td></td></tr><tr><td>episode_num</td><td></td></tr><tr><td>episode_reward</td><td></td></tr><tr><td>epsilon</td><td></td></tr><tr><td>local reward</td><td></td></tr><tr><td>loss</td><td></td></tr><tr><td>steps</td><td></td></tr><tr><td>total steps</td><td></td></tr></table><br/></br></div><div class="wandb-col"><h3>Run summary:</h3><br><table class="wandb"><tr><td>Evaluation Reward</td><td>-47</td></tr><tr><td>Evaluation Run</td><td>4</td></tr><tr><td>episode</td><td>99</td></tr><tr><td>episode_num</td><td>99</td></tr><tr><td>episode_reward</td><td>-26</td></tr><tr><td>epsilon</td><td>0.2</td></tr><tr><td>local reward</td><td>0</td></tr><tr><td>loss</td><td>1.36791</td></tr><tr><td>steps</td><td>1785</td></tr><tr><td>total steps</td><td>178600</td></tr></table><br/></br></div></div>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
 View run <strong style="color:#cdcd00">cosmic-serenity-20</strong> at: <a href="https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final/runs/kqjpahr9" target="_blank">https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final/runs/kqjpahr9</a><br> View project at: <a href="https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final" target="_blank">https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final</a><br>Synced 5 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 5 other file(s)
</br></br></div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
Find logs at: <code>./wandb/run-20241016_183130-kqjpahr9/logs</code>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=cbbce6de-7425-440c-af59-315ffbf1247a">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[57]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">wandb</span><span class="o">.</span><span class="n">finish</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[57]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>&lt;function wandb.sdk.wandb_run.finish(exit_code: Optional[int] = None, quiet: Optional[bool] = None) -&gt; None&gt;</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=9640a652-38bb-4b86-90db-d55aa479d09b">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Make environment and set up logging</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=df785ba8-a341-4f47-9741-b1806826c3dd">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[14]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">agent</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">'Boxing.DQN.prac.agent1.pt'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=c3d85df3-0fab-4bf6-b9f0-f1a5e9d65bc2">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=d3d4d88d-9099-46a1-a01a-646438b23f90">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span><span class="p">,</span> <span class="n">deque</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">imageio</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="c1">#%%writefile SAC_spedup_and_vectorised.py</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">T</span>

<span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="kn">import</span> <span class="nn">moviepy.editor</span> <span class="k">as</span> <span class="nn">mpy</span>
<span class="kn">from</span> <span class="nn">torch.cuda.amp</span> <span class="kn">import</span> <span class="n">autocast</span><span class="p">,</span> <span class="n">GradScaler</span>
<span class="kn">import</span> <span class="nn">wandb</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=998a6ee5-c5c1-44da-bef6-dbd7d0542694">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=92d7675b-777c-4d97-ac4e-5ee21c1f3ac6">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Deep-Q-Network-RAM-Observations">Deep-Q-Network RAM Observations<a class="anchor-link" href="#Deep-Q-Network-RAM-Observations"></a></h4>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=beb86dbd-9607-48cd-a3e6-ef4ff1708d73">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>The original implementation didn seen to be improving throughout the training run. After a lot of testing it believ it was due to the loss function logging resulting in gradients not being updated correctly. Thus the loss logging was removed for V2. The hidden size was also increased and the learning rate was reduced. 2</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=28a26755-ed55-418e-8ce7-ba8cf01d5300">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[63]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span> <span class="c1"># training on GPU</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Using device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">QNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># create network layers</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>

        <span class="c1"># input layer</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>

        <span class="c1"># hidden layers</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>

        <span class="c1"># output layer</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">output_size</span><span class="p">))</span>

        <span class="c1"># combine layers into feed-forward network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

        <span class="c1"># select loss function and optimizer</span>
        <span class="c1"># note: original paper uses modified MSE loss and RMSprop</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># return output of Q-network for the input x</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
        <span class="c1"># update network weights for a minibatch of inputs and targets:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="c1">#return loss Removed returning the loss function for logging </span>

    <span class="k">def</span> <span class="nf">copy_from</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">qnetwork</span><span class="p">):</span>
        <span class="c1"># copy weights from another Q-network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">qnetwork</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Using device: cuda
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=a1765a0c-f55c-4c6a-a56b-f504d41d2124">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[64]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">'ALE/Boxing-v5'</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">"rgb_array_list"</span><span class="p">,</span> <span class="n">obs_type</span><span class="o">=</span><span class="s2">"ram"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">high</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">low</span><span class="p">)</span>

<span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.99</span>
<span class="n">hidden_sizes</span> <span class="o">=</span> <span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.0001</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">replay_size</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">minibatch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">target_update</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">max_episodes</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">max_steps</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">criterion_episodes</span> <span class="o">=</span> <span class="mi">5</span>

<span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">project</span><span class="o">=</span><span class="s1">'DQN-Original-comparison-Final'</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'DQN_V2_2'</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="p">{</span>
    <span class="s1">'gamma'</span><span class="p">:</span> <span class="n">gamma</span><span class="p">,</span>
    <span class="s1">'learning_rate'</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">,</span>
    <span class="s1">'epsilon'</span><span class="p">:</span> <span class="n">epsilon</span><span class="p">,</span>
    <span class="s1">'replay_size'</span><span class="p">:</span> <span class="n">replay_size</span><span class="p">,</span>
    <span class="s1">'minibatch_size'</span><span class="p">:</span> <span class="n">minibatch_size</span><span class="p">,</span>
    <span class="s1">'target_update_freq'</span><span class="p">:</span> <span class="n">target_update</span><span class="p">,</span>
    <span class="s1">'num_episodes'</span><span class="p">:</span> <span class="n">max_episodes</span><span class="p">,</span>
    <span class="s1">'max_steps_per_episode'</span><span class="p">:</span> <span class="n">max_steps</span><span class="p">,</span>
    <span class="s1">'criterion_episodes'</span><span class="p">:</span><span class="n">criterion_episodes</span>
<span class="p">})</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>128
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
Tracking run with wandb version 0.18.3
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
Run data is saved locally in <code>/home/tristan/UniStuff/ReinforcementLearning/Assignment/wandb/run-20241016_203323-rh8p31zj</code>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
Syncing run <strong><a href="https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final/runs/rh8p31zj" target="_blank">DQN_V2_2</a></strong> to <a href="https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final" target="_blank">Weights &amp; Biases</a> (<a href="https://wandb.me/run" target="_blank">docs</a>)<br>
</br></div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
 View project at <a href="https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final" target="_blank">https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final</a>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
 View run at <a href="https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final/runs/rh8p31zj" target="_blank">https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final/runs/rh8p31zj</a>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[64]:</div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html" tabindex="0">
<button onclick="this.nextSibling.style.display='block';this.style.display='none';">Display W&amp;B run</button><iframe src="https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final/runs/rh8p31zj?jupyter=true" style="border:none;width:100%;height:420px;display:none;"></iframe>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=cd62b4cc-c4cf-4deb-b32e-d4633ba8b12e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[65]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">wandb</span>
###########################################################################################################################################################################################################
class V2AgentDQN():
    def __init__(self, env, gamma,
                 hidden_sizes=(128, 128,128), #Increased Depth and size
                 learning_rate=0.0001, #decrease learning rate
                 epsilon=0.2, #increased epsilon
                 replay_size=10000,
                 minibatch_size=64, #increase batch size
                 target_update=20):
        # check if the state space has correct type
        continuous = isinstance(env.observation_space, spaces.Box) and len(env.observation_space.shape) == 1
        assert continuous, 'Observation space must be continuous with shape (n,)'
        self.state_dims = env.observation_space.shape[0]

        # check if the action space has correct type
        assert isinstance(env.action_space, spaces.Discrete), 'Action space must be discrete'
        self.num_actions = env.action_space.n

        # create Q-networks for action-value function
        self.qnet = QNetwork(self.state_dims, hidden_sizes, self.num_actions, learning_rate)
        self.target_qnet = QNetwork(self.state_dims, hidden_sizes, self.num_actions, learning_rate)

        # copy weights from Q-network to target Q-network
        self.target_qnet.copy_from(self.qnet)

        # initialise replay buffer
        self.replay_buffer = deque(maxlen=replay_size)

        self.env = env
        self.gamma = gamma
        self.epsilon = epsilon
        self.minibatch_size = minibatch_size
        self.target_update = target_update
        self.target_update_idx = 0
###########################################################################################################################################################################################################
    def behaviour(self, state):
        # exploratory behaviour policy
        if rng.uniform() &gt;= self.epsilon:
            # convert state to torch format
            if not torch.is_tensor(state):
                state = torch.tensor(state, dtype=torch.float)

            # exploitation with probability 1-epsilon; break ties randomly
            q = self.qnet(state).detach()
            j = rng.permutation(self.num_actions)
            return j[q[j].argmax().item()]
        else:
            # exploration with probability epsilon
            return self.env.action_space.sample()
###########################################################################################################################################################################################################
    def policy(self, state):
        # convert state to torch format
        if not torch.is_tensor(state):
            state = torch.tensor(state, dtype=torch.float)

        # greedy policy
        q = self.qnet(state).detach()
        return q.argmax().item()
###########################################################################################################################################################################################################
    def update(self):
        # update Q-network if there is enough experience
        if len(self.replay_buffer) &gt;= self.minibatch_size:
            # select mini-batch of experiences uniformly at random without replacement                                
            batch = rng.choice(len(self.replay_buffer), size=self.minibatch_size, replace=False)

            # calculate inputs and targets for the transitions in the mini-batch
            inputs = torch.zeros((self.minibatch_size, self.state_dims))
            targets = torch.zeros((self.minibatch_size, self.num_actions))

            for n, index in enumerate(batch):
                state, action, reward, next_state, terminated = self.replay_buffer[index]
                # inputs are states
                inputs[n, :] = state

                # targets are TD targets
                targets[n, :] = self.target_qnet(state).detach()

                if terminated:
                    targets[n, action] = reward
                else:
                    targets[n, action] = reward + self.gamma*self.target_qnet(next_state).detach().max()
            
                        # train Q-network on the mini-batch
            self.qnet.update(inputs, targets)
            #logging_loss=
            #print(logging_loss)
            #return logging_loss

        # periodically copy weights from Q-network to target Q-network
        self.target_update_idx += 1
        if self.target_update_idx % self.target_update == 0:
            self.target_qnet.copy_from(self.qnet)
        #return None
###########################################################################################################################################################################################################    
    def train(self, max_episodes, stop_criterion, criterion_episodes):
                # train the agent for a number of episodes
        rewards = []
        num_steps = 0
        
        for episode in range(max_episodes):
            steps=0
            state, _ = env.reset()
            # convert state to torch format
            state = torch.tensor(state, dtype=torch.float)
            terminated = False
            truncated = False
            rewards.append(0)
            while not (terminated or truncated):
                # select action by following behaviour policy
                action = self.behaviour(state)

                # send the action to the environment
                next_state, reward, terminated, truncated, _ = env.step(action)

                # convert next state to torch format and add experience to replay buffer
                next_state = torch.tensor(next_state, dtype=torch.float)
                self.replay_buffer.append((state, action, reward, next_state, terminated))
                self.update() 
                # update Q-network
                #logging_loss=#and log loss
                '''if logging_loss is not None:
                    wandb.log({
                    'episode_num': episode,
                    'loss':logging_loss,
                    'steps': steps,
                    'local reward':reward,
                })'''
                state = next_state
                rewards[-1] += reward
                num_steps += 1
                steps += 1

            print(f'\rEpisode {episode+1} done: steps = {num_steps}, rewards = {rewards[episode]}     ', end='')
            # Log metrics to W&amp;B
            wandb.log({
                    'episode': episode,
                    'total steps':num_steps,
                    'episode_reward': rewards[episode],
                    'epsilon': self.epsilon,
                })

            if episode &gt;= criterion_episodes-1 and stop_criterion(rewards[-criterion_episodes:]):
                print(f'\nStopping criterion satisfied after {episode} episodes')
                break
###############################################################################################################################################################################################################
     # changed evaluationto a function just to help break it up, also added logging and changed video script as mpy doesnt work for me for some reason
    def evaluate(self, Run):
        state, _ = self.env.reset()
        state = state.flatten()
        terminated = False
        truncated = False
        total_reward = 0
        steps=0
        frames = []

        while not (terminated or truncated): #removed max steps, boxing is timed so it will end after 2 minutes of the game we want to see how the agent goes over the full game

            action = self.policy(state)
            state, reward, terminated, truncated, _ = self.env.step(action)
            total_reward += reward
            steps +=1 
        frame = self.env.render() # Render environment frame and store for video
        v= VideoRecorderRAM('DQN')
        v.frames=frame
        vfilename = f'DQN_Prac_RAMV2_run_{Run}.mp4'
        v.save(vfilename)
        video_path="DQN/" + vfilename
        # Save video of the evaluation episode
        #video = np.stack(frames)
        #video_path = f"evaluation_episode_{episode_num}.mp4"
        #mpy_clip = mpy.ImageSequenceClip(list(video), fps=30)
        #mpy_clip.write_videofile(video_path, codec="libx264")

        # Log evaluation results and video to W&amp;B
        wandb.log({
            'Evaluation Run': Run,
            'Evaluation Reward': total_reward,
            'Evaluation Video': wandb.Video(video_path, fps=30, format="mp4")
        })

        # Logging evaluation result
        print(f"Evaluation run: {Run} Total Reward = {total_reward}")
        env.close()
###########################################################################################################################################################################################################
    def save(self, path):
        # save network weights to a file
        torch.save(self.qnet.state_dict(), path)
###########################################################################################################################################################################################################
    def load(self, path):
        # load network weights from a file
        self.qnet.load_state_dict(torch.load(path))
        self.target_qnet.copy_from(self.qnet)
###########################################################################################################################################################################################################




#Initialize, train and evaluate


agent = V2AgentDQN(env,
                 gamma=gamma,
                 hidden_sizes=hidden_sizes,
                 learning_rate=learning_rate,
                 epsilon=epsilon,
                 replay_size=replay_size,
                 minibatch_size=minibatch_size,
                 target_update=target_update)



#agent.load('acrobot.128x128.DQN.pt')

agent.train(max_episodes, lambda x : min(x) &gt;= 100, criterion_episodes)
for x in range(5):
    agent.evaluate(Run=x)
wandb.finish()
# create and play video clip using the frames and given fps
#clip = mpy.ImageSequenceClip(frames, fps=15)
#clip.ipython_display(rd_kwargs=dict(logger=None))
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
<iframe src="https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final/runs/rh8p31zj?jupyter=true" style="border:none;width:100%;height:420px;"></iframe>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Episode 100 done: steps = 178600, rewards = -21.0     Evaluation run: 0 Total Reward = 2.0
Evaluation run: 1 Total Reward = 14.0
Evaluation run: 2 Total Reward = 3.0
Evaluation run: 3 Total Reward = 2.0
Evaluation run: 4 Total Reward = 4.0
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>VBox(children=(Label(value='1.208 MB of 1.208 MB uploaded\r'), FloatProgress(value=1.0, max=1.0)))</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
<style>
    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}
    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }
    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }
    </style>
<div class="wandb-row"><div class="wandb-col"><h3>Run history:</h3><br><table class="wandb"><tr><td>Evaluation Reward</td><td></td></tr><tr><td>Evaluation Run</td><td></td></tr><tr><td>episode</td><td></td></tr><tr><td>episode_reward</td><td></td></tr><tr><td>epsilon</td><td></td></tr><tr><td>total steps</td><td></td></tr></table><br/></br></div><div class="wandb-col"><h3>Run summary:</h3><br><table class="wandb"><tr><td>Evaluation Reward</td><td>4</td></tr><tr><td>Evaluation Run</td><td>4</td></tr><tr><td>episode</td><td>99</td></tr><tr><td>episode_reward</td><td>-21</td></tr><tr><td>epsilon</td><td>0.2</td></tr><tr><td>total steps</td><td>178600</td></tr></table><br/></br></div></div>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
 View run <strong style="color:#cdcd00">DQN_V2_2</strong> at: <a href="https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final/runs/rh8p31zj" target="_blank">https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final/runs/rh8p31zj</a><br> View project at: <a href="https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final" target="_blank">https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final</a><br>Synced 5 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 5 other file(s)
</br></br></div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
Find logs at: <code>./wandb/run-20241016_203323-rh8p31zj/logs</code>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=4a7bc6c5-492b-4859-8fa9-b05d0e965d00">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[30]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">agent</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">'Boxing.DQN.prac.agent2.pt'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=2424cd68-49b5-4255-9810-9c7a9a591043">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Successful runs in evaluation !! When comparing DQN_V2 and DQN_V2_2 the only difference is the logging of the loss. Thus, it removing it allowed the agent to learn effectively. The comparison can be seen below.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=25dae47a-3087-499c-a6b5-9082ce20e25f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[69]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">wandb</span> tristancarlisle/DQN-Original-comparison-Final/reports/Loss-logging-impact--Vmlldzo5NzQzMjEy
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
<iframe src="https://wandb.ai/tristancarlisle/DQN-Original-comparison-Final/reports/Loss-logging-impact--Vmlldzo5NzQzMjEy?jupyter=true" style="border:none;width:100%;height:420px;"></iframe>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=1d6a8f31-7fba-471d-b58c-4e74610171a3">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Deep-Q-Network-Image-Observations">Deep-Q-Network Image Observations<a class="anchor-link" href="#Deep-Q-Network-Image-Observations"></a></h4>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=c60c9d3c-f79f-4ed2-9b75-1d0555fbb148">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>First iteration of improvements:
instead of ram implementation going to try grayscale then reduce image size 
add warm up steps
add epsilon decay
change Q Network to utilise images 
Frame stack to try and learn temporal information
Skip frames 
Normalise frame values for</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=ad443a85-81ae-40d8-b819-d5dc2e48baf9">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="Q-Network">Q Network<a class="anchor-link" href="#Q-Network"></a></h5><ul>
<li>Adapted to images and frame staking, hence the use of 2D convolutions. greyscale is a 2D array stack them and you have a 3D array.</li>
</ul>
<div class="highlight"><pre><span></span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span>
</pre></div>
<ul>
<li>Also added in warm up steps</li>
</ul>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">warmup</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</pre></div>
<ul>
<li>epsilon decay</li>
</ul>
<div class="highlight"><pre><span></span><span class="n">epsilon_threshold</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_end</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">epsilon_start</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_end</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">1.</span> <span class="o">*</span> <span class="n">num_steps</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_decay</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=85e5d40d-cdcf-49f2-b51b-ad9d251083ef">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[71]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span> <span class="c1"># training on GPU</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Using device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">QNetworkImage</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># create network layers</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>

        <span class="c1"># input layer</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>

        <span class="c1">#Layer2</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>

        <span class="c1">#Layer3</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>

        <span class="c1">#flatten for linear layes</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    
        <span class="c1"># output layer</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3136</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span> <span class="c1">#input size =64*7*7 =            </span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">output_size</span><span class="p">))</span>

        <span class="c1"># combine layers into feed-forward network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

        <span class="c1"># select loss function and optimizer</span>
        <span class="c1"># note: original paper uses modified MSE loss and RMSprop</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># return output of Q-network for the input x</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
        <span class="c1"># update network weights for a minibatch of inputs and targets:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">copy_from</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">qnetwork</span><span class="p">):</span>
        <span class="c1"># copy weights from another Q-network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">qnetwork</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Using device: cuda
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=caebe49d-2a21-452f-92f1-ec11cbe88613">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[72]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">'ALE/Boxing-v5'</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">"rgb_array"</span><span class="p">,</span><span class="n">obs_type</span><span class="o">=</span><span class="s2">"grayscale"</span><span class="p">)</span> <span class="c1"># use grayscale images</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">wrappers</span><span class="o">.</span><span class="n">ResizeObservation</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="mi">84</span><span class="p">))</span>    <span class="c1"># Resize to 84x84 Gym inbuilt wrappers</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">wrappers</span><span class="o">.</span><span class="n">NormalizeObservation</span><span class="p">(</span><span class="n">env</span><span class="p">)</span> <span class="c1">#Normalize </span>

<span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.99</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.0001</span>
<span class="n">max_episodes</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">max_steps</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">criterion_episodes</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">epsilon_start</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="c1">#added epsilon start point</span>
<span class="n">epsilon_end</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="c1">#added epsilon endpoint</span>
<span class="n">epsilon_decay</span><span class="o">=</span><span class="mi">50000</span><span class="p">,</span> <span class="c1">#added epsilon decay</span>
<span class="n">warmupsteps</span><span class="o">=</span><span class="mi">1000</span> <span class="c1">#added warmupsteps</span>
<span class="n">replay_size</span><span class="o">=</span><span class="mi">10000</span>
<span class="n">minibatch_size</span><span class="o">=</span><span class="mi">32</span>
<span class="n">target_update</span><span class="o">=</span><span class="mi">20</span>

<span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">project</span><span class="o">=</span><span class="s1">'DQN_Image'</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'DQN_Image'</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="p">{</span>
    <span class="s1">'gamma'</span><span class="p">:</span> <span class="n">gamma</span><span class="p">,</span>
    <span class="s1">'learning_rate'</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">,</span>
    <span class="s1">'epsilon start'</span><span class="p">:</span> <span class="n">epsilon_start</span><span class="p">,</span>
    <span class="s1">'epsilon end'</span><span class="p">:</span> <span class="n">epsilon_end</span><span class="p">,</span>
    <span class="s1">'epsilon decay'</span><span class="p">:</span> <span class="n">epsilon_decay</span><span class="p">,</span>
    <span class="s1">'replay_size'</span><span class="p">:</span> <span class="n">replay_size</span><span class="p">,</span>
    <span class="s1">'minibatch_size'</span><span class="p">:</span> <span class="n">minibatch_size</span><span class="p">,</span>
    <span class="s1">'target_update_freq'</span><span class="p">:</span> <span class="n">target_update</span><span class="p">,</span>
    <span class="s1">'num_episodes'</span><span class="p">:</span> <span class="n">max_episodes</span><span class="p">,</span>
    <span class="s1">'max_steps_per_episode'</span><span class="p">:</span> <span class="n">max_steps</span><span class="p">,</span>
    <span class="s1">'criterion_episodes'</span><span class="p">:</span><span class="n">criterion_episodes</span>
<span class="p">})</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
Tracking run with wandb version 0.18.3
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
Run data is saved locally in <code>/home/tristan/UniStuff/ReinforcementLearning/Assignment/wandb/run-20241016_224154-8yabz8ol</code>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
Syncing run <strong><a href="https://wandb.ai/tristancarlisle/DQN_Image/runs/8yabz8ol" target="_blank">DQN_Image</a></strong> to <a href="https://wandb.ai/tristancarlisle/DQN_Image" target="_blank">Weights &amp; Biases</a> (<a href="https://wandb.me/run" target="_blank">docs</a>)<br/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
 View project at <a href="https://wandb.ai/tristancarlisle/DQN_Image" target="_blank">https://wandb.ai/tristancarlisle/DQN_Image</a>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
 View run at <a href="https://wandb.ai/tristancarlisle/DQN_Image/runs/8yabz8ol" target="_blank">https://wandb.ai/tristancarlisle/DQN_Image/runs/8yabz8ol</a>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[72]:</div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html" tabindex="0">
<button onclick="this.nextSibling.style.display='block';this.style.display='none';">Display W&amp;B run</button><iframe src="https://wandb.ai/tristancarlisle/DQN_Image/runs/8yabz8ol?jupyter=true" style="border:none;width:100%;height:420px;display:none;"></iframe>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=6db02575-8575-467d-901c-edc85f85acb4">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">Agent</span> <span class="k">class</span> <span class="nc">set</span> <span class="n">up</span> <span class="n">initialise</span> <span class="ow">and</span> <span class="n">run</span> <span class="n">train</span> <span class="ow">and</span> <span class="n">evaluation</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=7321e4c0-6baf-45df-89e0-e3d332f1ae67">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[95]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">wandb</span>
class AgentDQNImage():
    def __init__(self, env, gamma,
                 #hidden_sizes=(128, 128,128), #Increased Depth and size
                 learning_rate=0.0001, #decrease learning rate
                 epsilon_start=1, #added epsilon start point
                 epsilon_end=0.05, #added epsilon endpoint
                 epsilon_decay=50000, #added epsilon decay
                 warmupsteps=1000, #added warmupsteps
                 replay_size=10000,
                 minibatch_size=32,
                 target_update=20):
        # check if the state space has correct type
        #continuous = isinstance(env.observation_space, spaces.Box) and len(env.observation_space.shape) == 1  removed as using an image now 
        #assert continuous, 'Observation space must be continuous with shape (n,)'
        self.state_dims = env.observation_space.shape[0]

        # check if the action space has correct type
        assert isinstance(env.action_space, spaces.Discrete), 'Action space must be discrete'
        self.num_actions = env.action_space.n

        # create Q-networks for action-value function
        self.qnet = QNetworkImage(self.state_dims,self.num_actions, learning_rate).to(device) #moved to GPU
        self.target_qnet = QNetworkImage(self.state_dims,self.num_actions, learning_rate).to(device)#moved to GPU

        # copy weights from Q-network to target Q-network
        self.target_qnet.copy_from(self.qnet)

        # initialise replay buffer
        self.replay_buffer = deque(maxlen=replay_size)

        self.env = env
        self.gamma = gamma
        self.epsilon_start = epsilon_start
        self.epsilon_end= epsilon_end
        self.epsilon_decay = epsilon_decay
        self.minibatch_size = minibatch_size
        self.target_update = target_update
        self.target_update_idx = 0
        self.warmupsteps=warmupsteps
###############################################################################################################################################################################################################
    def behaviour(self, state, num_steps): 
        #set  epsilon threshold to global variable to keep track
        global epsilon_threshold
        # exploratory behaviour policy
        epsilon_threshold = self.epsilon_end[0] + (self.epsilon_start[0] - self.epsilon_end[0]) * math.exp(-1. * num_steps / self.epsilon_decay[0]) #epsilon value calculation for incorporation of decay

        if rng.uniform() &gt;= epsilon_threshold:
            if not torch.is_tensor(state):
                state = torch.tensor(state, dtype=torch.float).to(device)

            # exploitation with probability 1-epsilon; break ties randomly
            q = self.qnet(state).detach()
            action = q.argmax().item() #changed to take the highest q value 
            return torch.tensor([[action]], dtype=torch.long).to(device) #changed for usage on GPU
        else:
            # exploration with probability epsilon
            return torch.tensor([[self.env.action_space.sample()]], dtype=torch.long).to(device) #changed to usage on GPU
###############################################################################################################################################################################################################
    def policy(self, state):
        # convert state to torch format
        if not torch.is_tensor(state):
            state = torch.tensor(state, dtype=torch.float)

        # greedy policy
        q = self.qnet(state).detach()
        return q.argmax().item()
###############################################################################################################################################################################################################
    def update(self):
        # update Q-network if there is enough experience
        if len(self.replay_buffer) &gt;= self.minibatch_size:
            # select mini-batch of experiences uniformly at random without replacement                                
            batch = rng.choice(len(self.replay_buffer), size=self.minibatch_size, replace=False)

            # calculate inputs and targets for the transitions in the mini-batch
            inputs = torch.zeros((self.minibatch_size, 4, 84, 84), device=device)
            targets = torch.zeros((self.minibatch_size, self.num_actions), device=device)

            for n, index in enumerate(batch):
                state, action, reward, next_state, terminated = self.replay_buffer[index]
                inputs[n] = state.squeeze(0) # had to change to account for frame stacking removes batch dimension

                # targets are TD targets
                targets[n, :] = self.target_qnet(state).detach()

                if terminated:
                    targets[n, action] = reward
                else:
                    targets[n, action] = reward + self.gamma*self.target_qnet(next_state).detach().max()
            
            # train Q-network on the mini-batch
            self.qnet.update(inputs, targets)

        # periodically copy weights from Q-network to target Q-network
        self.target_update_idx += 1
        if self.target_update_idx % self.target_update == 0:
            self.target_qnet.copy_from(self.qnet)
###############################################################################################################################################################################################################
    def warmup(self):
            print('Warming up')
            warmupstep = 0
            # Warmup loop
            while warmupstep &lt; self.warmupsteps:
                state, _ = self.env.reset()
                state = torch.tensor(state, dtype=torch.float32).to(device)
                state = torch.stack((state,state,state,state)).unsqueeze(0) #(1,4,84,84)
                terminated = False
                truncated = False
                while not (terminated or truncated):
                    action = torch.tensor([[self.env.action_space.sample()]]).to(device)# Random action selection during warm-up
                    # Step in environment
                    next_state, reward, terminated, truncated, _ = self.env.step(action.item())
                    next_state = torch.tensor(next_state, dtype=torch.float32).to(device)
                    next_state = torch.stack((next_state,state[0][0],state[0][1],state[0][2])).unsqueeze(0)
                    reward = torch.tensor([reward], device=device)
                    term = torch.tensor([terminated or truncated], device=device)
                    self.replay_buffer.append((state, action, reward, next_state, term))# Store the transition in memory
                    state = next_state
                    warmupstep += 1
                    if warmupstep &gt;= self.warmupsteps:
                        break
    
            print(f'Warm-up finito: {self.warmupsteps} steps stored.')
###############################################################################################################################################################################################################    
    def train(self, max_episodes, stop_criterion, criterion_episodes):
        # train the agent for a number of episodes
        rewards = []
        num_steps = 0
        for episode in range(max_episodes):
            state, _ = env.reset()
            # convert state to torch format
            state = torch.tensor(state, dtype=torch.float32).to(device)
            state = torch.stack((state,state,state,state)).unsqueeze(0) #(1,4,84,84)
            terminated = False
            truncated = False
            rewards.append(0)
            while not (terminated or truncated):
                # select action by following behaviour policy
                action = self.behaviour(state , num_steps).to(device)

                # send the action to the environment
                next_state, reward, terminated, truncated, _ = env.step(action)

                # convert next state to torch format and add experience to replay buffer
                next_state = torch.tensor(next_state, dtype=torch.float32).to(device)
                next_state = torch.stack((next_state,state[0][0],state[0][1],state[0][2])).unsqueeze(0)
                reward=torch.tensor(reward, dtype=torch.float).to(device)
                term = torch.tensor([terminated or  truncated], device=device)
                self.replay_buffer.append((state, action, reward, next_state, term))
                
                # update Q-network
                self.update()

                state = next_state
                rewards[-1] += reward
                num_steps += 1

                #all to tensors
                
                
            print(f'\rEpisode {episode+1} done: steps = {num_steps}, rewards = {rewards[episode]}     ', end='')

            if episode &gt;= criterion_episodes-1 and stop_criterion(rewards[-criterion_episodes:]):
                print(f'\nStopping criterion satisfied after {episode} episodes')
                break

        # Log metrics to W&amp;B
            wandb.log({
                    'episode': episode,
                    'episode_reward': rewards[episode],
                    'epsilon threshold': epsilon_threshold,
                    'steps': num_steps,
                })

        # plot rewards received during training
        #plt.figure(dpi=100)
        #plt.plot(range(1, len(rewards)+1), rewards, label=f'Rewards')

        #plt.xlabel('Episodes')
        #plt.ylabel('Rewards per episode')
        #plt.legend(loc='lower right')
        #plt.grid()
        #plt.show()
###############################################################################################################################################################################################################
    def evaluate(self, Run):
        state, _ = self.env.reset()
        terminated = False
        truncated = False
        total_reward = 0
        steps=0
        frames=[]
        while not (terminated or truncated or steps &gt; max_steps*2):
            # take action based on policy
            
            state = torch.tensor(state, dtype=torch.float32).to(device)
            state = torch.stack((state,state,state,state)).unsqueeze(0) #(1,4,84,84)
            action = agent.policy(state)
        
            # environment receives the action and returns:
            # next observation, reward, terminated, truncated, and additional information (if applicable)
            state, reward, terminated, truncated, info = env.step(action)
            total_reward += reward
            steps += 1
            frame = env.render()
            frames.append(frame)
        print(f'Reward: {total_reward}')
        v= VideoRecorder('DQN') # None ram version of videorecorder
        for frame in frames:
            v.record(frame)
        vfilename = f'DQN__Image_run_{Run}.mp4'
        v.save(vfilename)
        video_path="DQN/" + vfilename
        # Save video of the evaluation episode
        #video = np.stack(frames)
        #video_path = f"evaluation_episode_{episode_num}.mp4"
        #mpy_clip = mpy.ImageSequenceClip(list(video), fps=30)
        #mpy_clip.write_videofile(video_path, codec="libx264")

        # Log evaluation results and video to W&amp;B
        wandb.log({
            'Evaluation Run': Run,
            'Evaluation Reward': total_reward,
            'Evaluation Video': wandb.Video(video_path, fps=30, format="mp4")
        })

        # Logging evaluation result
        print(f"Evaluation run: {Run} Total Reward = {total_reward}")
        env.close()
###############################################################################################################################################################################################################       
    def save(self, path):
        # save network weights to a file
        torch.save(self.qnet.state_dict(), path)
###############################################################################################################################################################################################################
    def load(self, path):
        # load network weights from a file
        self.qnet.load_state_dict(torch.load(path))
        self.target_qnet.copy_from(self.qnet)

###############################################################################################################################################################################################################

#initialise Agent
agent = AgentDQNImage(env,
                 gamma=gamma,
                 learning_rate=learning_rate,
                 replay_size=replay_size,
                 epsilon_start=epsilon_start,
                 epsilon_end=epsilon_end,
                 epsilon_decay=epsilon_decay,
                 minibatch_size=minibatch_size,
                 target_update=target_update)


#train 
#agent.train(max_episodes, lambda x : min(x) &gt;= 100, criterion_episodes)

#evaluate
for x in range(5):
    agent.evaluate(Run=x)
wandb.finish()

#agent.load('acrobot.128x128.DQN.pt')
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
<iframe src="https://wandb.ai/tristancarlisle/DQN_Image/runs/8yabz8ol?jupyter=true" style="border:none;width:100%;height:420px;"></iframe>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>WARNING:py.warnings:/home/tristan/miniconda3/envs/ReinforcementLearning/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:335: UserWarning: <span class="ansi-yellow-fg">WARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.</span>
  logger.warn(

</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Reward: -3.0
Evaluation run: 0 Total Reward = -3.0
Reward: 3.0
Evaluation run: 1 Total Reward = 3.0
Reward: 1.0
Evaluation run: 2 Total Reward = 1.0
Reward: -3.0
Evaluation run: 3 Total Reward = -3.0
Reward: 2.0
Evaluation run: 4 Total Reward = 2.0
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>VBox(children=(Label(value='0.872 MB of 0.872 MB uploaded\r'), FloatProgress(value=1.0, max=1.0)))</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
<style>
    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}
    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }
    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }
    </style>
<div class="wandb-row"><div class="wandb-col"><h3>Run history:</h3><br/><table class="wandb"><tr><td>Evaluation Reward</td><td></td></tr><tr><td>Evaluation Run</td><td></td></tr><tr><td>episode</td><td></td></tr><tr><td>episode_reward</td><td></td></tr><tr><td>epsilon threshold</td><td></td></tr><tr><td>steps</td><td></td></tr></table><br/></div><div class="wandb-col"><h3>Run summary:</h3><br/><table class="wandb"><tr><td>Evaluation Reward</td><td>2</td></tr><tr><td>Evaluation Run</td><td>4</td></tr><tr><td>episode</td><td>99</td></tr><tr><td>episode_reward</td><td>-12</td></tr><tr><td>epsilon threshold</td><td>0.0767</td></tr><tr><td>steps</td><td>178600</td></tr></table><br/></div></div>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
 View run <strong style="color:#cdcd00">DQN_Image</strong> at: <a href="https://wandb.ai/tristancarlisle/DQN_Image/runs/8yabz8ol" target="_blank">https://wandb.ai/tristancarlisle/DQN_Image/runs/8yabz8ol</a><br/> View project at: <a href="https://wandb.ai/tristancarlisle/DQN_Image" target="_blank">https://wandb.ai/tristancarlisle/DQN_Image</a><br/>Synced 5 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 5 other file(s)
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
Find logs at: <code>./wandb/run-20241016_224154-8yabz8ol/logs</code>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=769fc9a5-3b5b-4758-96d5-9c7a7c09633c">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[78]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">agent</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">'Boxing.DQN.Image.pt'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=872931e1-ba0d-4dfe-aff6-ad95ffeb425e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Hyperparameter-Sweep-Deep-Q-Network-(RAM)">Hyperparameter Sweep Deep-Q-Network (RAM)<a class="anchor-link" href="#Hyperparameter-Sweep-Deep-Q-Network-(RAM)"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=2affd07c-26a3-4f7c-b027-6c09a188c184">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">Param</span> <span class="n">sweep</span> <span class="n">on</span> <span class="n">it</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=42b6af7d-294a-4132-9b24-3592a14959db">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Using device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Set random seeds for reproducibility</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="c1"># Define the Q-Network</span>
<span class="k">class</span> <span class="nc">QNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Create network layers</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>

        <span class="c1"># Input layer</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>

        <span class="c1"># Hidden layers</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>

        <span class="c1"># Output layer</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">output_size</span><span class="p">))</span>

        <span class="c1"># Combine layers into a feed-forward network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

        <span class="c1"># Select loss function and optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Return output of Q-network for the input x</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
        <span class="c1"># Update network weights for a minibatch of inputs and targets</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">copy_from</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">qnetwork</span><span class="p">):</span>
        <span class="c1"># Copy weights from another Q-network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">qnetwork</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=9a556f38-9f06-4d84-95d3-4bd25224259c">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Deep Q-Network (DQN) Agent</span>
<span class="k">class</span> <span class="nc">AgentDQN</span><span class="p">():</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="c1"># Check if the state space has the correct type</span>
        <span class="n">continuous</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">,</span> <span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="n">continuous</span><span class="p">,</span> <span class="s1">'Observation space must be continuous with shape (n,)'</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Check if the action space has the correct type</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span> <span class="n">spaces</span><span class="o">.</span><span class="n">Discrete</span><span class="p">),</span> <span class="s1">'Action space must be discrete'</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span>

        <span class="c1"># Parse hidden_sizes from string to tuple</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_sizes</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">hidden_sizes</span> <span class="o">=</span> <span class="n">ast</span><span class="o">.</span><span class="n">literal_eval</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_sizes</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">hidden_sizes</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_sizes</span>

        <span class="c1"># Create Q-networks for action-value function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qnet</span> <span class="o">=</span> <span class="n">QNetwork</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_qnet</span> <span class="o">=</span> <span class="n">QNetwork</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Copy weights from Q-network to target Q-network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_qnet</span><span class="o">.</span><span class="n">copy_from</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="p">)</span>

        <span class="c1"># Initialize replay buffer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">replay_size</span><span class="p">)</span>

        <span class="c1"># Initialize hyperparameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">env</span> <span class="o">=</span> <span class="n">env</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">minibatch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_update</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">target_update</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_update_idx</span> <span class="o">=</span> <span class="mi">0</span>
<span class="c1">###############################################################################################################################################################################################################</span>
    <span class="k">def</span> <span class="nf">behaviour</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="c1"># Exploratory behaviour policy</span>
        <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">:</span>
            <span class="c1"># Convert state to torch format</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># Exploitation: select the action with highest Q-value</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">q_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">q_values</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Exploration: select a random action</span>
            <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">action</span>
<span class="c1">###############################################################################################################################################################################################################</span>
    <span class="k">def</span> <span class="nf">policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="c1"># Greedy policy: select the action with highest Q-value</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">q_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">q_values</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">action</span>
<span class="c1">###############################################################################################################################################################################################################</span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Update Q-network if there is enough experience</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">:</span>
            <span class="c1"># Sample a minibatch of experiences uniformly at random</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">)</span>

            <span class="c1"># Extract components of the batch</span>
            <span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">next_states</span><span class="p">,</span> <span class="n">terminateds</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">batch</span><span class="p">)</span>

            <span class="c1"># Convert to tensors</span>
            <span class="n">states</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">states</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Shape: (batch_size, state_dims)</span>
            <span class="n">actions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Shape: (batch_size, 1)</span>
            <span class="n">rewards</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">rewards</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Shape: (batch_size, 1)</span>
            <span class="n">next_states</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">next_states</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Shape: (batch_size, state_dims)</span>
            <span class="n">terminateds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">terminateds</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Shape: (batch_size, 1)</span>

            <span class="c1"># Compute current Q-values</span>
            <span class="n">current_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="p">(</span><span class="n">states</span><span class="p">)</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">actions</span><span class="p">)</span>  <span class="c1"># Shape: (batch_size, 1)</span>

            <span class="c1"># Compute target Q-values</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">max_next_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_qnet</span><span class="p">(</span><span class="n">next_states</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Shape: (batch_size, 1)</span>
                <span class="n">target_q</span> <span class="o">=</span> <span class="n">rewards</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">terminateds</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">max_next_q</span>  <span class="c1"># Shape: (batch_size, 1)</span>

            <span class="c1"># Update Q-network</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">target_q</span><span class="p">)</span>

        <span class="c1"># Periodically copy weights from Q-network to target Q-network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_update_idx</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_update_idx</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_update</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">target_qnet</span><span class="o">.</span><span class="n">copy_from</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="p">)</span>
<span class="c1">###############################################################################################################################################################################################################</span>
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_episodes</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="p">,</span> <span class="n">criterion_episodes</span><span class="p">):</span>
        <span class="c1"># Train the agent for a number of episodes</span>
        <span class="n">rewards</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_episodes</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
            <span class="n">terminated</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">truncated</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">episode_reward</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">while</span> <span class="ow">not</span> <span class="p">(</span><span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">):</span>
                <span class="c1"># Select action by following behaviour policy</span>
                <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">behaviour</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

                <span class="c1"># Send the action to the environment</span>
                <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

                <span class="c1"># Convert states to torch tensors</span>
                <span class="n">state_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">next_state_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">next_state</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

                <span class="c1"># Add experience to replay buffer</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">state_tensor</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state_tensor</span><span class="p">,</span> <span class="n">terminated</span><span class="p">))</span>

                <span class="c1"># Update Q-network</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>

                <span class="c1"># Update state and cumulative reward</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
                <span class="n">episode_reward</span> <span class="o">+=</span> <span class="n">reward</span>

            <span class="c1"># Append the reward for this episode</span>
            <span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">episode_reward</span><span class="p">)</span>

            <span class="c1"># Log metrics to W&amp;B</span>
            <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">({</span>
                <span class="s1">'episode'</span><span class="p">:</span> <span class="n">episode</span><span class="p">,</span>
                <span class="s1">'episode_reward'</span><span class="p">:</span> <span class="n">episode_reward</span><span class="p">,</span>
                <span class="s1">'epsilon'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">,</span>
                <span class="s1">'steps'</span><span class="p">:</span> <span class="n">episode</span>  <span class="c1"># Alternatively, track actual steps if desired</span>
            <span class="p">})</span>

            <span class="c1"># Print progress</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Episode </span><span class="si">{</span><span class="n">episode</span><span class="si">}</span><span class="s2">: Reward = </span><span class="si">{</span><span class="n">episode_reward</span><span class="si">}</span><span class="s2">, Total Steps = </span><span class="si">{</span><span class="n">episode</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

            <span class="c1"># Check stopping criterion</span>
            <span class="k">if</span> <span class="n">episode</span> <span class="o">&gt;=</span> <span class="n">criterion_episodes</span> <span class="ow">and</span> <span class="n">stop_criterion</span><span class="p">(</span><span class="n">rewards</span><span class="p">[</span><span class="o">-</span><span class="n">criterion_episodes</span><span class="p">:]):</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Stopping criterion satisfied after </span><span class="si">{</span><span class="n">episode</span><span class="si">}</span><span class="s2"> episodes"</span><span class="p">)</span>
                <span class="k">break</span>

        <span class="c1"># Plot rewards received during training</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">dpi</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">rewards</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Rewards per Episode'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Episodes'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Rewards'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Training Rewards over Episodes'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower right'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="c1">###############################################################################################################################################################################################################</span>
    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="c1"># Save network weights to a file</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">path</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Model saved to </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="c1">###############################################################################################################################################################################################################</span>
    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="c1"># Load network weights from a file</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_qnet</span><span class="o">.</span><span class="n">copy_from</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Model loaded from </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=3dddb7c6-68e7-422b-bad6-f4e3256812b1">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="Sweep-setup">Sweep setup<a class="anchor-link" href="#Sweep-setup"></a></h5>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=7904ee28-5cbe-4f74-a36a-9f5a52087566">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Define the Sweep Agent Function</span>
<span class="k">def</span> <span class="nf">sweep_agent</span><span class="p">():</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Initialize a new wandb run</span>
        <span class="k">with</span> <span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">()</span> <span class="k">as</span> <span class="n">run</span><span class="p">:</span>
            <span class="n">config</span> <span class="o">=</span> <span class="n">wandb</span><span class="o">.</span><span class="n">config</span>

            <span class="c1"># Create the environment with RAM observation type</span>
            <span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">'ALE/Boxing-v5'</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">"rgb_array_list"</span><span class="p">,</span> <span class="n">obs_type</span><span class="o">=</span><span class="s2">"ram"</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"Observation Space Shape:"</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

            <span class="c1"># Ensure the observation is a 128-length vector</span>
            <span class="k">assert</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">128</span><span class="p">,),</span> <span class="s2">"Observation space must be a 128-length vector."</span>

            <span class="c1"># Instantiate AgentDQN with current wandb config</span>
            <span class="n">agent</span> <span class="o">=</span> <span class="n">AgentDQN</span><span class="p">(</span><span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>

            <span class="c1"># Define stopping criterion (optional)</span>
            <span class="k">def</span> <span class="nf">stopping_criterion</span><span class="p">(</span><span class="n">rewards</span><span class="p">):</span>
                <span class="c1"># Example: stop if average reward over last 5 episodes &gt;= 100</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rewards</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">100</span>

            <span class="c1"># Start training</span>
            <span class="n">agent</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
                <span class="n">max_episodes</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">num_episodes</span><span class="p">,</span>
                <span class="n">stop_criterion</span><span class="o">=</span><span class="n">stopping_criterion</span><span class="p">,</span>
                <span class="n">criterion_episodes</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">criterion_episodes</span>
            <span class="p">)</span>

            <span class="c1"># Close the environment after training</span>
            <span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="c1"># Log the error to wandb</span>
        <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">({</span><span class="s2">"error"</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)})</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"An error occurred: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="c1"># Ensure the environment is closed in case of an error</span>
        <span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="c1"># Define the Sweep Configuration</span>
<span class="c1"># Random Sweep Configuration with Limited Runs</span>
<span class="n">sweep_configuration</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"method"</span><span class="p">:</span> <span class="s2">"random"</span><span class="p">,</span>  <span class="c1"># Options: "grid", "random", "bayes"</span>
    <span class="s2">"metric"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"episode_reward"</span><span class="p">,</span>  <span class="c1"># The metric to optimize</span>
        <span class="s2">"goal"</span><span class="p">:</span> <span class="s2">"maximize"</span>         <span class="c1"># Whether to "minimize" or "maximize"</span>
    <span class="p">},</span>
    <span class="s2">"parameters"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"learning_rate"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Learning rate for the Q-network</span>
            <span class="s2">"distribution"</span><span class="p">:</span> <span class="s2">"log_uniform"</span><span class="p">,</span>
            <span class="s2">"min"</span><span class="p">:</span> <span class="mf">1e-5</span><span class="p">,</span>
            <span class="s2">"max"</span><span class="p">:</span> <span class="mf">1e-3</span>
        <span class="p">},</span>
        <span class="s2">"epsilon"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Exploration rate</span>
            <span class="s2">"distribution"</span><span class="p">:</span> <span class="s2">"uniform"</span><span class="p">,</span>
            <span class="s2">"min"</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
            <span class="s2">"max"</span><span class="p">:</span> <span class="mf">0.3</span>
        <span class="p">},</span>
        <span class="s2">"gamma"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Discount factor for future rewards</span>
            <span class="s2">"distribution"</span><span class="p">:</span> <span class="s2">"uniform"</span><span class="p">,</span>
            <span class="s2">"min"</span><span class="p">:</span> <span class="mf">0.95</span><span class="p">,</span>
            <span class="s2">"max"</span><span class="p">:</span> <span class="mf">0.99</span>
        <span class="p">},</span>
        <span class="s2">"replay_size"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Replay buffer size</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="mi">20000</span><span class="p">]</span>  <span class="c1"># Three discrete values</span>
        <span class="p">},</span>
        <span class="s2">"minibatch_size"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Mini-batch size for updates</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">]</span>  <span class="c1"># Three discrete values</span>
        <span class="p">},</span>
        <span class="c1"># Fixed Hyperparameters</span>
        <span class="s2">"hidden_sizes"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Architecture of hidden layers</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="s2">"(64,64)"</span><span class="p">,</span><span class="s2">"(128,128)"</span><span class="p">,</span><span class="s2">"(64,64,64)"</span><span class="p">,</span><span class="s2">"(128,128,128)"</span><span class="p">]</span>  
        <span class="p">},</span>
        <span class="s2">"target_update"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Frequency of target network updates</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">]</span>  <span class="c1"># Fixed to 20</span>
        <span class="p">},</span>
        <span class="s2">"num_episodes"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Total number of training episodes</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mi">500</span><span class="p">]</span>  <span class="c1"># Fixed to 500</span>
        <span class="p">},</span>
        <span class="s2">"criterion_episodes"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Number of episodes for stopping criterion</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">]</span>  <span class="c1"># Fixed to 5</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>

     

<span class="c1"># Initialize the sweep</span>
<span class="n">sweep_id</span> <span class="o">=</span> <span class="n">wandb</span><span class="o">.</span><span class="n">sweep</span><span class="p">(</span><span class="n">sweep</span><span class="o">=</span><span class="n">sweep_configuration</span><span class="p">,</span> <span class="n">project</span><span class="o">=</span><span class="s1">'DQN'</span><span class="p">)</span>

<span class="c1"># Launch the Sweep with Limited Runs</span>

<span class="n">wandb</span><span class="o">.</span><span class="n">agent</span><span class="p">(</span><span class="n">sweep_id</span><span class="p">,</span> <span class="n">function</span><span class="o">=</span><span class="n">sweep_agent</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=e643a88b-5a63-4aff-84ea-5757dd2961ee">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">wandb</span> tristancarlisle/DQN/sweeps/vk9fl1fi
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
<iframe src="https://wandb.ai/tristancarlisle/DQN/sweeps/vk9fl1fi?jupyter=true" style="border:none;width:100%;height:420px;"></iframe>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=e23bfc25-a093-4638-9fb1-d98d8aefb01d">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Dueling-Double-DQN-Implementation">Dueling Double DQN Implementation<a class="anchor-link" href="#Dueling-Double-DQN-Implementation"></a></h3>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=aa0e3cbe-bbd7-4fca-a769-6a93b5298934">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Dueling-Double-DQN-RAM-Observations">Dueling Double DQN RAM Observations<a class="anchor-link" href="#Dueling-Double-DQN-RAM-Observations"></a></h4>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=e1fb4598-4462-444d-9064-df7921a8d589">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Dueling-Double-DQN-Image-Observations">Dueling Double DQN Image Observations<a class="anchor-link" href="#Dueling-Double-DQN-Image-Observations"></a></h4>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=e8942e06-a363-4575-9fc8-9e55fd90544e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="Network-for-dueling">Network for dueling<a class="anchor-link" href="#Network-for-dueling"></a></h5><p>big point is the presence of the advantage and value streams</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=6ab1db02-eca6-4f71-8aa1-fe53c0ef1e65">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[96]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span> <span class="c1"># training on GPU</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Using device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"CUDA_LAUNCH_BLOCKING"</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"1"</span>

<span class="k">class</span> <span class="nc">DDQNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># create network layers (gave up trying to get the format in the practicals to work this is just how I always do it)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="p">)</span>
        
        <span class="c1"># Advantage stream</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">netAx</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3136</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
        <span class="p">)</span>
        
        <span class="c1"># Value stream</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">netVx</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3136</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>
        
        <span class="c1"># Loss function and optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span>
            <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">netAx</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">netVx</span><span class="o">.</span><span class="n">parameters</span><span class="p">()),</span>
            <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">Ax</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">netAx</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1">#key difference wiith network is the calculations here</span>
        <span class="n">Vx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">netVx</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Vx</span> <span class="o">+</span> <span class="p">(</span><span class="n">Ax</span> <span class="o">-</span> <span class="n">Ax</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">copy_from</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">qnetwork</span><span class="p">):</span>
        <span class="c1"># Correctly copy the entire state_dict</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">qnetwork</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Using device: cuda
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=2f066ffe-2962-49a6-972d-15fd05c18eba">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h6 id="Env-set-up-for-image">Env set up for image<a class="anchor-link" href="#Env-set-up-for-image"></a></h6>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=81266c41-98a1-4768-873f-dc478efb5ddb">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[97]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">'ALE/Boxing-v5'</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">"rgb_array"</span><span class="p">,</span><span class="n">obs_type</span><span class="o">=</span><span class="s2">"grayscale"</span><span class="p">)</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">wrappers</span><span class="o">.</span><span class="n">ResizeObservation</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="mi">84</span><span class="p">))</span>    <span class="c1"># Resize to 84x84</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">wrappers</span><span class="o">.</span><span class="n">NormalizeObservation</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>


<span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.99</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.0001</span>
<span class="n">max_episodes</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">max_steps</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">criterion_episodes</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">epsilon_start</span><span class="o">=</span><span class="mi">1</span> <span class="c1">#added epsilon start point</span>
<span class="n">epsilon_end</span><span class="o">=</span><span class="mf">0.05</span> <span class="c1">#added epsilon endpoint</span>
<span class="n">epsilon_decay</span><span class="o">=</span><span class="mi">50000</span> <span class="c1">#added epsilon decay</span>
<span class="n">warmupsteps</span><span class="o">=</span><span class="mi">1000</span> <span class="c1">#added warmupsteps</span>
<span class="n">replay_size</span><span class="o">=</span><span class="mi">10000</span>
<span class="n">minibatch_size</span><span class="o">=</span><span class="mi">32</span>
<span class="n">target_update</span><span class="o">=</span><span class="mi">20</span>
<span class="n">rep_omega</span><span class="o">=</span><span class="mf">0.2</span>

<span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">project</span><span class="o">=</span><span class="s1">'DDQN dueling_Image'</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'DDQN_dueling_image_1'</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="p">{</span>
    <span class="s1">'gamma'</span><span class="p">:</span> <span class="n">gamma</span><span class="p">,</span>
    <span class="s1">'learning_rate'</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">,</span>
    <span class="s1">'epsilon_start'</span><span class="p">:</span> <span class="n">epsilon_start</span><span class="p">,</span>
    <span class="s1">'epsilon_end'</span><span class="p">:</span> <span class="n">epsilon_end</span><span class="p">,</span>
    <span class="s1">'epsilon_decay'</span><span class="p">:</span> <span class="n">epsilon_decay</span><span class="p">,</span>
    <span class="s1">'replay_size'</span><span class="p">:</span> <span class="n">replay_size</span><span class="p">,</span>
    <span class="s1">'minibatch_size'</span><span class="p">:</span> <span class="n">minibatch_size</span><span class="p">,</span>
    <span class="s1">'target_update_freq'</span><span class="p">:</span> <span class="n">target_update</span><span class="p">,</span>
    <span class="s1">'num_episodes'</span><span class="p">:</span> <span class="n">max_episodes</span><span class="p">,</span>
    <span class="s1">'max_steps_per_episode'</span><span class="p">:</span> <span class="n">max_steps</span><span class="p">,</span>
    <span class="s1">'rep_omega'</span><span class="p">:</span><span class="n">rep_omega</span><span class="p">,</span>
    <span class="s1">'criterion_episodes'</span><span class="p">:</span><span class="n">criterion_episodes</span>
<span class="p">})</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
Tracking run with wandb version 0.18.3
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
Run data is saved locally in <code>/home/tristan/UniStuff/ReinforcementLearning/Assignment/wandb/run-20241017_175159-danpovfr</code>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
Syncing run <strong><a href="https://wandb.ai/tristancarlisle/DDQN%20dueling_Image/runs/danpovfr" target="_blank">DDQN_dueling_image_1</a></strong> to <a href="https://wandb.ai/tristancarlisle/DDQN%20dueling_Image" target="_blank">Weights &amp; Biases</a> (<a href="https://wandb.me/run" target="_blank">docs</a>)<br/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
 View project at <a href="https://wandb.ai/tristancarlisle/DDQN%20dueling_Image" target="_blank">https://wandb.ai/tristancarlisle/DDQN%20dueling_Image</a>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
 View run at <a href="https://wandb.ai/tristancarlisle/DDQN%20dueling_Image/runs/danpovfr" target="_blank">https://wandb.ai/tristancarlisle/DDQN%20dueling_Image/runs/danpovfr</a>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[97]:</div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html" tabindex="0">
<button onclick="this.nextSibling.style.display='block';this.style.display='none';">Display W&amp;B run</button><iframe src="https://wandb.ai/tristancarlisle/DDQN%20dueling_Image/runs/danpovfr?jupyter=true" style="border:none;width:100%;height:420px;display:none;"></iframe>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=bd17aafa-cb3d-4ed0-9fd2-60b55b806b54">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="Agent-class-set-up-initialisation-and-evaluation">Agent class set up initialisation and evaluation<a class="anchor-link" href="#Agent-class-set-up-initialisation-and-evaluation"></a></h5>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=bcd0a18b-f952-4afc-b150-b12f1b5c8ba2">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Deep Q-network (DQN)</span>
<span class="k">class</span> <span class="nc">AgentDuelingDDQNImage</span><span class="p">():</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span>
                 <span class="c1">#hidden_sizes=(128, 128,128), #Increased Depth and size</span>
                 <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="c1">#decrease learning rate</span>
                 <span class="n">epsilon_start</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="c1">#added epsilon start point</span>
                 <span class="n">epsilon_end</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="c1">#added epsilon endpoint</span>
                 <span class="n">epsilon_decay</span><span class="o">=</span><span class="mi">50000</span><span class="p">,</span> <span class="c1">#added epsilon decay</span>
                 <span class="n">warmupsteps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="c1">#added warmupsteps</span>
                 <span class="n">replay_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
                 <span class="n">minibatch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                 <span class="n">rep_omega</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                 <span class="n">target_update</span><span class="o">=</span><span class="mi">20</span><span class="p">):</span>
        <span class="c1"># check if the state space has correct type</span>
        <span class="c1">#continuous = isinstance(env.observation_space, spaces.Box) and len(env.observation_space.shape) == 1  removed as using an image now </span>
        <span class="c1">#assert continuous, 'Observation space must be continuous with shape (n,)'</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># check if the action space has correct type</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span> <span class="n">spaces</span><span class="o">.</span><span class="n">Discrete</span><span class="p">),</span> <span class="s1">'Action space must be discrete'</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">qnet</span> <span class="o">=</span> <span class="n">DDQNetwork</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="c1">#moved to GPU</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_qnet</span> <span class="o">=</span> <span class="n">DDQNetwork</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="c1">#moved to GPU</span>


        <span class="c1"># copy weights from Q-network to target Q-network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_qnet</span><span class="o">.</span><span class="n">copy_from</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="p">)</span>

        <span class="c1"># initialise replay buffer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">replay_size</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">env</span> <span class="o">=</span> <span class="n">env</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_start</span> <span class="o">=</span> <span class="n">epsilon_start</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_end</span><span class="o">=</span> <span class="n">epsilon_end</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_decay</span> <span class="o">=</span> <span class="n">epsilon_decay</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span> <span class="o">=</span> <span class="n">minibatch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_update</span> <span class="o">=</span> <span class="n">target_update</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rep_omega</span><span class="o">=</span><span class="n">rep_omega</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_update_idx</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">warmupsteps</span><span class="o">=</span><span class="n">warmupsteps</span>
<span class="c1">##########################################################################################################################################################################################################</span>
    <span class="k">def</span> <span class="nf">behaviour</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">):</span> 
        <span class="c1">#set  epsilon threshold to global variable to keep track</span>
        <span class="k">global</span> <span class="n">epsilon_threshold</span>
        <span class="c1"># exploratory behaviour policy</span>
        <span class="n">epsilon_threshold</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_end</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">epsilon_start</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_end</span><span class="p">)</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">1.</span> <span class="o">*</span> <span class="n">num_steps</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_decay</span><span class="p">)</span><span class="c1">#epsilon value calculation for incorporation of decay</span>

        <span class="k">if</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="n">epsilon_threshold</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># exploitation with probability 1-epsilon; break ties randomly</span>
            <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="n">j</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">)</span>
            <span class="c1">#print(f"Q-values shape: {q.shape}, J: {j.shape}")</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">j</span><span class="p">[</span><span class="n">q</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="n">action</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="c1">#changed for usage on GPU</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># exploration with probability epsilon</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="c1">#changed to usage on GPU</span>
<span class="c1">##########################################################################################################################################################################################################</span>
    <span class="k">def</span> <span class="nf">policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="c1"># convert state to torch format</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="c1"># greedy policy</span>
        <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">q</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="c1">##########################################################################################################################################################################################################</span>
    <span class="k">def</span> <span class="nf">td_error</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">terminated</span><span class="p">):</span>
        <span class="c1"># calculate td error for prioritised experience replay</span>
        <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="n">action_index</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="c1">#added cause I kept getting an indexing error and for some reason I cannot count </span>
        <span class="k">if</span> <span class="n">action_index</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">action_index</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Action index </span><span class="si">{</span><span class="n">action_index</span><span class="si">}</span><span class="s2"> is out of bounds for the action space of size </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="si">}</span><span class="s2">."</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">terminated</span><span class="p">:</span>
            <span class="c1">#have to convert back to CPU for numpy :(</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">reward</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">-</span> <span class="n">q</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">action_index</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">rep_omega</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">next_action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="p">(</span><span class="n">next_state</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
            <span class="n">next_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_qnet</span><span class="p">(</span><span class="n">next_state</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="c1">#print(f"Q-values shape: {q[0].shape}, Action: {action.item()}")</span>
            <span class="c1">#print(f"Next Q-values shape: {next_q[0].shape}, Next Action: {next_action}")</span>
            <span class="c1">#also needs to be converted back to CPU for numpy</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">reward</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">next_q</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">next_action</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">-</span> <span class="n">q</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">action_index</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">rep_omega</span>
            
<span class="c1">##########################################################################################################################################################################################################</span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># update Q-network if there is enough experience</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">:</span>
            <span class="c1"># select mini-batch of experiences uniformly at random without replacement                                </span>
            <span class="n">p_rep</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="p">))])</span>
            <span class="n">p_rep</span> <span class="o">=</span> <span class="n">p_rep</span><span class="o">/</span><span class="n">p_rep</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p_rep</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="c1"># calculate inputs and targets for the transitions in the mini-batch</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">84</span><span class="p">,</span> <span class="mi">84</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
            <span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
                <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">per</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
                <span class="n">inputs</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># had to change to account for frame stacking removes batch dimension</span>

                <span class="c1"># targets are TD targets</span>
                <span class="n">target_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_qnet</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
                <span class="n">targets</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">target_q</span>

                <span class="k">if</span> <span class="n">terminated</span><span class="p">:</span>
                    <span class="n">targets</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">action</span><span class="p">]</span> <span class="o">=</span> <span class="n">reward</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">next_action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="p">(</span><span class="n">next_state</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="c1">#primary network for action selection </span>
                    <span class="n">next_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_qnet</span><span class="p">(</span><span class="n">next_state</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="c1">#target network for action evaluation</span>
                    <span class="n">targets</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">action</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span> <span class="o">=</span> <span class="n">reward</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="o">*</span><span class="n">next_q</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">next_action</span><span class="p">]</span>
            
            <span class="c1"># train Q-network on the mini-batch</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>

        <span class="c1"># periodically copy weights from Q-network to target Q-network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_update_idx</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_update_idx</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_update</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">target_qnet</span><span class="o">.</span><span class="n">copy_from</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="p">)</span>
<span class="c1">##########################################################################################################################################################################################################</span>
    <span class="k">def</span> <span class="nf">warmup</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">'Warming up'</span><span class="p">)</span>
            <span class="n">warmupstep</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="c1"># Warmup loop</span>
            <span class="k">while</span> <span class="n">warmupstep</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmupsteps</span><span class="p">:</span>
                <span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">state</span><span class="p">,</span><span class="n">state</span><span class="p">,</span><span class="n">state</span><span class="p">,</span><span class="n">state</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1">#(1,4,84,84)</span>
                <span class="n">terminated</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">truncated</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">while</span> <span class="ow">not</span> <span class="p">(</span><span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">):</span>
                    <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()]])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="c1"># Random action selection during warm-up</span>
                    <span class="c1"># Step in environment</span>
                    <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
                    <span class="n">next_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">next_state</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">next_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">next_state</span><span class="p">,</span><span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span><span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span><span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">2</span><span class="p">]))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">reward</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">reward</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">term</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">per</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">td_error</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">term</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">term</span><span class="p">,</span><span class="n">per</span><span class="p">))</span><span class="c1"># Store the transition in memory</span>
                    <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
                    <span class="n">warmupstep</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="k">if</span> <span class="n">warmupstep</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmupsteps</span><span class="p">:</span>
                        <span class="k">break</span>
    
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Warm-up finito: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">warmupsteps</span><span class="si">}</span><span class="s1"> steps stored.'</span><span class="p">)</span>


<span class="c1">##########################################################################################################################################################################################################</span>
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_episodes</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="p">,</span> <span class="n">criterion_episodes</span><span class="p">):</span>
        <span class="c1"># train the agent for a number of episodes</span>
        <span class="n">rewards</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_episodes</span><span class="p">):</span>
            <span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
            <span class="c1"># convert state to torch format</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">state</span><span class="p">,</span><span class="n">state</span><span class="p">,</span><span class="n">state</span><span class="p">,</span><span class="n">state</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1">#(1,4,84,84)</span>
            <span class="n">terminated</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">truncated</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">while</span> <span class="ow">not</span> <span class="p">(</span><span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">):</span>
                <span class="c1"># select action by following behaviour policy</span>
                <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">behaviour</span><span class="p">(</span><span class="n">state</span> <span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

                <span class="c1"># send the action to the environment</span>
                <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

                <span class="c1"># convert next state to torch format and add experience to replay buffer</span>
                <span class="n">next_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">next_state</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">next_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">next_state</span><span class="p">,</span><span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span><span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span><span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">2</span><span class="p">]))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">reward</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">reward</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">term</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">terminated</span> <span class="ow">or</span>  <span class="n">truncated</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
                <span class="n">per</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">td_error</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">term</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                
                <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">term</span><span class="p">,</span><span class="n">per</span><span class="p">))</span>
                
                <span class="c1"># update Q-network</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>

                <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
                <span class="n">rewards</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+=</span> <span class="n">reward</span>
                <span class="n">num_steps</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="c1">#all to tensors</span>
            <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">({</span>
                    <span class="s1">'episode'</span><span class="p">:</span> <span class="n">episode</span><span class="p">,</span>
                    <span class="s1">'episode_reward'</span><span class="p">:</span> <span class="n">rewards</span><span class="p">[</span><span class="n">episode</span><span class="p">],</span>
                    <span class="s1">'epsilon threshold'</span><span class="p">:</span> <span class="n">epsilon_threshold</span><span class="p">,</span>
                    <span class="s1">'steps'</span><span class="p">:</span> <span class="n">num_steps</span><span class="p">,</span>
                <span class="p">})</span>     
                
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\r</span><span class="s1">Episode </span><span class="si">{</span><span class="n">episode</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1"> done: steps = </span><span class="si">{</span><span class="n">num_steps</span><span class="si">}</span><span class="s1">, rewards = </span><span class="si">{</span><span class="n">rewards</span><span class="p">[</span><span class="n">episode</span><span class="p">]</span><span class="si">}</span><span class="s1">     '</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">''</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">episode</span> <span class="o">&gt;=</span> <span class="n">criterion_episodes</span><span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">stop_criterion</span><span class="p">(</span><span class="n">rewards</span><span class="p">[</span><span class="o">-</span><span class="n">criterion_episodes</span><span class="p">:]):</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Stopping criterion satisfied after </span><span class="si">{</span><span class="n">episode</span><span class="si">}</span><span class="s1"> episodes'</span><span class="p">)</span>
                <span class="k">break</span>

        <span class="c1"># Log metrics to W&amp;B</span>
           

        <span class="c1"># plot rewards received during training</span>
        <span class="c1">#plt.figure(dpi=100)</span>
        <span class="c1">#plt.plot(range(1, len(rewards)+1), rewards, label=f'Rewards')</span>

        <span class="c1">#plt.xlabel('Episodes')</span>
        <span class="c1">#plt.ylabel('Rewards per episode')</span>
        <span class="c1">#plt.legend(loc='lower right')</span>
        <span class="c1">#plt.grid()</span>
        <span class="c1">#plt.show()</span>

<span class="c1">##########################################################################################################################################################################################################</span>
        <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Run</span><span class="p">):</span>
            <span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
            <span class="n">terminated</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">truncated</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">steps</span><span class="o">=</span><span class="mi">0</span>
            <span class="n">frames</span><span class="o">=</span><span class="p">[]</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">state</span><span class="p">,</span><span class="n">state</span><span class="p">,</span><span class="n">state</span><span class="p">,</span><span class="n">state</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1">#(1,4,84,84)</span>
            <span class="k">while</span> <span class="ow">not</span> <span class="p">(</span><span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">):</span>
                <span class="c1"># take action based on policy</span>

                <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">state</span><span class="p">,</span><span class="n">state</span><span class="p">,</span><span class="n">state</span><span class="p">,</span><span class="n">state</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1">#(1,4,84,84)</span>
                <span class="n">action</span> <span class="o">=</span> <span class="n">AgentDuelingDDQNImage</span><span class="o">.</span><span class="n">policy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
            
                <span class="c1"># environment receives the action and returns:</span>
                <span class="c1"># next observation, reward, terminated, truncated, and additional information (if applicable)</span>
                <span class="n">state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
                <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">reward</span>
                <span class="n">steps</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">frame</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>
                <span class="n">frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Reward: </span><span class="si">{</span><span class="n">total_reward</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
            <span class="n">v</span><span class="o">=</span> <span class="n">VideoRecorder</span><span class="p">(</span><span class="s1">'DQN'</span><span class="p">)</span> <span class="c1"># None ram version of videorecorder</span>
            <span class="k">for</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">frames</span><span class="p">:</span>
                <span class="n">v</span><span class="o">.</span><span class="n">record</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>
            <span class="n">vfilename</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'DDDQN__Image_run_</span><span class="si">{</span><span class="n">Run</span><span class="si">}</span><span class="s1">.mp4'</span>
            <span class="n">v</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">vfilename</span><span class="p">)</span>
            <span class="n">video_path</span><span class="o">=</span><span class="s2">"DDDQN/"</span> <span class="o">+</span> <span class="n">vfilename</span>
            <span class="c1"># Save video of the evaluation episode</span>
            <span class="c1">#video = np.stack(frames)</span>
            <span class="c1">#video_path = f"evaluation_episode_{episode_num}.mp4"</span>
            <span class="c1">#mpy_clip = mpy.ImageSequenceClip(list(video), fps=30)</span>
            <span class="c1">#mpy_clip.write_videofile(video_path, codec="libx264")</span>
    
            <span class="c1"># Log evaluation results and video to W&amp;B</span>
            <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">({</span>
                <span class="s1">'Evaluation Run'</span><span class="p">:</span> <span class="n">Run</span><span class="p">,</span>
                <span class="s1">'Evaluation Reward'</span><span class="p">:</span> <span class="n">total_reward</span><span class="p">,</span>
                <span class="s1">'Evaluation Video'</span><span class="p">:</span> <span class="n">wandb</span><span class="o">.</span><span class="n">Video</span><span class="p">(</span><span class="n">video_path</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">"mp4"</span><span class="p">)</span>
            <span class="p">})</span>
    
            <span class="c1"># Logging evaluation result</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Evaluation run: </span><span class="si">{</span><span class="n">Run</span><span class="si">}</span><span class="s2"> Total Reward = </span><span class="si">{</span><span class="n">total_reward</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
            <span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="c1">##########################################################################################################################################################################################################            </span>
    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="c1"># save network weights to a file</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">path</span><span class="p">)</span>
<span class="c1">##########################################################################################################################################################################################################</span>
    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="c1"># load network weights from a file</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_qnet</span><span class="o">.</span><span class="n">copy_from</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="p">)</span>




<span class="c1">#initiaise</span>
<span class="n">AgentDuelingDDQNImage</span> <span class="o">=</span> <span class="n">AgentDuelingDDQNImage</span><span class="p">(</span><span class="n">env</span><span class="p">,</span>
                 <span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span>
                 <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
                 <span class="n">replay_size</span><span class="o">=</span><span class="n">replay_size</span><span class="p">,</span>
                 <span class="n">epsilon_start</span><span class="o">=</span><span class="n">epsilon_start</span><span class="p">,</span>
                 <span class="n">epsilon_end</span><span class="o">=</span><span class="n">epsilon_end</span><span class="p">,</span>
                 <span class="n">rep_omega</span><span class="o">=</span><span class="n">rep_omega</span><span class="p">,</span>
                 <span class="n">epsilon_decay</span><span class="o">=</span><span class="n">epsilon_decay</span><span class="p">,</span>
                 <span class="n">minibatch_size</span><span class="o">=</span><span class="n">minibatch_size</span><span class="p">,</span>
                 <span class="n">target_update</span><span class="o">=</span><span class="n">target_update</span><span class="p">)</span>

<span class="c1">#agent.load('acrobot.128x128.DQN.pt')</span>
<span class="n">AgentDuelingDDQNImage</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">max_episodes</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="nb">min</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">criterion_episodes</span><span class="p">)</span>


<span class="c1">##########################################################################################################################################################################################################</span>
<span class="c1">#Evaluate</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">AgentDuelingDDQNImage</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">Run</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
<span class="n">wandb</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>

<span class="c1"># create and play video clip using the frames and given fps</span>
<span class="c1">#clip = mpy.ImageSequenceClip(frames, fps=15)</span>
<span class="c1">#clip.ipython_display(rd_kwargs=dict(logger=None))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Episode 20 done: steps = 35720, rewards = -4.0     </pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=1d1d8352-6ebd-4af6-93be-56f8ef2630d0">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">AgentDQN</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">'Boxing.DuelingDQN.greyscale.agent1.pt'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=09ed6671-b0df-4fed-8a08-c765123e6702">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">wandb</span> tristancarlisle/DDQN dueling_Image/DDQN_dueling_image_1
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=ea591195-2f87-47d1-b7c8-e759856b6ff3">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Hyperparameter-Sweep-Dueling-Double-DQN-(RAM)">Hyperparameter Sweep Dueling Double DQN (RAM)<a class="anchor-link" href="#Hyperparameter-Sweep-Dueling-Double-DQN-(RAM)"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=47a5c240-f388-49b8-88a2-8a460985228e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Using device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Set random seeds for reproducibility</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="c1"># Define the Dueling Q-Network</span>
<span class="k">class</span> <span class="nc">DuelingQNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DuelingQNetwork</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Shared network layers</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">last_size</span> <span class="o">=</span> <span class="n">input_size</span>
        <span class="k">for</span> <span class="n">hidden_size</span> <span class="ow">in</span> <span class="n">hidden_sizes</span><span class="p">:</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">last_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
            <span class="n">last_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shared_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
        
        <span class="c1"># Advantage stream</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">advantage_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">last_size</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
        <span class="p">)</span>
        
        <span class="c1"># Value stream</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">last_size</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>
        
        <span class="c1"># Loss function and optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">shared</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shared_net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Shape: [batch_size, last_hidden_size]</span>
        <span class="n">advantage</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">advantage_net</span><span class="p">(</span><span class="n">shared</span><span class="p">)</span>  <span class="c1"># Shape: [batch_size, output_size]</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_net</span><span class="p">(</span><span class="n">shared</span><span class="p">)</span>  <span class="c1"># Shape: [batch_size, 1]</span>
        <span class="n">q_values</span> <span class="o">=</span> <span class="n">value</span> <span class="o">+</span> <span class="p">(</span><span class="n">advantage</span> <span class="o">-</span> <span class="n">advantage</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">q_values</span>  <span class="c1"># Shape: [batch_size, output_size]</span>
    
    <span class="k">def</span> <span class="nf">update_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">copy_from</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">source_network</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">source_network</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=e73cca27-0be9-43a2-9040-e7a40fc99160">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Dueling Double DQN Agent</span>
<span class="k">class</span> <span class="nc">AgentDuelingDoubleDQN</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
        <span class="c1"># Validate observation space</span>
        <span class="n">continuous</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="n">continuous</span><span class="p">,</span> <span class="s1">'Observation space must be continuous with shape (n,)'</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
        <span class="c1"># Validate action space</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Discrete</span><span class="p">),</span> <span class="s1">'Action space must be discrete'</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span>
    
        <span class="c1"># Parse hidden_sizes from string to tuple if necessary</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_sizes</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">hidden_sizes</span> <span class="o">=</span> <span class="n">ast</span><span class="o">.</span><span class="n">literal_eval</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_sizes</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_sizes</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">hidden_sizes</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_sizes</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">hidden_sizes</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_sizes</span>
    
       <span class="c1"># print(f"Using hidden_sizes: {hidden_sizes}")</span>
    
        <span class="c1"># Initialize Q-networks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qnet</span> <span class="o">=</span> <span class="n">DuelingQNetwork</span><span class="p">(</span>
            <span class="n">input_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span><span class="p">,</span> 
            <span class="n">hidden_sizes</span><span class="o">=</span><span class="n">hidden_sizes</span><span class="p">,</span> 
            <span class="n">output_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span> 
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">learning_rate</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    
        <span class="bp">self</span><span class="o">.</span><span class="n">target_qnet</span> <span class="o">=</span> <span class="n">DuelingQNetwork</span><span class="p">(</span>
            <span class="n">input_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span><span class="p">,</span> 
            <span class="n">hidden_sizes</span><span class="o">=</span><span class="n">hidden_sizes</span><span class="p">,</span> 
            <span class="n">output_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span> 
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">learning_rate</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    
        <span class="c1"># Copy weights from Q-network to target Q-network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_qnet</span><span class="o">.</span><span class="n">copy_from</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="p">)</span>
    
        <span class="c1"># Initialize replay buffer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">replay_size</span><span class="p">)</span>
    
        <span class="c1"># Initialize hyperparameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">env</span> <span class="o">=</span> <span class="n">env</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">minibatch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_update</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">target_update</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_update_idx</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">def</span> <span class="nf">behaviour</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="c1"># Exploratory behaviour policy</span>
        <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">:</span>
            <span class="c1"># Convert state to torch tensor</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Shape: [1, state_dims]</span>
    
            <span class="c1"># Exploitation: select the action with highest Q-value</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">q_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>  <span class="c1"># Shape: [1, num_actions]</span>
                <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">q_values</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Exploration: select a random action</span>
            <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">action</span>
    
    <span class="k">def</span> <span class="nf">policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="c1"># Greedy policy: select the action with highest Q-value</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Shape: [1, state_dims]</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">q_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>  <span class="c1"># Shape: [1, num_actions]</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">q_values</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">action</span>
    
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Update Q-network if there is enough experience</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">:</span>
            <span class="c1"># Sample a minibatch of experiences uniformly at random</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">minibatch_size</span><span class="p">)</span>
    
            <span class="c1"># Extract components of the batch</span>
            <span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">next_states</span><span class="p">,</span> <span class="n">terminateds</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">batch</span><span class="p">)</span>
    
            <span class="c1"># Convert to tensors</span>
            <span class="n">states</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">states</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Shape: [batch_size, state_dims]</span>
            <span class="n">actions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Shape: [batch_size, 1]</span>
            <span class="n">rewards</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">rewards</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Shape: [batch_size, 1]</span>
            <span class="n">next_states</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">next_states</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Shape: [batch_size, state_dims]</span>
            <span class="n">terminateds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">terminateds</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Shape: [batch_size, 1]</span>
    
            <span class="c1"># Debugging: Print tensor shapes</span>
            <span class="c1">#print(f"Update - states shape: {states.shape}")  # [batch_size, state_dims]</span>
            <span class="c1">#print(f"Update - actions shape: {actions.shape}")  # [batch_size, 1]</span>
            <span class="c1">#print(f"Update - rewards shape: {rewards.shape}")  # [batch_size, 1]</span>
            <span class="c1">#print(f"Update - next_states shape: {next_states.shape}")  # [batch_size, state_dims]</span>
            <span class="c1">#print(f"Update - terminateds shape: {terminateds.shape}")  # [batch_size, 1]</span>
    
            <span class="c1"># Validate actions</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">actions</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span> <span class="ow">or</span> <span class="p">(</span><span class="n">actions</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="n">invalid_actions</span> <span class="o">=</span> <span class="n">actions</span><span class="p">[(</span><span class="n">actions</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">actions</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">)]</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Invalid actions in batch: </span><span class="si">{</span><span class="n">invalid_actions</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Found invalid action indices in batch."</span><span class="p">)</span>
    
            <span class="c1"># Compute current Q-values for the actions taken</span>
            <span class="n">current_q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="p">(</span><span class="n">states</span><span class="p">)</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">actions</span><span class="p">)</span>  <span class="c1"># Shape: [batch_size, 1]</span>
            <span class="c1">#print(f"Update - current_q shape: {current_q.shape}")  # [batch_size, 1]</span>
    
            <span class="c1"># Double DQN: Use the main network to select the best action, and the target network to evaluate it</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="c1"># Select the best action using the main Q-network</span>
                <span class="n">next_q_main</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="p">(</span><span class="n">next_states</span><span class="p">)</span>  <span class="c1"># Shape: [batch_size, num_actions]</span>
                <span class="n">best_next_actions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">next_q_main</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Shape: [batch_size, 1]</span>
                <span class="c1">#print(f"Update - best_next_actions shape: {best_next_actions.shape}")  # [batch_size, 1]</span>
    
                <span class="c1"># Evaluate the best actions using the target Q-network</span>
                <span class="n">next_q_target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_qnet</span><span class="p">(</span><span class="n">next_states</span><span class="p">)</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">best_next_actions</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Shape: [batch_size]</span>
               <span class="c1"># print(f"Update - next_q_target shape: {next_q_target.shape}")  # [batch_size]</span>
    
                <span class="c1"># Compute target Q-values</span>
                <span class="n">target_q</span> <span class="o">=</span> <span class="n">rewards</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">terminateds</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">next_q_target</span>  <span class="c1"># Shape: [batch_size]</span>
               <span class="c1"># print(f"Update - target_q shape: {target_q.shape}")  # [batch_size]</span>
    
            <span class="c1"># Compute loss</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">current_q</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">target_q</span><span class="p">)</span>
            <span class="c1">#print(f"Update - loss: {loss.item()}")</span>
    
            <span class="c1"># Update Q-network</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="o">.</span><span class="n">update_network</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    
            <span class="c1"># Periodically copy weights from Q-network to target Q-network</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">target_update_idx</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_update_idx</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_update</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">target_qnet</span><span class="o">.</span><span class="n">copy_from</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="p">)</span>
                <span class="c1">#print("Target network updated.")</span>
    
    <span class="k">def</span> <span class="nf">train_agent</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_episodes</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="p">,</span> <span class="n">criterion_episodes</span><span class="p">):</span>
        <span class="c1"># Train the agent for a number of episodes</span>
        <span class="n">rewards</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_episodes</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
            <span class="n">terminated</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">truncated</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">episode_reward</span> <span class="o">=</span> <span class="mi">0</span>
    
            <span class="k">while</span> <span class="ow">not</span> <span class="p">(</span><span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">):</span>
                <span class="c1"># Select action by following behaviour policy</span>
                <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">behaviour</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
    
                <span class="c1"># Send the action to the environment</span>
                <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
    
                <span class="c1"># Convert states to torch tensors</span>
                <span class="n">state_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Shape: [state_dims]</span>
                <span class="n">next_state_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">next_state</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Shape: [state_dims]</span>
    
                <span class="c1"># Add experience to replay buffer</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">state_tensor</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state_tensor</span><span class="p">,</span> <span class="n">terminated</span><span class="p">))</span>
    
                <span class="c1"># Update Q-network</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
                <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">ve</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"ValueError during update: </span><span class="si">{</span><span class="n">ve</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
                    <span class="k">raise</span> <span class="n">ve</span>
                <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">re</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"RuntimeError during update: </span><span class="si">{</span><span class="n">re</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">"Consider running on CPU for detailed error messages."</span><span class="p">)</span>
                    <span class="k">raise</span> <span class="n">re</span>
    
                <span class="c1"># Update state and cumulative reward</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
                <span class="n">episode_reward</span> <span class="o">+=</span> <span class="n">reward</span>
                <span class="n">num_steps</span> <span class="o">+=</span> <span class="mi">1</span>
    
            <span class="c1"># Append the reward for this episode</span>
            <span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">episode_reward</span><span class="p">)</span>
    
            <span class="c1"># Log metrics to W&amp;B</span>
            <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">({</span>
                <span class="s1">'episode'</span><span class="p">:</span> <span class="n">episode</span><span class="p">,</span>
                <span class="s1">'episode_reward'</span><span class="p">:</span> <span class="n">episode_reward</span><span class="p">,</span>
                <span class="s1">'epsilon'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">,</span>
                <span class="s1">'steps'</span><span class="p">:</span> <span class="n">num_steps</span>
            <span class="p">})</span>
    
            <span class="c1"># Print progress</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Episode </span><span class="si">{</span><span class="n">episode</span><span class="si">}</span><span class="s2">: Reward = </span><span class="si">{</span><span class="n">episode_reward</span><span class="si">}</span><span class="s2">, Total Steps = </span><span class="si">{</span><span class="n">num_steps</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    
            <span class="c1"># Check stopping criterion</span>
            <span class="k">if</span> <span class="n">episode</span> <span class="o">&gt;=</span> <span class="n">criterion_episodes</span> <span class="ow">and</span> <span class="n">stop_criterion</span><span class="p">(</span><span class="n">rewards</span><span class="p">[</span><span class="o">-</span><span class="n">criterion_episodes</span><span class="p">:]):</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Stopping criterion satisfied after </span><span class="si">{</span><span class="n">episode</span><span class="si">}</span><span class="s2"> episodes"</span><span class="p">)</span>
                <span class="k">break</span>
    
        <span class="c1"># Plot rewards received during training</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">dpi</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">rewards</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Rewards per Episode'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Episodes'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Rewards'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Training Rewards over Episodes'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower right'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="c1"># Save network weights to a file</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">path</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Model saved to </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="c1"># Load network weights from a file</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_qnet</span><span class="o">.</span><span class="n">copy_from</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qnet</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Model loaded from </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=e213860a-0595-4ca4-9bae-9c78650c20d2">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Define the Sweep Agent Function</span>
<span class="k">def</span> <span class="nf">sweep_agent</span><span class="p">():</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Initialize a new wandb run</span>
        <span class="k">with</span> <span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">()</span> <span class="k">as</span> <span class="n">run</span><span class="p">:</span>
            <span class="n">config</span> <span class="o">=</span> <span class="n">wandb</span><span class="o">.</span><span class="n">config</span>
    
            <span class="c1"># Create the environment with RAM observation type</span>
            <span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">'ALE/Boxing-v5'</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">"rgb_array_list"</span><span class="p">,</span> <span class="n">obs_type</span><span class="o">=</span><span class="s2">"ram"</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"Observation Space Shape:"</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    
            <span class="c1"># Ensure the observation is a 128-length vector</span>
            <span class="k">assert</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">128</span><span class="p">,),</span> <span class="s2">"Observation space must be a 128-length vector."</span>
    
            <span class="c1"># Instantiate AgentDuelingDoubleDQN with current wandb config</span>
            <span class="n">agent</span> <span class="o">=</span> <span class="n">AgentDuelingDoubleDQN</span><span class="p">(</span><span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    
            <span class="c1"># Define stopping criterion (optional)</span>
            <span class="k">def</span> <span class="nf">stopping_criterion</span><span class="p">(</span><span class="n">rewards</span><span class="p">):</span>
                <span class="c1"># Example: stop if average reward over last 5 episodes &gt;= 100</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rewards</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">100</span>
    
            <span class="c1"># Start training</span>
            <span class="n">agent</span><span class="o">.</span><span class="n">train_agent</span><span class="p">(</span>
                <span class="n">max_episodes</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">num_episodes</span><span class="p">,</span>
                <span class="n">stop_criterion</span><span class="o">=</span><span class="n">stopping_criterion</span><span class="p">,</span>
                <span class="n">criterion_episodes</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">criterion_episodes</span>
            <span class="p">)</span>
    
            <span class="c1"># Close the environment after training</span>
            <span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="c1"># Log the error to wandb</span>
        <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">({</span><span class="s2">"error"</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)})</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"An error occurred: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="c1"># Ensure the environment is closed in case of an error</span>
        <span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=446cd609-4f92-49d5-9bac-e7a25b03b31e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Define the Sweep Configuration</span>
<span class="c1"># Random Sweep Configuration with Limited Runs</span>
<span class="n">sweep_configuration</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"method"</span><span class="p">:</span> <span class="s2">"random"</span><span class="p">,</span>  <span class="c1"># Options: "grid", "random", "bayes"</span>
    <span class="s2">"metric"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"episode_reward"</span><span class="p">,</span>  <span class="c1"># The metric to optimize</span>
        <span class="s2">"goal"</span><span class="p">:</span> <span class="s2">"maximize"</span>         <span class="c1"># Whether to "minimize" or "maximize"</span>
    <span class="p">},</span>
    <span class="s2">"parameters"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"learning_rate"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Learning rate for the Q-network</span>
            <span class="s2">"distribution"</span><span class="p">:</span> <span class="s2">"uniform"</span><span class="p">,</span>
            <span class="s2">"min"</span><span class="p">:</span> <span class="mf">1e-7</span><span class="p">,</span>
            <span class="s2">"max"</span><span class="p">:</span> <span class="mf">1e-3</span>
        <span class="p">},</span>
        <span class="s2">"epsilon"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Exploration rate</span>
            <span class="s2">"distribution"</span><span class="p">:</span> <span class="s2">"uniform"</span><span class="p">,</span>
            <span class="s2">"min"</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
            <span class="s2">"max"</span><span class="p">:</span> <span class="mf">0.3</span>
        <span class="p">},</span>
        <span class="s2">"gamma"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Discount factor for future rewards</span>
            <span class="s2">"distribution"</span><span class="p">:</span> <span class="s2">"uniform"</span><span class="p">,</span>
            <span class="s2">"min"</span><span class="p">:</span> <span class="mf">0.95</span><span class="p">,</span>
            <span class="s2">"max"</span><span class="p">:</span> <span class="mf">0.99</span>
        <span class="p">},</span>
        <span class="s2">"replay_size"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Replay buffer size</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="mi">20000</span><span class="p">]</span>  <span class="c1"># Three discrete values</span>
        <span class="p">},</span>
        <span class="s2">"minibatch_size"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Mini-batch size for updates</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">]</span>  <span class="c1"># Three discrete values</span>
        <span class="p">},</span>
        <span class="c1"># Fixed Hyperparameters</span>
        <span class="s2">"hidden_sizes"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Architecture of hidden layers</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="s2">"(64,64)"</span><span class="p">,</span> <span class="s2">"(128,128)"</span><span class="p">,</span> <span class="s2">"(64,64,64)"</span><span class="p">,</span> <span class="s2">"(128,128,128)"</span><span class="p">]</span>  
        <span class="p">},</span>
        <span class="s2">"target_update"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Frequency of target network updates</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">]</span>  <span class="c1"># Fixed to 20</span>
        <span class="p">},</span>
        <span class="s2">"num_episodes"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Total number of training episodes</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mi">500</span><span class="p">]</span>  <span class="c1"># Fixed to 500</span>
        <span class="p">},</span>
        <span class="s2">"criterion_episodes"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Number of episodes for stopping criterion</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">]</span>  <span class="c1"># Fixed to 5</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c1"># Initialize the sweep</span>
<span class="n">sweep_id</span> <span class="o">=</span> <span class="n">wandb</span><span class="o">.</span><span class="n">sweep</span><span class="p">(</span><span class="n">sweep</span><span class="o">=</span><span class="n">sweep_configuration</span><span class="p">,</span> <span class="n">project</span><span class="o">=</span><span class="s1">'DuelingDoubleDQN_RAM'</span><span class="p">)</span>

<span class="c1"># Launch the Sweep with Limited Runs</span>
<span class="n">wandb</span><span class="o">.</span><span class="n">agent</span><span class="p">(</span><span class="n">sweep_id</span><span class="p">,</span> <span class="n">function</span><span class="o">=</span><span class="n">sweep_agent</span><span class="p">,</span> <span class="n">count</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=ba3835ea-95c9-47aa-b1d0-a96e2aa809ce">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[90]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">wandb</span> tristancarlisle/DuelingDoubleDQN_RAM/sweeps/14vtcl50
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
<iframe src="https://wandb.ai/tristancarlisle/DuelingDoubleDQN_RAM/sweeps/14vtcl50?jupyter=true" style="border:none;width:100%;height:420px;"></iframe>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=d7fddfd9-7d05-4355-b038-f09617d18b0f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Soft-Actor-Critic-(SAC)">Soft Actor Critic (SAC)<a class="anchor-link" href="#Soft-Actor-Critic-(SAC)"></a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=2c5adf7c-f807-4d6a-9676-ab55a2662b37">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Actor-Critic-Implementation">Actor Critic Implementation<a class="anchor-link" href="#Actor-Critic-Implementation"></a></h3>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=b564860a-b366-4f54-9890-9f2c91551215">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Actor-Critic-Image-Observations">Actor Critic Image Observations<a class="anchor-link" href="#Actor-Critic-Image-Observations"></a></h4>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=cccf4873-059b-4ec5-81b4-65f1901a511c">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Explanation of the Current Implementation
The code below implements a basic Actor-Critic algorithm for the Atari Boxing environment using PyTorch.</p>
<p>Overview of Actor-Critic Algorithm
The Actor-Critic (AC) method is a type of policy gradient algorithm that combines both value-based and policy-based methods. It consists of two main components:
    Actor (Policy Network): Learns the policy function (), which tells the agent which action to take in a given state.
    Critic (Value Network): Learns the value function (), which estimates the expected return from a state.
    The actor updates the policy in the direction suggested by the critic, using the estimated advantage (how good an action is compared to the average).</p>
<p>On-Policy Learning: The agent learns from the data collected by its current policy.
Single-Step Updates: Uses one-step TD targets for updates.
No Entropy Regularization: The policy updates do not include an entropy term to encourage exploration.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=1b480390-3938-4a65-a8d6-7c2d41170c8b">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Policy-network---deep-neural-network-approximation-of-policy-function">Policy network - deep neural network approximation of policy function<a class="anchor-link" href="#Policy-network---deep-neural-network-approximation-of-policy-function"></a></h4>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=220c5017-2cb7-4302-b68c-574f38686c9f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Policy Network (PolicyNetwork)
Architecture:
    Convolutional Layers: Extract features from the image input (Atari frames).
    Fully Connected Layers: Process the flattened features to produce logits for each possible action.
Functionality:
    Forward Pass: Processes input states and outputs action logits.
    Update Method: Computes the loss using the negative log probability of the taken action multiplied by the advantage (delta), and updates the network       weights accordingly.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=7ef5f667-7bd2-4a10-96fe-5bfac9686f0b">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[100]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Using device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Set random seeds for reproducibility</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="c1"># Policy network for approximating policy function</span>
<span class="k">class</span> <span class="nc">PolicyNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1">#2D CNN layers for boxing atari image </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>  <span class="c1"># Input channels = 3 (RGB), Output channels = 32</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="c1">#Input size post CNN for fully connected layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flattened_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_flattened_size</span><span class="p">(</span><span class="n">input_size</span><span class="p">)</span>
        <span class="c1"># create network layers</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>

        <span class="c1"># input layer</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flattened_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>

        <span class="c1"># hidden layers</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>

        <span class="c1"># output layer (preferences/logits/unnormalised log-probabilities)</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">output_size</span><span class="p">))</span>

        <span class="c1"># combine layers into feed-forward network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

        <span class="c1"># select optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="c1">##########################################################################################################################################################################################################        </span>
    <span class="k">def</span> <span class="nf">_get_flattened_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">):</span>
        <span class="c1">#just a function to help me with dynamically changing the CNN structure</span>
       <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">dummy_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">input_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># Batch size 1, C, H, W</span>
            <span class="n">conv_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_net</span><span class="p">(</span><span class="n">dummy_input</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">conv_out</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="c1">##########################################################################################################################################################################################################</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1">#permuting input from(H,W,C) to (C,H,W) for CNN: (210, 160, 3) to (3, 210, 160)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># return output of policy network</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="c1">##########################################################################################################################################################################################################</span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">advantage</span><span class="p">):</span>
        <span class="c1"># update network weights for given input(s) and target(s)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">state</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># State is (batch_size, H, W, C)</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># (batch_size, C, H, W)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">)</span>
        <span class="n">log_prob</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">log_prob</span> <span class="o">*</span> <span class="n">advantage</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=09dd0cdd-8b5b-4f5b-a477-09678e301844">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Value-Network">Value Network<a class="anchor-link" href="#Value-Network"></a></h4>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=fc680953-3534-4bb7-82a1-299e0c96d536">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Value Network (ValueNetwork)
Architecture:
Similar to the policy network but outputs a single scalar value representing the state value ().
Functionality:
    Forward Pass: Processes input states and outputs the estimated value.
    Update Method: Uses mean squared error (MSE) loss between the predicted value and the TD target, and updates the network weights.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=afa028c7-5d1b-4bed-b28d-2140273b703a">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[101]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">ValueNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1">#2D CNN layers for boxing atari image </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>  <span class="c1"># Input channels = 3 (RGB), Output channels = 32</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="c1">#Input size post CNN for fully connected layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flattened_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_flattened_size</span><span class="p">(</span><span class="n">input_size</span><span class="p">)</span>
        
        <span class="c1"># create network layers</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>

        <span class="c1"># input layer</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flattened_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>

        <span class="c1"># hidden layers</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>

        <span class="c1"># output layer (there is only one unit representing state value)</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>

        <span class="c1"># combine layers into feed-forward network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

        <span class="c1"># select loss function and optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="c1">##########################################################################################################################################################################################################</span>
    <span class="k">def</span> <span class="nf">_get_flattened_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">):</span>
        <span class="c1">#just a function to help me with dynamically changing the CNN structure</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">dummy_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">input_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># Batch size 1, C, H, W</span>
            <span class="n">conv_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_net</span><span class="p">(</span><span class="n">dummy_input</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">conv_out</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="c1">##########################################################################################################################################################################################################</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># return output of value network for the input x</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="c1">##########################################################################################################################################################################################################</span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
        <span class="c1"># update network weights </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">state</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># State is (batch_size, H, W, C)</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># (batch_size, C, H, W)</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=997d2fe7-4b6f-4091-912e-69b152762615">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Actor-critic-class">Actor-critic class<a class="anchor-link" href="#Actor-critic-class"></a></h4>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=1c9f8512-7f3e-44a9-acda-2b7d1450447f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Training Loop (ActorCritic Class)
Initialization:
    Creates instances of the policy and value networks.
    Sets up the environment and hyperparameters.
Policy Method:
    Chooses an action based on the current policy, either stochastically (sampling) or deterministically (argmax).
Update Method:
    Computes the TD target and advantage.
    Updates both the policy and value networks using the computed loss functions.
Training Method:
    Runs episodes where the agent interacts with the environment.
    After each step, updates the networks.
    Tracks and plots the rewards over episodes.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=5547b4e8-a149-48ac-b4db-6aff153cefe4">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[102]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Actor-Critic algorithm with one-step TD target</span>
<span class="k">class</span> <span class="nc">ActorCritic</span><span class="p">():</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">lr_policy</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">lr_value</span><span class="o">=</span><span class="mf">0.001</span><span class="p">):</span>
        <span class="c1"># check if the state space has correct type</span>
        <span class="c1">#continuous = isinstance(env.observation_space, spaces.Box) and len(env.observation_space.shape) == 1</span>
        <span class="c1">#assert continuous, 'Observation space must be continuous with shape (n,)'</span>
        <span class="c1">#Variation to accept 2D image using CNN as opposed to 1D continous statespace</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1"># check if the action space has correct type</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span> <span class="n">spaces</span><span class="o">.</span><span class="n">Discrete</span><span class="p">),</span> <span class="s1">'Action space must be discrete'</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span>
        
        <span class="c1"># create policy network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policynet</span> <span class="o">=</span> <span class="n">PolicyNetwork</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span> <span class="n">lr_policy</span><span class="p">)</span>

        <span class="c1"># create value network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valuenet</span> <span class="o">=</span> <span class="n">ValueNetwork</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">lr_value</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">env</span> <span class="o">=</span> <span class="n">env</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
<span class="c1">##########################################################################################################################################################################################################</span>
    <span class="k">def</span> <span class="nf">prepare_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="c1">#New introduced function to practical code it converts state to tensor with batch dimension and proper shape, just to assist policy function</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">state</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># (1, H, W, C)</span>
        <span class="k">return</span> <span class="n">state</span>
<span class="c1">##########################################################################################################################################################################################################</span>
    <span class="k">def</span> <span class="nf">policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">stochastic</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_state</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># (batch_size, C, H, W)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policynet</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">stochastic</span><span class="p">:</span>
            <span class="c1"># sample action using action probabilities</span>
            <span class="k">return</span> <span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># select action with the highest probability</span>
            <span class="c1"># note: we ignore breaking ties randomly (low chance of happening)</span>
            <span class="k">return</span> <span class="n">dist</span><span class="o">.</span><span class="n">probs</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="c1">##########################################################################################################################################################################################################</span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">terminated</span><span class="p">):</span>
        <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_state</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">next_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_state</span><span class="p">(</span><span class="n">next_state</span><span class="p">)</span>
        <span class="n">state_perm</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">next_state_perm</span> <span class="o">=</span> <span class="n">next_state</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># calculate TD target for value network update</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">terminated</span><span class="p">:</span>
                <span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="n">reward</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span> <span class="c1">#updated hasd issues doing it below for some reason but works here (convert target to torch format)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">next_state_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">valuenet</span><span class="p">(</span><span class="n">next_state_perm</span><span class="p">)</span> <span class="c1"># changed as well (convert target to torch format(</span>
                <span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="n">reward</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">next_state_value</span>
                <span class="c1">#target = reward + self.gamma*self.valuenet(next_state).detach()</span>

        <span class="c1"># calculate TD error for policy network update (equal to the action advantage)</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">valuenet</span><span class="p">(</span><span class="n">state_perm</span><span class="p">)</span> <span class="c1">#broke it up to help make it easier to follow for myself and anyone reading</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="n">target</span> <span class="o">-</span> <span class="n">value</span>


        <span class="c1"># update networks</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">action</span><span class="p">])</span> <span class="c1"># batch dimension so slightly different to in practical</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policynet</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">delta</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span> <span class="c1">#also detached here instead was having issues just doing it in the delta function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valuenet</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="c1">##########################################################################################################################################################################################################</span>
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_episodes</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="p">,</span> <span class="n">criterion_episodes</span><span class="p">):</span>
        <span class="c1"># train the agent for a number of episodes</span>
        <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">episode_rewards</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_episodes</span><span class="p">):</span>
            <span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>


            <span class="n">terminated</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">truncated</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">episode_rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">while</span> <span class="ow">not</span> <span class="p">(</span><span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">):</span>
                <span class="c1"># select action by following policy</span>
                <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

                <span class="c1"># send the action to the environment</span>
                <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
                <span class="n">episode_rewards</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+=</span> <span class="n">reward</span>

                <span class="c1"># update policy and value networks</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">terminated</span><span class="p">)</span>

                <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
                <span class="n">num_steps</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\r</span><span class="s1">Episode </span><span class="si">{</span><span class="n">episode</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1"> done: steps = </span><span class="si">{</span><span class="n">num_steps</span><span class="si">}</span><span class="s1">, '</span>
                  <span class="sa">f</span><span class="s1">'rewards = </span><span class="si">{</span><span class="n">episode_rewards</span><span class="p">[</span><span class="n">episode</span><span class="p">]</span><span class="si">}</span><span class="s1">     '</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">''</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">episode</span> <span class="o">&gt;=</span> <span class="n">criterion_episodes</span><span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">stop_criterion</span><span class="p">(</span><span class="n">episode_rewards</span><span class="p">[</span><span class="o">-</span><span class="n">criterion_episodes</span><span class="p">:]):</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Stopping criterion satisfied after </span><span class="si">{</span><span class="n">episode</span><span class="si">}</span><span class="s1"> episodes'</span><span class="p">)</span>
                <span class="k">break</span>

        <span class="c1"># plot rewards received during training</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">dpi</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">episode_rewards</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">episode_rewards</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">'Rewards'</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Episodes'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Rewards per episode'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower right'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="c1">##########################################################################################################################################################################################################</span>
    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="c1"># save network weights to a file</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span><span class="s1">'policy'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">policynet</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                    <span class="s1">'value'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">valuenet</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()},</span> <span class="n">path</span><span class="p">)</span>
<span class="c1">##########################################################################################################################################################################################################</span>
    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="c1"># load network weights from a file</span>
        <span class="n">networks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policynet</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">networks</span><span class="p">[</span><span class="s1">'policy'</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valuenet</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">networks</span><span class="p">[</span><span class="s1">'value'</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=af40ab9a-5043-4287-8e79-3c1a2bbddceb">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Boxing-ENV">Boxing ENV<a class="anchor-link" href="#Boxing-ENV"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=cd0fc608-3efc-4be6-95d1-09f37c757d77">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">'ALE/Boxing-v5'</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">"rgb_array_list"</span><span class="p">)</span>

<span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.99</span>
<span class="n">hidden_sizes</span> <span class="o">=</span> <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="n">lr_policy</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">lr_value</span> <span class="o">=</span> <span class="mf">0.005</span>
<span class="n">max_episodes</span> <span class="o">=</span> <span class="mi">20000</span>
<span class="n">max_steps</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">criterion_episodes</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">agent</span> <span class="o">=</span> <span class="n">ActorCritic</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="o">=</span><span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">lr_policy</span><span class="o">=</span><span class="n">lr_policy</span><span class="p">,</span> <span class="n">lr_value</span><span class="o">=</span><span class="n">lr_value</span><span class="p">)</span>

<span class="c1">#agent.load('cartpole.64x64.AC.pt')</span>
<span class="n">agent</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">max_episodes</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="nb">min</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">400</span><span class="p">,</span> <span class="n">criterion_episodes</span><span class="p">)</span>

<span class="c1"># visualise one episode</span>
<span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="n">terminated</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">truncated</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">steps</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">while</span> <span class="ow">not</span> <span class="p">(</span><span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span> <span class="ow">or</span> <span class="n">steps</span> <span class="o">&gt;</span> <span class="n">max_steps</span><span class="p">):</span>
    <span class="c1"># take action based on policy</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">policy</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">stochastic</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># environment receives the action and returns:</span>
    <span class="c1"># next observation, reward, terminated, truncated, and additional information (if applicable)</span>
    <span class="n">state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
    <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">reward</span>
    <span class="n">steps</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Reward: </span><span class="si">{</span><span class="n">total_reward</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

<span class="c1"># store RGB frames for the entire episode</span>
<span class="n">frames</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>

<span class="c1"># close the environment</span>
<span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="c1"># create and play video clip using the frames and given fps</span>
<span class="n">clip</span> <span class="o">=</span> <span class="n">mpy</span><span class="o">.</span><span class="n">ImageSequenceClip</span><span class="p">(</span><span class="n">frames</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">clip</span><span class="o">.</span><span class="n">ipython_display</span><span class="p">(</span><span class="n">rd_kwargs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">logger</span><span class="o">=</span><span class="kc">None</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Episode 3452 done: steps = 6165272, rewards = -25.0     </pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=1bff5e37-1fc3-4b72-b548-437e9830c786">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Soft-Actor-Critic-(SAC)-Implementation">Soft Actor-Critic (SAC) Implementation<a class="anchor-link" href="#Soft-Actor-Critic-(SAC)-Implementation"></a></h3>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=910071c9-b92d-4191-9693-d464fe93689b">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Soft Actor-Critic (SAC) is an off-policy actor-critic algorithm that aims to maximize a trade-off between expected return and entropy. It encourages exploration by adding an entropy term to the objective function, making the policy stochastic even in deterministic environments.</p>
<p>Off-Policy Learning: Uses a replay buffer to store experiences and sample from it.
Entropy Regularization: Encourages the policy to explore more by maximizing the expected entropy of the policy.
Twin Q-Networks: Uses two Q-value networks to mitigate overestimation bias.
Target Networks: Uses target networks to stabilize training.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=482f0396-2da7-4529-8272-7fcb0606ef22">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Atari boxing is a discrete action spcae thus, need to make alterations for SAC which is designed for continuous action spaces.
Alterations:
Implement rwo Q-networks: mitigate overestimation bias.
Modify the policy network: tooutput a categorical distribution and include entropy in the loss function.
Use a replay buffer: for off-policy learning.
Add target networks: Ffor both Q-networks.
Include entropy coefficient (): fixed or learned.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=42eb2747-41ed-4479-adf3-56f0a0ec1144">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Soft-Actor-Critic-(SAC)-RAM-Observations">Soft Actor-Critic (SAC) RAM Observations<a class="anchor-link" href="#Soft-Actor-Critic-(SAC)-RAM-Observations"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=9854189e-232b-4be6-9455-0b073fef4552">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[54]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Using device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Set random seeds for reproducibility</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Using device: cuda
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=9fbaf67f-aca7-4313-ae9b-d7a46684192d">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[87]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">PolicyNetworkRAM</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="c1"># Define network layers</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">last_size</span> <span class="o">=</span> <span class="n">input_size</span>
        <span class="k">for</span> <span class="n">hidden_size</span> <span class="ow">in</span> <span class="n">hidden_sizes</span><span class="p">:</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">last_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
            <span class="n">last_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="c1"># Output layer for logits</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">last_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
        
        <span class="c1"># Optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Output logits for Categorical distribution</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">update_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">q_values</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">states</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">)</span>
        <span class="n">log_probs</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">actions</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># [batch_size]</span>
        <span class="n">entropy</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">entropy</span><span class="p">()</span>  <span class="c1"># [batch_size]</span>
        
        <span class="c1"># Ensure q_values require gradients</span>
        <span class="n">q_values</span> <span class="o">=</span> <span class="n">q_values</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        
        <span class="c1"># Policy loss with entropy regularization</span>
        <span class="n">policy_loss</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">log_probs</span> <span class="o">-</span> <span class="n">q_values</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">policy_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        
        <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">max_norm</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        
        <span class="c1"># Calculate gradient norms for logging</span>
        <span class="n">total_norm</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">param_norm</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">total_norm</span> <span class="o">+=</span> <span class="n">param_norm</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="n">total_norm</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">total_norm</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">policy_loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">total_norm</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=9911c11b-fcb5-4550-b137-0c681a3e001b">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[88]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">QNetworkRAM</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">num_actions</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Define network layers</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">last_size</span> <span class="o">=</span> <span class="n">input_size</span>
        <span class="k">for</span> <span class="n">hidden_size</span> <span class="ow">in</span> <span class="n">hidden_sizes</span><span class="p">:</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">last_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
            <span class="n">last_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="c1"># Output layer for Q-values</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">last_size</span><span class="p">,</span> <span class="n">num_actions</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
        
        <span class="c1"># Loss function and optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Output Q-values for each action</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
    
    <span class="k">def</span> <span class="nf">update_q_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">loss</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="c1"># Gradient clipping</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">max_norm</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=04050921-41fb-4bb4-9bb9-768721f04a1f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Added replay buffer</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=91a5747d-b9f5-4c8f-9bc0-5363cb7c2ab7">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[84]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">ReplayBuffer</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">capacity</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">capacity</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">push</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">terminated</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">terminated</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">state_batch</span><span class="p">,</span> <span class="n">action_batch</span><span class="p">,</span> <span class="n">reward_batch</span><span class="p">,</span> <span class="n">next_state_batch</span><span class="p">,</span> <span class="n">terminated_batch</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">samples</span><span class="p">)</span>
        
        <span class="c1"># Convert lists to single numpy arrays for efficiency</span>
        <span class="n">state_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span>
        <span class="n">action_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">action_batch</span><span class="p">)</span>
        <span class="n">reward_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">reward_batch</span><span class="p">)</span>
        <span class="n">next_state_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">next_state_batch</span><span class="p">)</span>
        <span class="n">terminated_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">terminated_batch</span><span class="p">)</span>
        
        <span class="c1"># Convert to tensors and move to device</span>
        <span class="n">state_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># [batch_size, state_dims]</span>
        <span class="n">action_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">action_batch</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># [batch_size, 1]</span>
        <span class="n">reward_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">reward_batch</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># [batch_size, 1]</span>
        <span class="n">next_state_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">next_state_batch</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># [batch_size, state_dims]</span>
        <span class="n">terminated_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">terminated_batch</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># [batch_size, 1]</span>
        
        <span class="k">return</span> <span class="n">state_batch</span><span class="p">,</span> <span class="n">action_batch</span><span class="p">,</span> <span class="n">reward_batch</span><span class="p">,</span> <span class="n">next_state_batch</span><span class="p">,</span> <span class="n">terminated_batch</span>
    
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=508e96d5-6da9-4d66-b5f6-0554e963f370">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[91]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">SACAgentRAM</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
                 <span class="n">lr_policy</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">lr_q</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">replay_size</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
                 <span class="n">target_update_interval</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">tau</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span> <span class="n">automatic_alpha</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="c1"># Validate observation space</span>
        <span class="n">continuous</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">,</span> <span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="n">continuous</span><span class="p">,</span> <span class="s1">'Observation space must be continuous with shape (n,)'</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1">#print(f"State dimensions: {self.state_dims}")</span>
    
        <span class="c1"># Validate action space</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span> <span class="n">spaces</span><span class="o">.</span><span class="n">Discrete</span><span class="p">),</span> <span class="s1">'Action space must be discrete'</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span>
        <span class="c1">#print(f"Number of actions: {self.num_actions}")</span>
        
        <span class="c1"># Initialize Replay Buffer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="o">=</span> <span class="n">ReplayBuffer</span><span class="p">(</span><span class="n">replay_size</span><span class="p">)</span>
        
        <span class="c1"># Initialize Policy Network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span> <span class="o">=</span> <span class="n">PolicyNetworkRAM</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span> <span class="n">lr_policy</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Initialize Q-Networks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span> <span class="o">=</span> <span class="n">QNetworkRAM</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span> <span class="n">lr_q</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span> <span class="o">=</span> <span class="n">QNetworkRAM</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span> <span class="n">lr_q</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Initialize Target Q-Networks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span> <span class="o">=</span> <span class="n">QNetworkRAM</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span> <span class="n">lr_q</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span> <span class="o">=</span> <span class="n">QNetworkRAM</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span> <span class="n">lr_q</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Synchronize target networks with main Q-networks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
        
        <span class="c1"># Hyperparameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">env</span> <span class="o">=</span> <span class="n">env</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>  <span class="c1"># Entropy temperature</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">=</span> <span class="n">tau</span>  <span class="c1"># Target smoothing coefficient</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_update_interval</span> <span class="o">=</span> <span class="n">target_update_interval</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">automatic_alpha</span> <span class="o">=</span> <span class="n">automatic_alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">warm_up</span><span class="p">(</span><span class="n">initial_steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">automatic_alpha</span><span class="p">:</span>
            <span class="c1"># target entropy</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">target_entropy</span> <span class="o">=</span> <span class="o">-</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.98</span>  <span class="c1"># Slightly lower than maximum</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    
            <span class="bp">self</span><span class="o">.</span><span class="n">alpha_optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">log_alpha</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr_policy</span><span class="p">)</span>
            <span class="c1">#print("Automatic alpha tuning enabled.")</span>
<span class="c1">##########################################################################################################################################################################################################    </span>
    <span class="k">def</span> <span class="nf">warm_up</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">initial_steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
        <span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">initial_steps</span><span class="p">):</span>
            <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># Take random action</span>
            <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">reward</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Clip rewards</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">push</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">terminated</span><span class="p">)</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
            <span class="k">if</span> <span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">:</span>
                <span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
                
  <span class="c1">##########################################################################################################################################################################################################  </span>
    <span class="k">def</span> <span class="nf">policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">evaluate</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="c1">#state = self.normalize_state(state)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>  <span class="c1"># [1, num_actions]</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">evaluate</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">probs</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="c1"># Validate action</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">action</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Sampled action </span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="s2"> is out of bounds."</span><span class="p">)</span>
        
        <span class="c1"># Log action probabilities for debugging</span>
        <span class="n">action_probs</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">probs</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">({</span>
            <span class="s1">'action_probabilities'</span><span class="p">:</span> <span class="n">wandb</span><span class="o">.</span><span class="n">Histogram</span><span class="p">(</span><span class="n">action_probs</span><span class="p">),</span>
            <span class="s1">'selected_action'</span><span class="p">:</span> <span class="n">action</span>
        <span class="p">})</span>
        
        <span class="k">return</span> <span class="n">action</span>
 <span class="c1">##########################################################################################################################################################################################################   </span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">updates</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>  <span class="c1">#  none for all values when not updating</span>
    
        <span class="c1"># samples a minibatch from replay buffer</span>
        <span class="n">state_batch</span><span class="p">,</span> <span class="n">action_batch</span><span class="p">,</span> <span class="n">reward_batch</span><span class="p">,</span> <span class="n">next_state_batch</span><span class="p">,</span> <span class="n">terminated_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
    
    
        <span class="c1"># Compute target Q-values</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="c1"># Get logits and probabilities from the policy network for next states</span>
            <span class="n">next_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="p">(</span><span class="n">next_state_batch</span><span class="p">)</span>
            <span class="n">next_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">next_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
            <span class="n">next_log_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">next_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
    
            <span class="c1"># Get target q-values from target networks</span>
            <span class="n">target_q1_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span><span class="p">(</span><span class="n">next_state_batch</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
            <span class="n">target_q2_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span><span class="p">(</span><span class="n">next_state_batch</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
            <span class="n">target_q_values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">target_q1_values</span><span class="p">,</span> <span class="n">target_q2_values</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
    
            <span class="c1"># Compute expected q-values for next states</span>
            <span class="n">expected_q</span> <span class="o">=</span> <span class="p">(</span><span class="n">next_probs</span> <span class="o">*</span> <span class="p">(</span><span class="n">target_q_values</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">next_log_probs</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># [batch_size, 1]</span>
    
            <span class="c1"># Compute target q</span>
            <span class="n">q_target</span> <span class="o">=</span> <span class="n">reward_batch</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">terminated_batch</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">expected_q</span>  <span class="c1"># [batch_size, 1]</span>
    
        <span class="c1"># Compute current Q-values from both Q-networks</span>
        <span class="n">current_q1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">action_batch</span><span class="p">)</span>  <span class="c1"># [batch_size, 1]</span>
        <span class="n">current_q2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">action_batch</span><span class="p">)</span>  <span class="c1"># [batch_size, 1]</span>


        <span class="n">current_q1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">current_q1</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">current_q2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">current_q2</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    
        <span class="c1"># Compute q-network losses</span>
        <span class="n">q1_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">current_q1</span><span class="p">,</span> <span class="n">q_target</span><span class="p">)</span>
        <span class="n">q2_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">current_q2</span><span class="p">,</span> <span class="n">q_target</span><span class="p">)</span>
    
        <span class="c1"># Update q-networks</span>
        <span class="n">q1_loss_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">update_q_network</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">q1_loss</span><span class="p">)</span>
        <span class="n">q2_loss_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">update_q_network</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">q2_loss</span><span class="p">)</span>
        <span class="n">policy_loss_value</span><span class="p">,</span> <span class="n">grad_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="o">.</span><span class="n">update_policy</span><span class="p">(</span><span class="n">state_batch</span><span class="p">,</span> <span class="n">action_batch</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="p">(</span><span class="n">state_batch</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="p">(</span><span class="n">state_batch</span><span class="p">))</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">action_batch</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="c1"># Compute policy loss</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">entropy</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="p">(</span><span class="n">state_batch</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="p">(</span><span class="n">state_batch</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">entropy</span> <span class="o">=</span> <span class="o">-</span><span class="n">entropy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="c1">#  Update alpha for entropy temperature added because my first implementation sucked</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">automatic_alpha</span><span class="p">:</span>
            <span class="c1">#log_probs for entropy adjustment</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
            <span class="n">log_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
            <span class="n">entropy</span> <span class="o">=</span> <span class="o">-</span> <span class="p">(</span><span class="n">log_probs</span> <span class="o">*</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

            <span class="n">alpha_loss</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">entropy</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_entropy</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">alpha_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">alpha_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">alpha_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="c1"># clamp alpha to prevent it from becoming too small</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_alpha</span><span class="o">.</span><span class="n">exp</span><span class="p">(),</span> <span class="nb">min</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Updated alpha: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Alpha Loss: </span><span class="si">{</span><span class="n">alpha_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="c1"># update target networks</span>
        <span class="k">if</span> <span class="n">updates</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_update_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">soft_update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">soft_update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"Target networks updated."</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">q1_loss_value</span><span class="p">,</span> <span class="n">q2_loss_value</span><span class="p">,</span> <span class="n">policy_loss_value</span><span class="p">,</span> <span class="n">entropy</span>

<span class="c1">##########################################################################################################################################################################################################</span>
    <span class="k">def</span> <span class="nf">soft_update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">target_net</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">param</span><span class="p">,</span> <span class="n">target_param</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">target_net</span><span class="o">.</span><span class="n">parameters</span><span class="p">()):</span>
            <span class="n">target_param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">*</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">)</span> <span class="o">*</span> <span class="n">target_param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="c1">##########################################################################################################################################################################################################    </span>
    <span class="k">def</span> <span class="nf">train_agent</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_episodes</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="p">,</span> <span class="n">criterion_episodes</span><span class="p">):</span>
        <span class="n">total_rewards</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">updates</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">best_avg_reward</span> <span class="o">=</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s1">'inf'</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_episodes</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
            <span class="n">terminated</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">truncated</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">episode_reward</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">steps</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">while</span> <span class="ow">not</span> <span class="p">(</span><span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">)</span> <span class="ow">and</span> <span class="n">steps</span> <span class="o">&lt;</span> <span class="mi">10000</span><span class="p">:</span>  <span class="c1"># infinite loops preventing</span>
                <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
                <span class="n">episode_reward</span> <span class="o">+=</span> <span class="n">reward</span>
                
                <span class="c1"># Store transition in replay buffer</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">push</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">terminated</span><span class="p">)</span>
                
                <span class="c1"># Update state</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
                <span class="n">steps</span> <span class="o">+=</span> <span class="mi">1</span>
                
                <span class="c1"># Update networks</span>
                <span class="n">update_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">updates</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">update_results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">q1_loss</span><span class="p">,</span> <span class="n">q2_loss</span><span class="p">,</span> <span class="n">policy_loss</span><span class="p">,</span> <span class="n">entropy</span> <span class="o">=</span> <span class="n">update_results</span>
                    <span class="n">updates</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">q1_loss</span><span class="p">,</span> <span class="n">q2_loss</span><span class="p">,</span> <span class="n">policy_loss</span><span class="p">,</span> <span class="n">entropy</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

                
            <span class="c1"># Append reward for this episode</span>
            <span class="n">total_rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">episode_reward</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Episode </span><span class="si">{</span><span class="n">episode</span><span class="si">}</span><span class="s2">: Total Reward = </span><span class="si">{</span><span class="n">episode_reward</span><span class="si">}</span><span class="s2">, Steps = </span><span class="si">{</span><span class="n">steps</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
            <span class="n">q1_loss</span><span class="p">,</span> <span class="n">q2_loss</span><span class="p">,</span> <span class="n">policy_loss</span><span class="p">,</span> <span class="n">entropy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">updates</span><span class="p">)</span>
            <span class="c1"># Log metrics to W&amp;B</span>
            <span class="n">log_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">'episode'</span><span class="p">:</span> <span class="n">episode</span><span class="p">,</span>
                <span class="s1">'episode_reward'</span><span class="p">:</span> <span class="n">episode_reward</span><span class="p">,</span>
                <span class="s1">'steps'</span><span class="p">:</span> <span class="n">steps</span><span class="p">,</span>
                <span class="s1">'updates'</span><span class="p">:</span> <span class="n">updates</span><span class="p">,</span>
                <span class="s1">'alpha'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">automatic_alpha</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="k">if</span> <span class="n">q1_loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">log_dict</span><span class="o">.</span><span class="n">update</span><span class="p">({</span>
                    <span class="s1">'q1_loss'</span><span class="p">:</span> <span class="n">q1_loss</span><span class="p">,</span>
                    <span class="s1">'q2_loss'</span><span class="p">:</span> <span class="n">q2_loss</span><span class="p">,</span>
                    <span class="s1">'policy_loss'</span><span class="p">:</span> <span class="n">policy_loss</span><span class="p">,</span>
                    <span class="s1">'entropy'</span><span class="p">:</span> <span class="n">entropy</span><span class="p">,</span>
                <span class="p">})</span>

            <span class="c1"># Log metrics to W&amp;B</span>
            <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">log_dict</span><span class="p">)</span>
            
            <span class="c1"># Check stopping criterion</span>
            <span class="k">if</span> <span class="n">episode</span> <span class="o">&gt;=</span> <span class="n">criterion_episodes</span><span class="p">:</span>
                <span class="n">recent_rewards</span> <span class="o">=</span> <span class="n">total_rewards</span><span class="p">[</span><span class="o">-</span><span class="n">criterion_episodes</span><span class="p">:]</span>
                <span class="k">if</span> <span class="n">stop_criterion</span><span class="p">(</span><span class="n">recent_rewards</span><span class="p">):</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Stopping criterion satisfied after </span><span class="si">{</span><span class="n">episode</span><span class="si">}</span><span class="s2"> episodes"</span><span class="p">)</span>
                    <span class="k">break</span>
        
        <span class="c1"># Plot rewards</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">dpi</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">total_rewards</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">total_rewards</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Total Rewards'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Episode'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Total Reward'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Training Rewards over Episodes'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    
    <span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Save the model parameters.</span>
<span class="sd">        Args:</span>
<span class="sd">            path (str): File path to save the model.</span>
<span class="sd">        """</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
            <span class="s1">'policy_net'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'q_net1'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'q_net2'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'target_q_net1'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'target_q_net2'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
        <span class="p">},</span> <span class="n">path</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Model saved to </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Load the model parameters.</span>
<span class="sd">        Args:</span>
<span class="sd">            path (str): File path to load the model from.</span>
<span class="sd">        """</span>
        <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'policy_net'</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'q_net1'</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'q_net2'</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'target_q_net1'</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'target_q_net2'</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Model loaded from </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=2a5499ce-e853-4354-933a-55ea9f791c9a">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">'ALE/Boxing-v5'</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">"rgb_array_list"</span><span class="p">,</span> <span class="n">obs_type</span><span class="o">=</span><span class="s2">"ram"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Observation Space Shape:"</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Action Space:"</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">)</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">NormalizeObservation</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
<span class="c1"># Hyperparameters</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.99</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">hidden_sizes</span> <span class="o">=</span> <span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span class="n">lr_policy</span> <span class="o">=</span> <span class="mf">1e-4</span>
<span class="n">lr_q</span> <span class="o">=</span> <span class="mf">1e-4</span>
<span class="n">replay_size</span> <span class="o">=</span> <span class="mi">100000</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">target_update_interval</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">tau</span> <span class="o">=</span> <span class="mf">0.005</span>
<span class="n">num_episodes</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">criterion_episodes</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># Initialize W&amp;B</span>
<span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">project</span><span class="o">=</span><span class="s1">'SAC_Discrete_RAM'</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'SAC_Discrete_RAM_Run'</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="p">{</span>
    <span class="s1">'gamma'</span><span class="p">:</span> <span class="n">gamma</span><span class="p">,</span>
    <span class="s1">'lr_q'</span><span class="p">:</span> <span class="n">lr_q</span><span class="p">,</span>
    <span class="s1">'lr_policy'</span><span class="p">:</span> <span class="n">lr_policy</span><span class="p">,</span>
    <span class="s1">'alpha'</span><span class="p">:</span> <span class="n">alpha</span><span class="p">,</span>
    <span class="s1">'tau'</span><span class="p">:</span> <span class="n">tau</span><span class="p">,</span>
    <span class="s1">'replay_size'</span><span class="p">:</span> <span class="n">replay_size</span><span class="p">,</span>
    <span class="s1">'batch_size'</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">,</span>
    <span class="s1">'target_update_interval'</span><span class="p">:</span> <span class="n">target_update_interval</span><span class="p">,</span>
    <span class="s1">'num_episodes'</span><span class="p">:</span> <span class="n">num_episodes</span><span class="p">,</span>
    <span class="s1">'hidden_sizes'</span><span class="p">:</span> <span class="n">hidden_sizes</span><span class="p">,</span>
    <span class="s1">'criterion_episodes'</span><span class="p">:</span> <span class="n">criterion_episodes</span>
<span class="p">})</span>

<span class="c1"># Initialize the SAC agent</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">SACAgentRAM</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">lr_policy</span><span class="p">,</span> <span class="n">lr_q</span><span class="p">,</span> <span class="n">replay_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                   <span class="n">target_update_interval</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">automatic_alpha</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Start training</span>
<span class="n">agent</span><span class="o">.</span><span class="n">train_agent</span><span class="p">(</span>
    <span class="n">num_episodes</span><span class="o">=</span><span class="n">num_episodes</span><span class="p">,</span>
    <span class="n">stop_criterion</span><span class="o">=</span><span class="k">lambda</span> <span class="n">rewards</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rewards</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">criterion_episodes</span><span class="o">=</span><span class="n">criterion_episodes</span>
<span class="p">)</span>

<span class="c1"># Save the trained model</span>
<span class="n">agent</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s1">'sac_discrete_boxing_ram.pth'</span><span class="p">)</span>

<span class="c1"># Visualization: Run one episode and record frames</span>
<span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="n">terminated</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">truncated</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">steps</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">frames</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">while</span> <span class="ow">not</span> <span class="p">(</span><span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">)</span> <span class="ow">and</span> <span class="n">steps</span> <span class="o">&lt;</span> <span class="mi">10000</span><span class="p">:</span>
    <span class="c1"># Select action based on policy</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">policy</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">evaluate</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="c1"># Take action in the environment</span>
    <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
    <span class="n">frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">())</span>
    <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">reward</span>
    <span class="n">steps</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Reward: </span><span class="si">{</span><span class="n">total_reward</span><span class="si">}</span><span class="s1">, Steps: </span><span class="si">{</span><span class="n">steps</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>


<span class="c1"># store RGB frames for the entire episode</span>
<span class="c1">#frames = env.render()</span>

<span class="c1"># close the environment</span>
<span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=bb587bbe-0d99-4334-9d20-db462a347e0f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">wandb</span> tristancarlisle/SAC_Discrete_RAM
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
<iframe src="https://wandb.ai/tristancarlisle/SAC_Discrete_RAM/workspace?jupyter=true" style="border:none;width:100%;height:420px;"></iframe>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=3fa6f668-ae41-4f62-ad96-8737a40dd871">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">wandb</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">imageio</span>
<span class="kn">import</span> <span class="nn">ast</span>

<span class="c1"># Enable anomaly detection for debugging</span>
<span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">set_detect_anomaly</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Set device</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Using device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Set random seeds for reproducibility</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="c1"># Define the Policy Network for Discrete Actions</span>
<span class="k">class</span> <span class="nc">PolicyNetworkRAM</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="c1"># Define network layers</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">last_size</span> <span class="o">=</span> <span class="n">input_size</span>
        <span class="k">for</span> <span class="n">hidden_size</span> <span class="ow">in</span> <span class="n">hidden_sizes</span><span class="p">:</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">last_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
            <span class="n">last_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="c1"># Output layer for logits</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">last_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
        
        <span class="c1"># Optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Output logits for Categorical distribution</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">update_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">q_values</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Update the policy network.</span>
<span class="sd">        Args:</span>
<span class="sd">            states (Tensor): Current states [batch_size, state_dims]</span>
<span class="sd">            actions (Tensor): Actions taken [batch_size, 1]</span>
<span class="sd">            q_values (Tensor): Q-values corresponding to actions [batch_size]</span>
<span class="sd">        Returns:</span>
<span class="sd">            float: Policy loss value</span>
<span class="sd">        """</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">states</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">)</span>
        <span class="n">log_probs</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">actions</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># [batch_size]</span>
        <span class="n">entropy</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">entropy</span><span class="p">()</span>  <span class="c1"># [batch_size]</span>
        
        <span class="c1"># Ensure q_values are detached to prevent gradients flowing back to Q-networks</span>
        <span class="n">q_values</span> <span class="o">=</span> <span class="n">q_values</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        
        <span class="c1"># Policy loss with entropy regularization</span>
        <span class="n">policy_loss</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">log_probs</span> <span class="o">-</span> <span class="n">q_values</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">policy_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        
        <span class="c1"># Gradient clipping (optional)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">max_norm</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        
        <span class="c1"># Calculate gradient norms for logging</span>
        <span class="n">total_norm</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">param_norm</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">total_norm</span> <span class="o">+=</span> <span class="n">param_norm</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="n">total_norm</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">total_norm</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">policy_loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">total_norm</span>

<span class="c1"># Define the Q-Network</span>
<span class="k">class</span> <span class="nc">QNetworkRAM</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">num_actions</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Define network layers</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">last_size</span> <span class="o">=</span> <span class="n">input_size</span>
        <span class="k">for</span> <span class="n">hidden_size</span> <span class="ow">in</span> <span class="n">hidden_sizes</span><span class="p">:</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">last_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
            <span class="n">last_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="c1"># Output layer for Q-values</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">last_size</span><span class="p">,</span> <span class="n">num_actions</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
        
        <span class="c1"># Loss function and optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Output Q-values for each action</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
    
    <span class="k">def</span> <span class="nf">update_q_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">loss</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Update Q-network parameters.</span>
<span class="sd">        Args:</span>
<span class="sd">            parameters (iterable): Network parameters to update.</span>
<span class="sd">            loss (Tensor): Computed loss.</span>
<span class="sd">        Returns:</span>
<span class="sd">            float: Q-network loss value</span>
<span class="sd">        """</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="c1"># Gradient clipping</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">max_norm</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

<span class="c1"># Define the Replay Buffer</span>
<span class="k">class</span> <span class="nc">ReplayBuffer</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">capacity</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">capacity</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">push</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">terminated</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">terminated</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">state_batch</span><span class="p">,</span> <span class="n">action_batch</span><span class="p">,</span> <span class="n">reward_batch</span><span class="p">,</span> <span class="n">next_state_batch</span><span class="p">,</span> <span class="n">terminated_batch</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">samples</span><span class="p">)</span>
        
        <span class="c1"># Convert lists to single NumPy arrays for efficiency</span>
        <span class="n">state_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span>
        <span class="n">action_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">action_batch</span><span class="p">)</span>
        <span class="n">reward_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">reward_batch</span><span class="p">)</span>
        <span class="n">next_state_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">next_state_batch</span><span class="p">)</span>
        <span class="n">terminated_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">terminated_batch</span><span class="p">)</span>
        
        <span class="c1"># Convert to tensors and move to device</span>
        <span class="n">state_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># [batch_size, state_dims]</span>
        <span class="n">action_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">action_batch</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># [batch_size, 1]</span>
        <span class="n">reward_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">reward_batch</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># [batch_size, 1]</span>
        <span class="n">next_state_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">next_state_batch</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># [batch_size, state_dims]</span>
        <span class="n">terminated_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">terminated_batch</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># [batch_size, 1]</span>
        
        <span class="k">return</span> <span class="n">state_batch</span><span class="p">,</span> <span class="n">action_batch</span><span class="p">,</span> <span class="n">reward_batch</span><span class="p">,</span> <span class="n">next_state_batch</span><span class="p">,</span> <span class="n">terminated_batch</span>
    
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="p">)</span>

<span class="c1"># Define the SAC Agent for Discrete Actions</span>
<span class="k">class</span> <span class="nc">SACAgentRAM</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="c1"># Parse hyperparameters from config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">alpha</span>  <span class="c1"># Entropy temperature</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">tau</span>  <span class="c1"># Target smoothing coefficient</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_update_interval</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">target_update_interval</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">automatic_alpha</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">automatic_alpha</span>
        
        <span class="c1"># Validate observation space</span>
        <span class="n">continuous</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="n">continuous</span><span class="p">,</span> <span class="s1">'Observation space must be continuous with shape (n,)'</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"State dimensions: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    
        <span class="c1"># Validate action space</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Discrete</span><span class="p">),</span> <span class="s1">'Action space must be discrete'</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of actions: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        
        <span class="c1"># Parse hidden_sizes from string to tuple if necessary</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_sizes</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">hidden_sizes</span> <span class="o">=</span> <span class="n">ast</span><span class="o">.</span><span class="n">literal_eval</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_sizes</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">hidden_sizes</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_sizes</span>
        
        <span class="c1"># Initialize Replay Buffer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="o">=</span> <span class="n">ReplayBuffer</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">replay_size</span><span class="p">)</span>
        
        <span class="c1"># Initialize Policy Network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span> <span class="o">=</span> <span class="n">PolicyNetworkRAM</span><span class="p">(</span>
            <span class="n">input_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span><span class="p">,</span>
            <span class="n">hidden_sizes</span><span class="o">=</span><span class="n">hidden_sizes</span><span class="p">,</span>
            <span class="n">output_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_policy</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Initialize Q-Networks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span> <span class="o">=</span> <span class="n">QNetworkRAM</span><span class="p">(</span>
            <span class="n">input_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span><span class="p">,</span>
            <span class="n">hidden_sizes</span><span class="o">=</span><span class="n">hidden_sizes</span><span class="p">,</span>
            <span class="n">num_actions</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_q</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span> <span class="o">=</span> <span class="n">QNetworkRAM</span><span class="p">(</span>
            <span class="n">input_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span><span class="p">,</span>
            <span class="n">hidden_sizes</span><span class="o">=</span><span class="n">hidden_sizes</span><span class="p">,</span>
            <span class="n">num_actions</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_q</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Initialize Target Q-Networks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span> <span class="o">=</span> <span class="n">QNetworkRAM</span><span class="p">(</span>
            <span class="n">input_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span><span class="p">,</span>
            <span class="n">hidden_sizes</span><span class="o">=</span><span class="n">hidden_sizes</span><span class="p">,</span>
            <span class="n">num_actions</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_q</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span> <span class="o">=</span> <span class="n">QNetworkRAM</span><span class="p">(</span>
            <span class="n">input_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span><span class="p">,</span>
            <span class="n">hidden_sizes</span><span class="o">=</span><span class="n">hidden_sizes</span><span class="p">,</span>
            <span class="n">num_actions</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_q</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Synchronize target networks with main Q-networks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
        
        <span class="c1"># Automatic entropy tuning</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">automatic_alpha</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">target_entropy</span> <span class="o">=</span> <span class="o">-</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.98</span>  <span class="c1"># Slightly lower than maximum</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">alpha_optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">log_alpha</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_policy</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"Automatic alpha tuning enabled."</span><span class="p">)</span>
        
        <span class="c1"># Store environment</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">env</span> <span class="o">=</span> <span class="n">env</span>
        
        <span class="c1"># Warm up the replay buffer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">warm_up</span><span class="p">(</span><span class="n">initial_steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">normalize_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Normalize the state observations.</span>
<span class="sd">        Args:</span>
<span class="sd">            state (array-like or Tensor): Raw state.</span>
<span class="sd">        Returns:</span>
<span class="sd">            Tensor: Normalized state tensor.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="c1"># Convert NumPy array to PyTorch tensor</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># Ensure the tensor is on the correct device and of type float</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Unsupported state type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        
        <span class="c1"># Normalize the state</span>
        <span class="k">return</span> <span class="n">state</span> <span class="o">/</span> <span class="mf">255.0</span>

    
    <span class="k">def</span> <span class="nf">warm_up</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">initial_steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Populate the replay buffer with initial random experiences.</span>
<span class="sd">        Args:</span>
<span class="sd">            initial_steps (int): Number of initial random steps to perform.</span>
<span class="sd">        """</span>
        <span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">initial_steps</span><span class="p">):</span>
            <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># Take random action</span>
            <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">reward</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Clip rewards</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">push</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">terminated</span><span class="p">)</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
            <span class="k">if</span> <span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">:</span>
                <span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">evaluate</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Select action based on current policy.</span>
<span class="sd">        Args:</span>
<span class="sd">            state (array-like): Current state.</span>
<span class="sd">            evaluate (bool): If True, select the best action deterministically.</span>
<span class="sd">        Returns:</span>
<span class="sd">            int: Selected action.</span>
<span class="sd">        """</span>
        <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize_state</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>  <span class="c1"># [1, num_actions]</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">evaluate</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">probs</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="c1"># Validate action</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">action</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Sampled action </span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="s2"> is out of bounds."</span><span class="p">)</span>
        
        <span class="c1"># Log action probabilities for debugging</span>
        <span class="n">action_probs</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">probs</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">({</span>
            <span class="s1">'action_probabilities'</span><span class="p">:</span> <span class="n">wandb</span><span class="o">.</span><span class="n">Histogram</span><span class="p">(</span><span class="n">action_probs</span><span class="p">),</span>
            <span class="s1">'selected_action'</span><span class="p">:</span> <span class="n">action</span>
        <span class="p">})</span>
        
        <span class="k">return</span> <span class="n">action</span>
    
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">updates</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Update the SAC agent's networks.</span>
<span class="sd">        Args:</span>
<span class="sd">            updates (int): Current update step count.</span>
<span class="sd">        Returns:</span>
<span class="sd">            tuple: (q1_loss, q2_loss, policy_loss, entropy) or (None, None, None, None) if no update.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>  <span class="c1"># Return None for all values when not updating</span>

        <span class="c1"># Sample a minibatch from replay buffer</span>
        <span class="n">state_batch</span><span class="p">,</span> <span class="n">action_batch</span><span class="p">,</span> <span class="n">reward_batch</span><span class="p">,</span> <span class="n">next_state_batch</span><span class="p">,</span> <span class="n">terminated_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>

        <span class="c1"># Normalize states</span>
        <span class="n">state_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize_state</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span>
        <span class="n">next_state_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize_state</span><span class="p">(</span><span class="n">next_state_batch</span><span class="p">)</span>

        <span class="c1"># Compute target Q-values</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="c1"># Get logits and probabilities from the policy network for next states</span>
            <span class="n">next_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="p">(</span><span class="n">next_state_batch</span><span class="p">)</span>
            <span class="n">next_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">next_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
            <span class="n">next_log_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">next_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>

            <span class="c1"># Get target Q-values from target networks</span>
            <span class="n">target_q1_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span><span class="p">(</span><span class="n">next_state_batch</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
            <span class="n">target_q2_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span><span class="p">(</span><span class="n">next_state_batch</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
            <span class="n">target_q_values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">target_q1_values</span><span class="p">,</span> <span class="n">target_q2_values</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>

            <span class="c1"># Compute expected Q-values for next states</span>
            <span class="n">expected_q</span> <span class="o">=</span> <span class="p">(</span><span class="n">next_probs</span> <span class="o">*</span> <span class="p">(</span><span class="n">target_q_values</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">next_log_probs</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># [batch_size, 1]</span>

            <span class="c1"># Compute target Q</span>
            <span class="n">q_target</span> <span class="o">=</span> <span class="n">reward_batch</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">terminated_batch</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">expected_q</span>  <span class="c1"># [batch_size, 1]</span>

        <span class="c1"># Compute current Q-values from both Q-networks</span>
        <span class="n">current_q1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">action_batch</span><span class="p">)</span>  <span class="c1"># [batch_size, 1]</span>
        <span class="n">current_q2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">action_batch</span><span class="p">)</span>  <span class="c1"># [batch_size, 1]</span>
        
        <span class="c1"># Clip Q-values to prevent them from growing too large</span>
        <span class="n">current_q1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">current_q1</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">current_q2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">current_q2</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

        <span class="c1"># Compute Q-network losses</span>
        <span class="n">q1_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">current_q1</span><span class="p">,</span> <span class="n">q_target</span><span class="p">)</span>
        <span class="n">q2_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">current_q2</span><span class="p">,</span> <span class="n">q_target</span><span class="p">)</span>

        <span class="c1"># Update Q-networks</span>
        <span class="n">q1_loss_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">update_q_network</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">q1_loss</span><span class="p">)</span>
        <span class="n">q2_loss_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">update_q_network</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">q2_loss</span><span class="p">)</span>

        <span class="c1"># Compute policy loss and gradient norm</span>
        <span class="n">policy_loss_value</span><span class="p">,</span> <span class="n">grad_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="o">.</span><span class="n">update_policy</span><span class="p">(</span><span class="n">state_batch</span><span class="p">,</span> <span class="n">action_batch</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="p">(</span><span class="n">state_batch</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="p">(</span><span class="n">state_batch</span><span class="p">))</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">action_batch</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        
        <span class="c1"># Compute entropy for logging</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">entropy</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="p">(</span><span class="n">state_batch</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="p">(</span><span class="n">state_batch</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">entropy</span> <span class="o">=</span> <span class="o">-</span><span class="n">entropy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="c1"># Optional: Update alpha for entropy temperature</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">automatic_alpha</span><span class="p">:</span>
            <span class="c1"># Recompute log_probs for entropy adjustment</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
            <span class="n">log_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
            <span class="n">entropy</span> <span class="o">=</span> <span class="o">-</span> <span class="p">(</span><span class="n">log_probs</span> <span class="o">*</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

            <span class="n">alpha_loss</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">entropy</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_entropy</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">alpha_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">alpha_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">alpha_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="c1"># Clamp alpha to prevent it from becoming too small</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_alpha</span><span class="o">.</span><span class="n">exp</span><span class="p">(),</span> <span class="nb">min</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="c1">#print(f"Updated alpha: {self.alpha.item():.4f}, Alpha Loss: {alpha_loss.item():.4f}")</span>

        <span class="c1"># Update target networks</span>
        <span class="k">if</span> <span class="n">updates</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_update_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">soft_update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">soft_update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span><span class="p">)</span>
            <span class="c1">#print("Target networks updated.")</span>

        <span class="k">return</span> <span class="n">q1_loss_value</span><span class="p">,</span> <span class="n">q2_loss_value</span><span class="p">,</span> <span class="n">policy_loss_value</span><span class="p">,</span> <span class="n">entropy</span>
    
    <span class="k">def</span> <span class="nf">soft_update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">target_net</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Perform soft update of target network parameters.</span>
<span class="sd">        Args:</span>
<span class="sd">            net (nn.Module): Main network.</span>
<span class="sd">            target_net (nn.Module): Target network.</span>
<span class="sd">        """</span>
        <span class="k">for</span> <span class="n">param</span><span class="p">,</span> <span class="n">target_param</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">target_net</span><span class="o">.</span><span class="n">parameters</span><span class="p">()):</span>
            <span class="n">target_param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">*</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">)</span> <span class="o">*</span> <span class="n">target_param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">train_agent</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_episodes</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="p">,</span> <span class="n">criterion_episodes</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Train the SAC agent.</span>
<span class="sd">        Args:</span>
<span class="sd">            max_episodes (int): Maximum number of episodes for training.</span>
<span class="sd">            stop_criterion (function): Function to determine stopping condition.</span>
<span class="sd">            criterion_episodes (int): Number of episodes to evaluate the stopping criterion.</span>
<span class="sd">        """</span>
        <span class="n">total_rewards</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">updates</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">best_avg_reward</span> <span class="o">=</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s1">'inf'</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_episodes</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
            <span class="n">terminated</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">truncated</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">episode_reward</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">steps</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">while</span> <span class="ow">not</span> <span class="p">(</span><span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">)</span> <span class="ow">and</span> <span class="n">steps</span> <span class="o">&lt;</span> <span class="mi">10000</span><span class="p">:</span>  <span class="c1"># Prevent infinite loops</span>
                <span class="c1"># Select action by following policy</span>
                <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

                <span class="c1"># Send the action to the environment</span>
                <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

                <span class="c1"># Clip reward</span>
                <span class="n">reward</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">reward</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

                <span class="c1"># Add experience to replay buffer</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">push</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">terminated</span><span class="p">)</span>

                <span class="c1"># Update state</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
                <span class="n">episode_reward</span> <span class="o">+=</span> <span class="n">reward</span>
                <span class="n">steps</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="c1"># Update Q-network and policy</span>
                <span class="n">update_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">updates</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">update_results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">q1_loss</span><span class="p">,</span> <span class="n">q2_loss</span><span class="p">,</span> <span class="n">policy_loss</span><span class="p">,</span> <span class="n">entropy</span> <span class="o">=</span> <span class="n">update_results</span>
                    <span class="n">updates</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">q1_loss</span><span class="p">,</span> <span class="n">q2_loss</span><span class="p">,</span> <span class="n">policy_loss</span><span class="p">,</span> <span class="n">entropy</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

            <span class="c1"># Append the reward for this episode</span>
            <span class="n">total_rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">episode_reward</span><span class="p">)</span>

            <span class="c1"># Prepare logging dictionary</span>
            <span class="n">log_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">'episode'</span><span class="p">:</span> <span class="n">episode</span><span class="p">,</span>
                <span class="s1">'episode_reward'</span><span class="p">:</span> <span class="n">episode_reward</span><span class="p">,</span>
                <span class="s1">'steps'</span><span class="p">:</span> <span class="n">steps</span><span class="p">,</span>
                <span class="s1">'updates'</span><span class="p">:</span> <span class="n">updates</span><span class="p">,</span>
                <span class="s1">'alpha'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">automatic_alpha</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="k">if</span> <span class="n">q1_loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">log_dict</span><span class="o">.</span><span class="n">update</span><span class="p">({</span>
                    <span class="s1">'q1_loss'</span><span class="p">:</span> <span class="n">q1_loss</span><span class="p">,</span>
                    <span class="s1">'q2_loss'</span><span class="p">:</span> <span class="n">q2_loss</span><span class="p">,</span>
                    <span class="s1">'policy_loss'</span><span class="p">:</span> <span class="n">policy_loss</span><span class="p">,</span>
                    <span class="s1">'entropy'</span><span class="p">:</span> <span class="n">entropy</span><span class="p">,</span>
                <span class="p">})</span>

            <span class="c1"># Log metrics to W&amp;B</span>
            <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">log_dict</span><span class="p">)</span>

            <span class="c1"># Print progress</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Episode </span><span class="si">{</span><span class="n">episode</span><span class="si">}</span><span class="s2">: Reward = </span><span class="si">{</span><span class="n">episode_reward</span><span class="si">}</span><span class="s2">, Steps = </span><span class="si">{</span><span class="n">steps</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

            <span class="c1"># Check stopping criterion</span>
            <span class="k">if</span> <span class="n">episode</span> <span class="o">&gt;=</span> <span class="n">criterion_episodes</span><span class="p">:</span>
                <span class="n">recent_rewards</span> <span class="o">=</span> <span class="n">total_rewards</span><span class="p">[</span><span class="o">-</span><span class="n">criterion_episodes</span><span class="p">:]</span>
                <span class="k">if</span> <span class="n">stop_criterion</span><span class="p">(</span><span class="n">recent_rewards</span><span class="p">):</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Stopping criterion satisfied after </span><span class="si">{</span><span class="n">episode</span><span class="si">}</span><span class="s2"> episodes"</span><span class="p">)</span>
                    <span class="k">break</span>

            <span class="c1"># Check and save the best model</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">total_rewards</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">criterion_episodes</span><span class="p">:</span>
                <span class="n">avg_reward</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">total_rewards</span><span class="p">[</span><span class="o">-</span><span class="n">criterion_episodes</span><span class="p">:])</span>
                <span class="k">if</span> <span class="n">avg_reward</span> <span class="o">&gt;</span> <span class="n">best_avg_reward</span><span class="p">:</span>
                    <span class="n">best_avg_reward</span> <span class="o">=</span> <span class="n">avg_reward</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="sa">f</span><span class="s1">'sac_discrete_boxing_ram_best_episode_</span><span class="si">{</span><span class="n">episode</span><span class="si">}</span><span class="s1">.pth'</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"New best average reward: </span><span class="si">{</span><span class="n">best_avg_reward</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">. Model saved."</span><span class="p">)</span>

        <span class="c1"># Plot rewards received during training</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">dpi</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">total_rewards</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">total_rewards</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Rewards per Episode'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Episode'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Rewards'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Training Rewards over Episodes'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower right'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Save the model parameters.</span>
<span class="sd">        Args:</span>
<span class="sd">            path (str): File path to save the model.</span>
<span class="sd">        """</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
            <span class="s1">'policy_net'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'q_net1'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'q_net2'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'target_q_net1'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'target_q_net2'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'alpha'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span>
            <span class="s1">'log_alpha'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_alpha</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">automatic_alpha</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="p">},</span> <span class="n">path</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Model saved to </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Load the model parameters.</span>
<span class="sd">        Args:</span>
<span class="sd">            path (str): File path to load the model from.</span>
<span class="sd">        """</span>
        <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'policy_net'</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'q_net1'</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'q_net2'</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'target_q_net1'</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'target_q_net2'</span><span class="p">])</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">automatic_alpha</span> <span class="ow">and</span> <span class="s1">'log_alpha'</span> <span class="ow">in</span> <span class="n">checkpoint</span> <span class="ow">and</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">'log_alpha'</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_alpha</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'log_alpha'</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_alpha</span><span class="o">.</span><span class="n">exp</span><span class="p">(),</span> <span class="nb">min</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">'alpha'</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Model loaded from </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Define the Sweep Agent Wrapper</span>
<span class="k">class</span> <span class="nc">AgentSAC</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="c1"># Instantiate SACAgentRAM with environment and config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">agent</span> <span class="o">=</span> <span class="n">SACAgentRAM</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_episodes</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="p">,</span> <span class="n">criterion_episodes</span><span class="p">):</span>
        <span class="c1"># Delegate training to SACAgentRAM</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">agent</span><span class="o">.</span><span class="n">train_agent</span><span class="p">(</span><span class="n">max_episodes</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="p">,</span> <span class="n">criterion_episodes</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="c1"># Delegate model saving to SACAgentRAM</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">agent</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="c1"># Delegate model loading to SACAgentRAM</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">agent</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

<span class="c1"># Define the Sweep Agent Function</span>
<span class="k">def</span> <span class="nf">sweep_agent</span><span class="p">():</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Initialize a new wandb run</span>
        <span class="k">with</span> <span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">()</span> <span class="k">as</span> <span class="n">run</span><span class="p">:</span>
            <span class="n">config</span> <span class="o">=</span> <span class="n">wandb</span><span class="o">.</span><span class="n">config</span>

            <span class="c1"># Create the environment with RAM observation type</span>
            <span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">'ALE/Boxing-v5'</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">"rgb_array_list"</span><span class="p">,</span> <span class="n">obs_type</span><span class="o">=</span><span class="s2">"ram"</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"Observation Space Shape:"</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"Action Space:"</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">)</span>

            <span class="c1"># Ensure the observation is a 128-length vector</span>
            <span class="k">assert</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">128</span><span class="p">,),</span> <span class="s2">"Observation space must be a 128-length vector."</span>

            <span class="c1"># Instantiate AgentSAC with current wandb config</span>
            <span class="n">agent</span> <span class="o">=</span> <span class="n">AgentSAC</span><span class="p">(</span><span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>

            <span class="c1"># Define stopping criterion (optional)</span>
            <span class="k">def</span> <span class="nf">stopping_criterion</span><span class="p">(</span><span class="n">rewards</span><span class="p">):</span>
                <span class="c1"># Example: stop if average reward over last 5 episodes &gt;= 100</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rewards</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">100</span>

            <span class="c1"># Start training</span>
            <span class="n">agent</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
                <span class="n">max_episodes</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">num_episodes</span><span class="p">,</span>
                <span class="n">stop_criterion</span><span class="o">=</span><span class="n">stopping_criterion</span><span class="p">,</span>
                <span class="n">criterion_episodes</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">criterion_episodes</span>
            <span class="p">)</span>

            <span class="c1"># Save the trained model</span>
            <span class="n">agent</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s1">'sac_discrete_boxing_ram.pth'</span><span class="p">)</span>

            <span class="c1"># Close the environment after training</span>
            <span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="c1"># Log the error to wandb</span>
        <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">({</span><span class="s2">"error"</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)})</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"An error occurred: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="c1"># Ensure the environment is closed in case of an error</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">pass</span>

<span class="c1"># Define the Sweep Configuration for SAC</span>
<span class="n">sweep_configuration_sac</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"method"</span><span class="p">:</span> <span class="s2">"random"</span><span class="p">,</span>  <span class="c1"># Options: "grid", "random", "bayes"</span>
    <span class="s2">"metric"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"episode_reward"</span><span class="p">,</span>  <span class="c1"># The metric to optimize</span>
        <span class="s2">"goal"</span><span class="p">:</span> <span class="s2">"maximize"</span>         <span class="c1"># Whether to "minimize" or "maximize"</span>
    <span class="p">},</span>
    <span class="s2">"parameters"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"lr_policy"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Learning rate for the policy network</span>
            <span class="s2">"distribution"</span><span class="p">:</span> <span class="s2">"uniform"</span><span class="p">,</span>
            <span class="s2">"min"</span><span class="p">:</span> <span class="mf">1e-7</span><span class="p">,</span>
            <span class="s2">"max"</span><span class="p">:</span> <span class="mf">3e-4</span>
        <span class="p">},</span>
        <span class="s2">"lr_q"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Learning rate for the Q-networks</span>
            <span class="s2">"distribution"</span><span class="p">:</span> <span class="s2">"uniform"</span><span class="p">,</span>
            <span class="s2">"min"</span><span class="p">:</span> <span class="mf">1e-7</span><span class="p">,</span>
            <span class="s2">"max"</span><span class="p">:</span> <span class="mf">3e-4</span>
        <span class="p">},</span>
        <span class="s2">"gamma"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Discount factor for future rewards</span>
            <span class="s2">"distribution"</span><span class="p">:</span> <span class="s2">"uniform"</span><span class="p">,</span>
            <span class="s2">"min"</span><span class="p">:</span> <span class="mf">0.95</span><span class="p">,</span>
            <span class="s2">"max"</span><span class="p">:</span> <span class="mf">0.99</span>
        <span class="p">},</span>
        <span class="s2">"alpha"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Entropy temperature (only if automatic_alpha is False)</span>
            <span class="s2">"distribution"</span><span class="p">:</span> <span class="s2">"uniform"</span><span class="p">,</span>
            <span class="s2">"min"</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
            <span class="s2">"max"</span><span class="p">:</span> <span class="mf">0.5</span>
        <span class="p">},</span>
        <span class="s2">"tau"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Soft update coefficient for target networks</span>
            <span class="s2">"distribution"</span><span class="p">:</span> <span class="s2">"uniform"</span><span class="p">,</span>
            <span class="s2">"min"</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span>
            <span class="s2">"max"</span><span class="p">:</span> <span class="mf">0.01</span>
        <span class="p">},</span>
        <span class="s2">"batch_size"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Mini-batch size for updates</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">]</span>  <span class="c1"># Two discrete values</span>
        <span class="p">},</span>
        <span class="s2">"replay_size"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Replay buffer size</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mi">50000</span><span class="p">,</span> <span class="mi">100000</span><span class="p">]</span>  <span class="c1"># Two discrete values</span>
        <span class="p">},</span>
        <span class="s2">"hidden_sizes"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Architecture of hidden layers</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="s2">"(256,256)"</span><span class="p">,</span> <span class="s2">"(512,512)"</span><span class="p">,</span> <span class="s2">"(256,256,256)"</span><span class="p">]</span>  
        <span class="p">},</span>
        <span class="s2">"target_update_interval"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Frequency of target network updates</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Fixed to 1 for SAC</span>
        <span class="p">},</span>
        <span class="s2">"num_episodes"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Total number of training episodes</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mi">500</span><span class="p">]</span>  <span class="c1"># Fixed to 500</span>
        <span class="p">},</span>
        <span class="s2">"criterion_episodes"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Number of episodes for stopping criterion</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">]</span>  <span class="c1"># Fixed to 5</span>
        <span class="p">},</span>
        <span class="s2">"automatic_alpha"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Whether to use automatic entropy tuning</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span>  <span class="c1"># Toggle between automatic and manual</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c1"># Initialize the sweep</span>
<span class="n">sweep_id</span> <span class="o">=</span> <span class="n">wandb</span><span class="o">.</span><span class="n">sweep</span><span class="p">(</span><span class="n">sweep</span><span class="o">=</span><span class="n">sweep_configuration_sac</span><span class="p">,</span> <span class="n">project</span><span class="o">=</span><span class="s1">'SAC_Discrete_RAM'</span><span class="p">)</span>

<span class="c1"># Launch the Sweep with Limited Runs</span>
<span class="c1"># Adjust 'count' based on your computational resources</span>
<span class="n">wandb</span><span class="o">.</span><span class="n">agent</span><span class="p">(</span><span class="n">sweep_id</span><span class="p">,</span> <span class="n">function</span><span class="o">=</span><span class="n">sweep_agent</span><span class="p">,</span> <span class="n">count</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>  <span class="c1"># Example: 20 runs</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=a62304df-1052-4902-b7c5-a2f4d5cf646a">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">wandb</span> tristancarlisle/SAC_Discrete_RAM/sweeps/tc9vx463
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
<iframe src="https://wandb.ai/tristancarlisle/SAC_Discrete_RAM/sweeps/tc9vx463?jupyter=true" style="border:none;width:100%;height:420px;"></iframe>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=a60f2779-e112-4be3-8bec-4e1b28d805ca">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Soft-Actor-Critic-(SAC)-Image-Observations">Soft Actor-Critic (SAC) Image Observations<a class="anchor-link" href="#Soft-Actor-Critic-(SAC)-Image-Observations"></a></h4>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=cb42648f-1840-476b-a020-8468445ce244">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="Replay-buffer">Replay buffer<a class="anchor-link" href="#Replay-buffer"></a></h5>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=53340356-3b5a-44fb-b788-1731cb863ef2">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Added class replay buffer which stores transitions (state, action, reward, next_state, terminated) for off-policy learning. Itsa deque with a fixed capacity, supporting sampling of random batches for training.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=73d54174-534d-44d1-a3f8-3ff8a72528a1">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">ReplayBuffer</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">capacity</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">capacity</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">push</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">terminated</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">terminated</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">state_batch</span><span class="p">,</span> <span class="n">action_batch</span><span class="p">,</span> <span class="n">reward_batch</span><span class="p">,</span> <span class="n">next_state_batch</span><span class="p">,</span> <span class="n">terminated_batch</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">samples</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">state_batch</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">action_batch</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">reward_batch</span><span class="p">),</span>
                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">next_state_batch</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">terminated_batch</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=92712978-3b09-4347-90cd-7ae3ff8c10bb">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="Updated-Policy-Network">Updated Policy Network<a class="anchor-link" href="#Updated-Policy-Network"></a></h5>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=c1dc89ef-a04d-4951-805e-ec39ab077db6">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Outputs logits for a categorical distribution over actions and uses the categorical distribution to sample actions and compute log probabilities. Also includes entropy regularization in the policy loss to encourage exploration</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=9752edb6-6aa0-4238-99e0-bb9b90197296">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[8]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">PolicyNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>  <span class="c1"># Entropy temperature coefficient</span>
        
        <span class="c1"># CNN layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>  <span class="c1"># Input channels = 3 (RGB)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="p">)</span>
        
        <span class="c1"># Compute the size after CNN layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flattened_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_flattened_size</span><span class="p">(</span><span class="n">input_size</span><span class="p">)</span>
        
        <span class="c1"># Fully connected layers</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flattened_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        
        <span class="c1"># Output layer for action probabilities</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">output_size</span><span class="p">))</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_get_flattened_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">dummy_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">input_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># Batch size 1</span>
            <span class="n">conv_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_net</span><span class="p">(</span><span class="n">dummy_input</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">conv_out</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logits</span>  <span class="c1"># Logits for categorical distribution</span>
    
    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">)</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
        <span class="n">log_prob</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">action</span><span class="p">,</span> <span class="n">log_prob</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">probs</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=1c98780c-369d-4217-b195-3cbb47a67959">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="QNetwork">QNetwork<a class="anchor-link" href="#QNetwork"></a></h5>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=6cfbe997-4439-4047-8f8d-c6a2d0b39582">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Two Q-Networks (q_net1 and q_net2): Mitigate overestimation bias by taking the minimum of the two estimates.
Target Networks: target_q_net1 and target_q_net2 are used to compute target Q-values for stability.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=bd1657eb-99eb-4a3b-9eb0-843433a51444">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[9]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">QNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">num_actions</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="c1"># CNN layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>  <span class="c1"># Input channels = 3 (RGB)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="p">)</span>
        
        <span class="c1"># Compute the size after CNN layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flattened_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_flattened_size</span><span class="p">(</span><span class="n">input_size</span><span class="p">)</span>
        
        <span class="c1"># Fully connected layers</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flattened_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        
        <span class="c1"># Output layer for Q-values for each action</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">num_actions</span><span class="p">))</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_get_flattened_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">dummy_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">input_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># Batch size 1</span>
            <span class="n">conv_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_net</span><span class="p">(</span><span class="n">dummy_input</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">conv_out</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">q_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">q_values</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=47008e8a-6bf7-48dd-ba74-f714575c31cc">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="Updated-Agent-SAC">Updated Agent SAC<a class="anchor-link" href="#Updated-Agent-SAC"></a></h5>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=6f6b876a-7136-4108-96d1-49fef0874cba">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Lots of modifications
Parameters:
gamma: Discount factor.
alpha: Entropy temperature coefficient. Balances exploration and exploitation.
tau: Soft update coefficient for the target networks.
Methods:
select_action: Chooses an action based on the policy network, either for training (sampling) or evaluation (greedy).
update_parameters: Updates the Q-networks and policy network using samples from the replay buffer.
soft_update: Performs a soft update of the target networks' parameters.
train: Runs the training loop, collecting experiences and updating the networks.
save and load: Save and load model parameters.
Training Loop
Episodes: Runs for a specified number of episodes.
Interaction: In each step, the agent selects an action, observes the next state and reward, and stores the transition in the replay buffer.
Parameter Updates: After each step, the agent updates the networks using samples from the replay buffer.
Logging: Prints the total reward for each episode and plots the rewards over time.
Entropy Regularization
Policy Loss: Incorporates the entropy term [log()] to encourage exploration.
Adjustable : The entropy temperature can be fixed or learned during training for adaptive exploration.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=ed83fd3b-9b12-4a6a-bfb3-fc418e19c20c">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[10]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">SACAgent</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
                 <span class="n">lr_policy</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">lr_q</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">replay_size</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
                 <span class="n">target_update_interval</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">tau</span><span class="o">=</span><span class="mf">0.005</span><span class="p">):</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">env</span> <span class="o">=</span> <span class="n">env</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>  <span class="c1"># Entropy temperature</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">=</span> <span class="n">tau</span>  <span class="c1"># Target smoothing coefficient</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_update_interval</span> <span class="o">=</span> <span class="n">target_update_interval</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation_shape</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span>
        
        <span class="c1"># Replay buffer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="o">=</span> <span class="n">ReplayBuffer</span><span class="p">(</span><span class="n">replay_size</span><span class="p">)</span>
        
        <span class="c1"># Policy network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span> <span class="o">=</span> <span class="n">PolicyNetwork</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_shape</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span> <span class="n">lr_policy</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
        
        <span class="c1"># Q-networks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span> <span class="o">=</span> <span class="n">QNetwork</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_shape</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span> <span class="n">lr_q</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span> <span class="o">=</span> <span class="n">QNetwork</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_shape</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span> <span class="n">lr_q</span><span class="p">)</span>
        
        <span class="c1"># Target Q-networks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span> <span class="o">=</span> <span class="n">QNetwork</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_shape</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span> <span class="n">lr_q</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span> <span class="o">=</span> <span class="n">QNetwork</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_shape</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span> <span class="n">lr_q</span><span class="p">)</span>
        
        <span class="c1"># Copy parameters from Q-networks to target networks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
        
        <span class="c1"># Loss function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">select_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">evaluate</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># (1, C, H, W)</span>
        <span class="k">if</span> <span class="n">evaluate</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">action</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                <span class="n">action</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">action</span>
    
    <span class="k">def</span> <span class="nf">update_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">updates</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
            <span class="k">return</span>
        
        <span class="n">state_batch</span><span class="p">,</span> <span class="n">action_batch</span><span class="p">,</span> <span class="n">reward_batch</span><span class="p">,</span> <span class="n">next_state_batch</span><span class="p">,</span> <span class="n">terminated_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        
        <span class="c1"># Convert batches to tensors</span>
        <span class="n">state_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># (batch_size, C, H, W)</span>
        <span class="n">next_state_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">next_state_batch</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">action_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">action_batch</span><span class="p">)</span>
        <span class="n">reward_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">reward_batch</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">terminated_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">terminated_batch</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="c1"># Next action probabilities and log probabilities</span>
            <span class="n">next_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="p">(</span><span class="n">next_state_batch</span><span class="p">)</span>
            <span class="n">next_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">next_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">next_log_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">next_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            
            <span class="c1"># Compute target Q-values</span>
            <span class="n">target_q1_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span><span class="p">(</span><span class="n">next_state_batch</span><span class="p">)</span>
            <span class="n">target_q2_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span><span class="p">(</span><span class="n">next_state_batch</span><span class="p">)</span>
            <span class="n">target_q_values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">target_q1_values</span><span class="p">,</span> <span class="n">target_q2_values</span><span class="p">)</span>
            <span class="n">next_q</span> <span class="o">=</span> <span class="p">(</span><span class="n">next_probs</span> <span class="o">*</span> <span class="p">(</span><span class="n">target_q_values</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">next_log_probs</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            
            <span class="c1"># Compute target values</span>
            <span class="n">q_target</span> <span class="o">=</span> <span class="n">reward_batch</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">terminated_batch</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">next_q</span>
        
        <span class="c1"># Compute current Q-values</span>
        <span class="n">current_q1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">action_batch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">current_q2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">action_batch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        
        <span class="c1"># Compute Q-network losses</span>
        <span class="n">q1_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">current_q1</span><span class="p">,</span> <span class="n">q_target</span><span class="p">)</span>
        <span class="n">q2_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">current_q2</span><span class="p">,</span> <span class="n">q_target</span><span class="p">)</span>
        
        <span class="c1"># Update Q-networks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">q1_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">q2_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        
        <span class="c1"># Update policy network</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">log_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="n">q1_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span>
        <span class="n">q2_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span>
        <span class="n">min_q_values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">q1_values</span><span class="p">,</span> <span class="n">q2_values</span><span class="p">)</span>
        
        <span class="n">policy_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">probs</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">log_probs</span> <span class="o">-</span> <span class="n">min_q_values</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">policy_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        
        <span class="c1"># Update target networks</span>
        <span class="k">if</span> <span class="n">updates</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_update_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">soft_update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">soft_update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">soft_update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">target_net</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">param</span><span class="p">,</span> <span class="n">target_param</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">target_net</span><span class="o">.</span><span class="n">parameters</span><span class="p">()):</span>
            <span class="n">target_param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">*</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">)</span> <span class="o">*</span> <span class="n">target_param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_episodes</span><span class="p">,</span> <span class="n">max_steps_per_episode</span><span class="p">,</span> <span class="n">updates_per_step</span><span class="p">):</span>
        <span class="n">total_rewards</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">updates</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_episodes</span><span class="p">):</span>
            <span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
            <span class="n">episode_reward</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_steps_per_episode</span><span class="p">):</span>
                <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_action</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
                <span class="n">episode_reward</span> <span class="o">+=</span> <span class="n">reward</span>
                
                <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">push</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">terminated</span><span class="p">)</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
                
                <span class="c1"># Update parameters</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">update_parameters</span><span class="p">(</span><span class="n">updates</span><span class="p">)</span>
                <span class="n">updates</span> <span class="o">+=</span> <span class="mi">1</span>
                
                <span class="k">if</span> <span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">:</span>
                    <span class="k">break</span>
            <span class="n">total_rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">episode_reward</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Episode </span><span class="si">{</span><span class="n">episode</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">: Total Reward = </span><span class="si">{</span><span class="n">episode_reward</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        
        <span class="c1"># Plotting rewards</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">dpi</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">total_rewards</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Episode'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Total Reward'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Training Rewards over Episodes'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
            <span class="s1">'policy_net'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'q_net1'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'q_net2'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'target_q_net1'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'target_q_net2'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
        <span class="p">},</span> <span class="n">path</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'policy_net'</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'q_net1'</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'q_net2'</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'target_q_net1'</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'target_q_net2'</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=0f856aea-41c3-4206-9c5b-4afdee9b43e6">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[13]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">'ALE/Boxing-v5'</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">"rgb_array_list"</span><span class="p">)</span>

<span class="c1"># Hyperparameters</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.99</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">hidden_sizes</span> <span class="o">=</span> <span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
<span class="n">lr_policy</span> <span class="o">=</span> <span class="mf">1e-4</span>
<span class="n">lr_q</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">replay_size</span> <span class="o">=</span> <span class="mi">100000</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">target_update_interval</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">tau</span> <span class="o">=</span> <span class="mf">0.005</span>
<span class="n">num_episodes</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">max_steps_per_episode</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">updates_per_step</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># Initialize the SAC agent</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">SACAgent</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">lr_policy</span><span class="p">,</span> <span class="n">lr_q</span><span class="p">,</span> <span class="n">replay_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                 <span class="n">target_update_interval</span><span class="p">,</span> <span class="n">tau</span><span class="p">)</span>

<span class="c1"># Train the agent</span>
<span class="n">agent</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">num_episodes</span><span class="p">,</span> <span class="n">max_steps_per_episode</span><span class="p">,</span> <span class="n">updates_per_step</span><span class="p">)</span>

<span class="c1"># Visualize one episode</span>
<span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="n">terminated</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">truncated</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">frames</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">while</span> <span class="ow">not</span> <span class="p">(</span><span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">):</span>
    <span class="n">frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">())</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">select_action</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">evaluate</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
    <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">reward</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total Reward: </span><span class="si">{</span><span class="n">total_reward</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Close the environment</span>
<span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="c1"># Create and play video clip using the frames and given fps</span>
<span class="n">clip</span> <span class="o">=</span> <span class="n">mpy</span><span class="o">.</span><span class="n">ImageSequenceClip</span><span class="p">(</span><span class="n">frames</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">clip</span><span class="o">.</span><span class="n">ipython_display</span><span class="p">(</span><span class="n">rd_kwargs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">logger</span><span class="o">=</span><span class="kc">None</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Episode 1: Total Reward = -2.0
Episode 2: Total Reward = -2.0
Episode 3: Total Reward = 2.0
Episode 4: Total Reward = 6.0
Episode 5: Total Reward = -1.0
Episode 6: Total Reward = -3.0
Episode 7: Total Reward = 0.0
Episode 8: Total Reward = 7.0
Episode 9: Total Reward = -2.0
Episode 10: Total Reward = 0.0
Episode 11: Total Reward = -12.0
Episode 12: Total Reward = -9.0
Episode 13: Total Reward = -1.0
Episode 14: Total Reward = 0.0
Episode 15: Total Reward = 0.0
Episode 16: Total Reward = 6.0
Episode 17: Total Reward = 1.0
Episode 18: Total Reward = -1.0
Episode 19: Total Reward = 0.0
Episode 20: Total Reward = 1.0
Episode 21: Total Reward = -1.0
Episode 22: Total Reward = -7.0
Episode 23: Total Reward = -8.0
Episode 24: Total Reward = 4.0
Episode 25: Total Reward = 8.0
Episode 26: Total Reward = 5.0
Episode 27: Total Reward = -5.0
Episode 28: Total Reward = 1.0
Episode 29: Total Reward = -5.0
Episode 30: Total Reward = -3.0
Episode 31: Total Reward = -17.0
Episode 32: Total Reward = -3.0
Episode 33: Total Reward = 4.0
Episode 34: Total Reward = -4.0
Episode 35: Total Reward = -2.0
Episode 36: Total Reward = 0.0
Episode 37: Total Reward = 1.0
Episode 38: Total Reward = -1.0
Episode 39: Total Reward = 8.0
Episode 40: Total Reward = 0.0
Episode 41: Total Reward = 6.0
Episode 42: Total Reward = 2.0
Episode 43: Total Reward = 0.0
Episode 44: Total Reward = -3.0
Episode 45: Total Reward = -4.0
Episode 46: Total Reward = 5.0
Episode 47: Total Reward = -2.0
Episode 48: Total Reward = -1.0
Episode 49: Total Reward = 1.0
Episode 50: Total Reward = 1.0
Episode 51: Total Reward = 0.0
Episode 52: Total Reward = -1.0
Episode 53: Total Reward = 0.0
Episode 54: Total Reward = -3.0
Episode 55: Total Reward = -2.0
Episode 56: Total Reward = -6.0
Episode 57: Total Reward = -3.0
Episode 58: Total Reward = 7.0
Episode 59: Total Reward = 5.0
Episode 60: Total Reward = -12.0
Episode 61: Total Reward = 11.0
Episode 62: Total Reward = 0.0
Episode 63: Total Reward = 5.0
Episode 64: Total Reward = 4.0
Episode 65: Total Reward = 6.0
Episode 66: Total Reward = -23.0
Episode 67: Total Reward = -2.0
Episode 68: Total Reward = -2.0
Episode 69: Total Reward = -12.0
Episode 70: Total Reward = -2.0
Episode 71: Total Reward = 2.0
Episode 72: Total Reward = 3.0
Episode 73: Total Reward = -3.0
Episode 74: Total Reward = -8.0
Episode 75: Total Reward = -9.0
Episode 76: Total Reward = -5.0
Episode 77: Total Reward = -2.0
Episode 78: Total Reward = -3.0
Episode 79: Total Reward = 5.0
Episode 80: Total Reward = 6.0
Episode 81: Total Reward = 3.0
Episode 82: Total Reward = -1.0
Episode 83: Total Reward = 0.0
Episode 84: Total Reward = 4.0
Episode 85: Total Reward = -2.0
Episode 86: Total Reward = -6.0
Episode 87: Total Reward = 4.0
Episode 88: Total Reward = -7.0
Episode 89: Total Reward = 4.0
Episode 90: Total Reward = -3.0
Episode 91: Total Reward = 3.0
Episode 92: Total Reward = -8.0
Episode 93: Total Reward = 2.0
Episode 94: Total Reward = 4.0
Episode 95: Total Reward = 5.0
Episode 96: Total Reward = -4.0
Episode 97: Total Reward = -1.0
Episode 98: Total Reward = -2.0
Episode 99: Total Reward = -6.0
Episode 100: Total Reward = -12.0
Episode 101: Total Reward = 0.0
Episode 102: Total Reward = -4.0
Episode 103: Total Reward = -7.0
Episode 104: Total Reward = -2.0
Episode 105: Total Reward = -5.0
Episode 106: Total Reward = -4.0
Episode 107: Total Reward = -5.0
Episode 108: Total Reward = 1.0
Episode 109: Total Reward = -3.0
Episode 110: Total Reward = 1.0
Episode 111: Total Reward = 4.0
Episode 112: Total Reward = 4.0
Episode 113: Total Reward = -5.0
Episode 114: Total Reward = -2.0
Episode 115: Total Reward = -1.0
Episode 116: Total Reward = 2.0
Episode 117: Total Reward = 0.0
Episode 118: Total Reward = -13.0
Episode 119: Total Reward = -8.0
Episode 120: Total Reward = -1.0
Episode 121: Total Reward = 2.0
Episode 122: Total Reward = -7.0
Episode 123: Total Reward = -16.0
Episode 124: Total Reward = -1.0
Episode 125: Total Reward = -12.0
Episode 126: Total Reward = -7.0
Episode 127: Total Reward = 1.0
Episode 128: Total Reward = 4.0
Episode 129: Total Reward = -2.0
Episode 130: Total Reward = -2.0
Episode 131: Total Reward = -4.0
Episode 132: Total Reward = -4.0
Episode 133: Total Reward = -5.0
Episode 134: Total Reward = -1.0
Episode 135: Total Reward = 2.0
Episode 136: Total Reward = 4.0
Episode 137: Total Reward = -2.0
Episode 138: Total Reward = -4.0
Episode 139: Total Reward = -5.0
Episode 140: Total Reward = 5.0
Episode 141: Total Reward = 2.0
Episode 142: Total Reward = -3.0
Episode 143: Total Reward = -5.0
Episode 144: Total Reward = -3.0
Episode 145: Total Reward = 4.0
Episode 146: Total Reward = 1.0
Episode 147: Total Reward = 5.0
Episode 148: Total Reward = 8.0
Episode 149: Total Reward = -1.0
Episode 150: Total Reward = -2.0
Episode 151: Total Reward = 3.0
Episode 152: Total Reward = -3.0
Episode 153: Total Reward = -1.0
Episode 154: Total Reward = 5.0
Episode 155: Total Reward = 0.0
Episode 156: Total Reward = 4.0
Episode 157: Total Reward = 0.0
Episode 158: Total Reward = 0.0
Episode 159: Total Reward = -3.0
Episode 160: Total Reward = 7.0
Episode 161: Total Reward = -4.0
Episode 162: Total Reward = -3.0
Episode 163: Total Reward = -2.0
Episode 164: Total Reward = -16.0
Episode 165: Total Reward = -9.0
Episode 166: Total Reward = -3.0
Episode 167: Total Reward = -13.0
Episode 168: Total Reward = 0.0
Episode 169: Total Reward = 3.0
Episode 170: Total Reward = -2.0
Episode 171: Total Reward = 2.0
Episode 172: Total Reward = 4.0
Episode 173: Total Reward = 2.0
Episode 174: Total Reward = -10.0
Episode 175: Total Reward = 0.0
Episode 176: Total Reward = -15.0
Episode 177: Total Reward = -7.0
Episode 178: Total Reward = 7.0
Episode 179: Total Reward = 0.0
Episode 180: Total Reward = -8.0
Episode 181: Total Reward = 6.0
Episode 182: Total Reward = -4.0
Episode 183: Total Reward = 2.0
Episode 184: Total Reward = -2.0
Episode 185: Total Reward = -4.0
Episode 186: Total Reward = 6.0
Episode 187: Total Reward = 0.0
Episode 188: Total Reward = -9.0
Episode 189: Total Reward = 1.0
Episode 190: Total Reward = -6.0
Episode 191: Total Reward = 1.0
Episode 192: Total Reward = -4.0
Episode 193: Total Reward = -8.0
Episode 194: Total Reward = -4.0
Episode 195: Total Reward = 0.0
Episode 196: Total Reward = 3.0
Episode 197: Total Reward = -2.0
Episode 198: Total Reward = 1.0
Episode 199: Total Reward = -2.0
Episode 200: Total Reward = 1.0
Episode 201: Total Reward = 3.0
Episode 202: Total Reward = -16.0
Episode 203: Total Reward = -4.0
Episode 204: Total Reward = 5.0
Episode 205: Total Reward = -1.0
Episode 206: Total Reward = 7.0
Episode 207: Total Reward = 4.0
Episode 208: Total Reward = 6.0
Episode 209: Total Reward = 6.0
Episode 210: Total Reward = 0.0
Episode 211: Total Reward = -9.0
Episode 212: Total Reward = 1.0
Episode 213: Total Reward = -5.0
Episode 214: Total Reward = 1.0
Episode 215: Total Reward = -2.0
Episode 216: Total Reward = 6.0
Episode 217: Total Reward = -5.0
Episode 218: Total Reward = 0.0
Episode 219: Total Reward = 1.0
Episode 220: Total Reward = -8.0
Episode 221: Total Reward = -7.0
Episode 222: Total Reward = -1.0
Episode 223: Total Reward = -9.0
Episode 224: Total Reward = -4.0
Episode 225: Total Reward = -2.0
Episode 226: Total Reward = 8.0
Episode 227: Total Reward = 1.0
Episode 228: Total Reward = -5.0
Episode 229: Total Reward = -1.0
Episode 230: Total Reward = -23.0
Episode 231: Total Reward = 5.0
Episode 232: Total Reward = -2.0
Episode 233: Total Reward = 0.0
Episode 234: Total Reward = -8.0
Episode 235: Total Reward = -4.0
Episode 236: Total Reward = -9.0
Episode 237: Total Reward = 1.0
Episode 238: Total Reward = 0.0
Episode 239: Total Reward = 0.0
Episode 240: Total Reward = -5.0
Episode 241: Total Reward = -4.0
Episode 242: Total Reward = -8.0
Episode 243: Total Reward = 3.0
Episode 244: Total Reward = -6.0
Episode 245: Total Reward = 4.0
Episode 246: Total Reward = 0.0
Episode 247: Total Reward = -1.0
Episode 248: Total Reward = 1.0
Episode 249: Total Reward = 6.0
Episode 250: Total Reward = 2.0
Episode 251: Total Reward = 2.0
Episode 252: Total Reward = -4.0
Episode 253: Total Reward = 1.0
Episode 254: Total Reward = -2.0
Episode 255: Total Reward = -3.0
Episode 256: Total Reward = -14.0
Episode 257: Total Reward = -1.0
Episode 258: Total Reward = -4.0
Episode 259: Total Reward = 7.0
Episode 260: Total Reward = -20.0
Episode 261: Total Reward = 1.0
Episode 262: Total Reward = -1.0
Episode 263: Total Reward = -8.0
Episode 264: Total Reward = -2.0
Episode 265: Total Reward = 0.0
Episode 266: Total Reward = -5.0
Episode 267: Total Reward = -21.0
Episode 268: Total Reward = 2.0
Episode 269: Total Reward = -1.0
Episode 270: Total Reward = -15.0
Episode 271: Total Reward = -4.0
Episode 272: Total Reward = -9.0
Episode 273: Total Reward = 2.0
Episode 274: Total Reward = -2.0
Episode 275: Total Reward = -1.0
Episode 276: Total Reward = 0.0
Episode 277: Total Reward = -11.0
Episode 278: Total Reward = 5.0
Episode 279: Total Reward = -9.0
Episode 280: Total Reward = -1.0
Episode 281: Total Reward = 3.0
Episode 282: Total Reward = -2.0
Episode 283: Total Reward = 0.0
Episode 284: Total Reward = 4.0
Episode 285: Total Reward = -7.0
Episode 286: Total Reward = 5.0
Episode 287: Total Reward = 6.0
Episode 288: Total Reward = 1.0
Episode 289: Total Reward = -5.0
Episode 290: Total Reward = 11.0
Episode 291: Total Reward = -8.0
Episode 292: Total Reward = -6.0
Episode 293: Total Reward = -2.0
Episode 294: Total Reward = -13.0
Episode 295: Total Reward = 1.0
Episode 296: Total Reward = 0.0
Episode 297: Total Reward = -3.0
Episode 298: Total Reward = 0.0
Episode 299: Total Reward = -6.0
Episode 300: Total Reward = -3.0
Episode 301: Total Reward = 5.0
Episode 302: Total Reward = -8.0
Episode 303: Total Reward = 16.0
Episode 304: Total Reward = 5.0
Episode 305: Total Reward = 5.0
Episode 306: Total Reward = -1.0
Episode 307: Total Reward = 3.0
Episode 308: Total Reward = 0.0
Episode 309: Total Reward = -9.0
Episode 310: Total Reward = -4.0
Episode 311: Total Reward = 6.0
Episode 312: Total Reward = 0.0
Episode 313: Total Reward = 2.0
Episode 314: Total Reward = -1.0
Episode 315: Total Reward = 8.0
Episode 316: Total Reward = -3.0
Episode 317: Total Reward = -19.0
Episode 318: Total Reward = 5.0
Episode 319: Total Reward = -6.0
Episode 320: Total Reward = 0.0
Episode 321: Total Reward = -2.0
Episode 322: Total Reward = -2.0
Episode 323: Total Reward = -11.0
Episode 324: Total Reward = -9.0
Episode 325: Total Reward = -1.0
Episode 326: Total Reward = -4.0
Episode 327: Total Reward = -8.0
Episode 328: Total Reward = 0.0
Episode 329: Total Reward = -4.0
Episode 330: Total Reward = 1.0
Episode 331: Total Reward = 0.0
Episode 332: Total Reward = -12.0
Episode 333: Total Reward = 17.0
Episode 334: Total Reward = -12.0
Episode 335: Total Reward = 2.0
Episode 336: Total Reward = -3.0
Episode 337: Total Reward = 1.0
Episode 338: Total Reward = -4.0
Episode 339: Total Reward = -13.0
Episode 340: Total Reward = -15.0
Episode 341: Total Reward = 14.0
Episode 342: Total Reward = 1.0
Episode 343: Total Reward = 2.0
Episode 344: Total Reward = 3.0
Episode 345: Total Reward = 4.0
Episode 346: Total Reward = -3.0
Episode 347: Total Reward = 0.0
Episode 348: Total Reward = 0.0
Episode 349: Total Reward = 4.0
Episode 350: Total Reward = 2.0
Episode 351: Total Reward = 0.0
Episode 352: Total Reward = -16.0
Episode 353: Total Reward = 5.0
Episode 354: Total Reward = -5.0
Episode 355: Total Reward = -1.0
Episode 356: Total Reward = -2.0
Episode 357: Total Reward = -1.0
Episode 358: Total Reward = 0.0
Episode 359: Total Reward = -10.0
Episode 360: Total Reward = -2.0
Episode 361: Total Reward = 1.0
Episode 362: Total Reward = -7.0
Episode 363: Total Reward = -5.0
Episode 364: Total Reward = 0.0
Episode 365: Total Reward = -1.0
Episode 366: Total Reward = -1.0
Episode 367: Total Reward = -4.0
Episode 368: Total Reward = 4.0
Episode 369: Total Reward = 9.0
Episode 370: Total Reward = -3.0
Episode 371: Total Reward = 4.0
Episode 372: Total Reward = -4.0
Episode 373: Total Reward = 4.0
Episode 374: Total Reward = -6.0
Episode 375: Total Reward = -5.0
Episode 376: Total Reward = 2.0
Episode 377: Total Reward = 2.0
Episode 378: Total Reward = 3.0
Episode 379: Total Reward = -1.0
Episode 380: Total Reward = -9.0
Episode 381: Total Reward = 4.0
Episode 382: Total Reward = -4.0
Episode 383: Total Reward = -7.0
Episode 384: Total Reward = 7.0
Episode 385: Total Reward = -7.0
Episode 386: Total Reward = 5.0
Episode 387: Total Reward = -20.0
Episode 388: Total Reward = 2.0
Episode 389: Total Reward = -12.0
Episode 390: Total Reward = 3.0
Episode 391: Total Reward = -11.0
Episode 392: Total Reward = 0.0
Episode 393: Total Reward = 2.0
Episode 394: Total Reward = 4.0
Episode 395: Total Reward = -3.0
Episode 396: Total Reward = 4.0
Episode 397: Total Reward = -2.0
Episode 398: Total Reward = 0.0
Episode 399: Total Reward = 2.0
Episode 400: Total Reward = -1.0
Episode 401: Total Reward = -4.0
Episode 402: Total Reward = -1.0
Episode 403: Total Reward = -1.0
Episode 404: Total Reward = -4.0
Episode 405: Total Reward = 0.0
Episode 406: Total Reward = -3.0
Episode 407: Total Reward = -2.0
Episode 408: Total Reward = 6.0
Episode 409: Total Reward = -3.0
Episode 410: Total Reward = 3.0
Episode 411: Total Reward = 1.0
Episode 412: Total Reward = 10.0
Episode 413: Total Reward = 1.0
Episode 414: Total Reward = 0.0
Episode 415: Total Reward = 3.0
Episode 416: Total Reward = -10.0
Episode 417: Total Reward = 4.0
Episode 418: Total Reward = -7.0
Episode 419: Total Reward = -7.0
Episode 420: Total Reward = 1.0
Episode 421: Total Reward = 4.0
Episode 422: Total Reward = 4.0
Episode 423: Total Reward = -1.0
Episode 424: Total Reward = -6.0
Episode 425: Total Reward = -3.0
Episode 426: Total Reward = 0.0
Episode 427: Total Reward = 4.0
Episode 428: Total Reward = -1.0
Episode 429: Total Reward = -15.0
Episode 430: Total Reward = -8.0
Episode 431: Total Reward = 1.0
Episode 432: Total Reward = -6.0
Episode 433: Total Reward = -4.0
Episode 434: Total Reward = -1.0
Episode 435: Total Reward = 1.0
Episode 436: Total Reward = 2.0
Episode 437: Total Reward = -1.0
Episode 438: Total Reward = 3.0
Episode 439: Total Reward = -9.0
Episode 440: Total Reward = 2.0
Episode 441: Total Reward = -11.0
Episode 442: Total Reward = -8.0
Episode 443: Total Reward = 0.0
Episode 444: Total Reward = -6.0
Episode 445: Total Reward = 4.0
Episode 446: Total Reward = 0.0
Episode 447: Total Reward = 4.0
Episode 448: Total Reward = -3.0
Episode 449: Total Reward = -10.0
Episode 450: Total Reward = -1.0
Episode 451: Total Reward = -4.0
Episode 452: Total Reward = -9.0
Episode 453: Total Reward = 13.0
Episode 454: Total Reward = 1.0
Episode 455: Total Reward = -5.0
Episode 456: Total Reward = 6.0
Episode 457: Total Reward = 0.0
Episode 458: Total Reward = -3.0
Episode 459: Total Reward = -12.0
Episode 460: Total Reward = -1.0
Episode 461: Total Reward = 7.0
Episode 462: Total Reward = 5.0
Episode 463: Total Reward = 1.0
Episode 464: Total Reward = -6.0
Episode 465: Total Reward = -2.0
Episode 466: Total Reward = 1.0
Episode 467: Total Reward = -1.0
Episode 468: Total Reward = 0.0
Episode 469: Total Reward = 2.0
Episode 470: Total Reward = 7.0
Episode 471: Total Reward = -8.0
Episode 472: Total Reward = 6.0
Episode 473: Total Reward = 1.0
Episode 474: Total Reward = 7.0
Episode 475: Total Reward = -8.0
Episode 476: Total Reward = -7.0
Episode 477: Total Reward = 1.0
Episode 478: Total Reward = -7.0
Episode 479: Total Reward = 2.0
Episode 480: Total Reward = -5.0
Episode 481: Total Reward = -9.0
Episode 482: Total Reward = 0.0
Episode 483: Total Reward = -6.0
Episode 484: Total Reward = 9.0
Episode 485: Total Reward = -10.0
Episode 486: Total Reward = -12.0
Episode 487: Total Reward = 3.0
Episode 488: Total Reward = -1.0
Episode 489: Total Reward = -5.0
Episode 490: Total Reward = -15.0
Episode 491: Total Reward = 1.0
Episode 492: Total Reward = 5.0
Episode 493: Total Reward = -16.0
Episode 494: Total Reward = -2.0
Episode 495: Total Reward = -9.0
Episode 496: Total Reward = -1.0
Episode 497: Total Reward = -16.0
Episode 498: Total Reward = 0.0
Episode 499: Total Reward = -4.0
Episode 500: Total Reward = 3.0
Episode 501: Total Reward = 0.0
Episode 502: Total Reward = 0.0
Episode 503: Total Reward = -1.0
Episode 504: Total Reward = -4.0
Episode 505: Total Reward = -1.0
Episode 506: Total Reward = 6.0
Episode 507: Total Reward = 2.0
Episode 508: Total Reward = 7.0
Episode 509: Total Reward = -6.0
Episode 510: Total Reward = 3.0
Episode 511: Total Reward = -6.0
Episode 512: Total Reward = 0.0
Episode 513: Total Reward = -5.0
Episode 514: Total Reward = 1.0
Episode 515: Total Reward = -4.0
Episode 516: Total Reward = -3.0
Episode 517: Total Reward = 0.0
Episode 518: Total Reward = 3.0
Episode 519: Total Reward = 1.0
Episode 520: Total Reward = 0.0
Episode 521: Total Reward = -3.0
Episode 522: Total Reward = -2.0
Episode 523: Total Reward = -7.0
Episode 524: Total Reward = -5.0
Episode 525: Total Reward = 7.0
Episode 526: Total Reward = -5.0
Episode 527: Total Reward = -12.0
Episode 528: Total Reward = 1.0
Episode 529: Total Reward = 2.0
Episode 530: Total Reward = -6.0
Episode 531: Total Reward = -3.0
Episode 532: Total Reward = 1.0
Episode 533: Total Reward = 4.0
Episode 534: Total Reward = 10.0
Episode 535: Total Reward = -9.0
Episode 536: Total Reward = 4.0
Episode 537: Total Reward = -7.0
Episode 538: Total Reward = -5.0
Episode 539: Total Reward = 9.0
Episode 540: Total Reward = 4.0
Episode 541: Total Reward = 5.0
Episode 542: Total Reward = 1.0
Episode 543: Total Reward = 7.0
Episode 544: Total Reward = -8.0
Episode 545: Total Reward = -11.0
Episode 546: Total Reward = 0.0
Episode 547: Total Reward = -1.0
Episode 548: Total Reward = 0.0
Episode 549: Total Reward = -5.0
Episode 550: Total Reward = 2.0
Episode 551: Total Reward = -1.0
Episode 552: Total Reward = -22.0
Episode 553: Total Reward = 2.0
Episode 554: Total Reward = 3.0
Episode 555: Total Reward = -1.0
Episode 556: Total Reward = 3.0
Episode 557: Total Reward = -3.0
Episode 558: Total Reward = -19.0
Episode 559: Total Reward = -6.0
Episode 560: Total Reward = -2.0
Episode 561: Total Reward = 0.0
Episode 562: Total Reward = 11.0
Episode 563: Total Reward = 4.0
Episode 564: Total Reward = 0.0
Episode 565: Total Reward = 6.0
Episode 566: Total Reward = -1.0
Episode 567: Total Reward = 5.0
Episode 568: Total Reward = -5.0
Episode 569: Total Reward = -9.0
Episode 570: Total Reward = -3.0
Episode 571: Total Reward = -2.0
Episode 572: Total Reward = -15.0
Episode 573: Total Reward = 4.0
Episode 574: Total Reward = 0.0
Episode 575: Total Reward = 0.0
Episode 576: Total Reward = 2.0
Episode 577: Total Reward = -4.0
Episode 578: Total Reward = -10.0
Episode 579: Total Reward = 7.0
Episode 580: Total Reward = 0.0
Episode 581: Total Reward = -11.0
Episode 582: Total Reward = -10.0
Episode 583: Total Reward = 3.0
Episode 584: Total Reward = 2.0
Episode 585: Total Reward = 0.0
Episode 586: Total Reward = 7.0
Episode 587: Total Reward = 6.0
Episode 588: Total Reward = 3.0
Episode 589: Total Reward = -10.0
Episode 590: Total Reward = -20.0
Episode 591: Total Reward = 4.0
Episode 592: Total Reward = 1.0
Episode 593: Total Reward = -5.0
Episode 594: Total Reward = -6.0
Episode 595: Total Reward = 0.0
Episode 596: Total Reward = -5.0
Episode 597: Total Reward = -3.0
Episode 598: Total Reward = 0.0
Episode 599: Total Reward = 3.0
Episode 600: Total Reward = 4.0
Episode 601: Total Reward = 3.0
Episode 602: Total Reward = 1.0
Episode 603: Total Reward = -7.0
Episode 604: Total Reward = 0.0
Episode 605: Total Reward = 4.0
Episode 606: Total Reward = 14.0
Episode 607: Total Reward = 4.0
Episode 608: Total Reward = 3.0
Episode 609: Total Reward = 0.0
Episode 610: Total Reward = -2.0
Episode 611: Total Reward = -4.0
Episode 612: Total Reward = 5.0
Episode 613: Total Reward = -6.0
Episode 614: Total Reward = -4.0
Episode 615: Total Reward = 3.0
Episode 616: Total Reward = 3.0
Episode 617: Total Reward = 5.0
Episode 618: Total Reward = -14.0
Episode 619: Total Reward = -3.0
Episode 620: Total Reward = -1.0
Episode 621: Total Reward = 0.0
Episode 622: Total Reward = 3.0
Episode 623: Total Reward = 4.0
Episode 624: Total Reward = 0.0
Episode 625: Total Reward = 7.0
Episode 626: Total Reward = 9.0
Episode 627: Total Reward = -17.0
Episode 628: Total Reward = 1.0
Episode 629: Total Reward = 4.0
Episode 630: Total Reward = -2.0
Episode 631: Total Reward = 0.0
Episode 632: Total Reward = -14.0
Episode 633: Total Reward = -1.0
Episode 634: Total Reward = -1.0
Episode 635: Total Reward = 0.0
Episode 636: Total Reward = 1.0
Episode 637: Total Reward = -7.0
Episode 638: Total Reward = 1.0
Episode 639: Total Reward = -1.0
Episode 640: Total Reward = -6.0
Episode 641: Total Reward = 2.0
Episode 642: Total Reward = 1.0
Episode 643: Total Reward = 5.0
Episode 644: Total Reward = -10.0
Episode 645: Total Reward = -8.0
Episode 646: Total Reward = -9.0
Episode 647: Total Reward = -4.0
Episode 648: Total Reward = -3.0
Episode 649: Total Reward = 4.0
Episode 650: Total Reward = 2.0
Episode 651: Total Reward = 4.0
Episode 652: Total Reward = -8.0
Episode 653: Total Reward = 1.0
Episode 654: Total Reward = -14.0
Episode 655: Total Reward = -2.0
Episode 656: Total Reward = -3.0
Episode 657: Total Reward = 0.0
Episode 658: Total Reward = 0.0
Episode 659: Total Reward = -8.0
Episode 660: Total Reward = -8.0
Episode 661: Total Reward = -7.0
Episode 662: Total Reward = -3.0
Episode 663: Total Reward = -2.0
Episode 664: Total Reward = -2.0
Episode 665: Total Reward = -1.0
Episode 666: Total Reward = 3.0
Episode 667: Total Reward = 4.0
Episode 668: Total Reward = -1.0
Episode 669: Total Reward = -8.0
Episode 670: Total Reward = 7.0
Episode 671: Total Reward = 0.0
Episode 672: Total Reward = -1.0
Episode 673: Total Reward = 2.0
Episode 674: Total Reward = -14.0
Episode 675: Total Reward = -2.0
Episode 676: Total Reward = 0.0
Episode 677: Total Reward = 2.0
Episode 678: Total Reward = 0.0
Episode 679: Total Reward = -5.0
Episode 680: Total Reward = -3.0
Episode 681: Total Reward = -6.0
Episode 682: Total Reward = 5.0
Episode 683: Total Reward = -1.0
Episode 684: Total Reward = 0.0
Episode 685: Total Reward = 2.0
Episode 686: Total Reward = -7.0
Episode 687: Total Reward = -4.0
Episode 688: Total Reward = 2.0
Episode 689: Total Reward = 3.0
Episode 690: Total Reward = 0.0
Episode 691: Total Reward = -2.0
Episode 692: Total Reward = -2.0
Episode 693: Total Reward = 1.0
Episode 694: Total Reward = -3.0
Episode 695: Total Reward = -9.0
Episode 696: Total Reward = 3.0
Episode 697: Total Reward = 1.0
Episode 698: Total Reward = 1.0
Episode 699: Total Reward = 2.0
Episode 700: Total Reward = 0.0
Episode 701: Total Reward = -7.0
Episode 702: Total Reward = -4.0
Episode 703: Total Reward = 1.0
Episode 704: Total Reward = -5.0
Episode 705: Total Reward = 1.0
Episode 706: Total Reward = -3.0
Episode 707: Total Reward = 4.0
Episode 708: Total Reward = -13.0
Episode 709: Total Reward = -4.0
Episode 710: Total Reward = -13.0
Episode 711: Total Reward = -2.0
Episode 712: Total Reward = -7.0
Episode 713: Total Reward = 3.0
Episode 714: Total Reward = 2.0
Episode 715: Total Reward = 3.0
Episode 716: Total Reward = 2.0
Episode 717: Total Reward = 3.0
Episode 718: Total Reward = -7.0
Episode 719: Total Reward = -3.0
Episode 720: Total Reward = 0.0
Episode 721: Total Reward = 6.0
Episode 722: Total Reward = -3.0
Episode 723: Total Reward = -1.0
Episode 724: Total Reward = -1.0
Episode 725: Total Reward = 0.0
Episode 726: Total Reward = -1.0
Episode 727: Total Reward = -9.0
Episode 728: Total Reward = -14.0
Episode 729: Total Reward = -7.0
Episode 730: Total Reward = 0.0
Episode 731: Total Reward = -3.0
Episode 732: Total Reward = 4.0
Episode 733: Total Reward = 3.0
Episode 734: Total Reward = 1.0
Episode 735: Total Reward = 0.0
Episode 736: Total Reward = 4.0
Episode 737: Total Reward = -6.0
Episode 738: Total Reward = -8.0
Episode 739: Total Reward = 1.0
Episode 740: Total Reward = 1.0
Episode 741: Total Reward = 3.0
Episode 742: Total Reward = 6.0
Episode 743: Total Reward = -6.0
Episode 744: Total Reward = 0.0
Episode 745: Total Reward = 5.0
Episode 746: Total Reward = -7.0
Episode 747: Total Reward = 1.0
Episode 748: Total Reward = -9.0
Episode 749: Total Reward = -10.0
Episode 750: Total Reward = -1.0
Episode 751: Total Reward = -5.0
Episode 752: Total Reward = -10.0
Episode 753: Total Reward = 4.0
Episode 754: Total Reward = -2.0
Episode 755: Total Reward = 6.0
Episode 756: Total Reward = 13.0
Episode 757: Total Reward = -2.0
Episode 758: Total Reward = 13.0
Episode 759: Total Reward = -3.0
Episode 760: Total Reward = -3.0
Episode 761: Total Reward = 15.0
Episode 762: Total Reward = -11.0
Episode 763: Total Reward = -8.0
Episode 764: Total Reward = -4.0
Episode 765: Total Reward = 6.0
Episode 766: Total Reward = 4.0
Episode 767: Total Reward = -20.0
Episode 768: Total Reward = 1.0
Episode 769: Total Reward = -5.0
Episode 770: Total Reward = -5.0
Episode 771: Total Reward = 4.0
Episode 772: Total Reward = 0.0
Episode 773: Total Reward = 4.0
Episode 774: Total Reward = -6.0
Episode 775: Total Reward = -8.0
Episode 776: Total Reward = 9.0
Episode 777: Total Reward = 9.0
Episode 778: Total Reward = -1.0
Episode 779: Total Reward = -6.0
Episode 780: Total Reward = 8.0
Episode 781: Total Reward = -5.0
Episode 782: Total Reward = 2.0
Episode 783: Total Reward = 6.0
Episode 784: Total Reward = -5.0
Episode 785: Total Reward = 3.0
Episode 786: Total Reward = 1.0
Episode 787: Total Reward = -17.0
Episode 788: Total Reward = 1.0
Episode 789: Total Reward = -4.0
Episode 790: Total Reward = 4.0
Episode 791: Total Reward = 1.0
Episode 792: Total Reward = -1.0
Episode 793: Total Reward = -1.0
Episode 794: Total Reward = -3.0
Episode 795: Total Reward = -22.0
Episode 796: Total Reward = -6.0
Episode 797: Total Reward = -4.0
Episode 798: Total Reward = -6.0
Episode 799: Total Reward = -21.0
Episode 800: Total Reward = -5.0
Episode 801: Total Reward = 7.0
Episode 802: Total Reward = 0.0
Episode 803: Total Reward = -13.0
Episode 804: Total Reward = 3.0
Episode 805: Total Reward = -7.0
Episode 806: Total Reward = 2.0
Episode 807: Total Reward = -3.0
Episode 808: Total Reward = -7.0
Episode 809: Total Reward = -2.0
Episode 810: Total Reward = 0.0
Episode 811: Total Reward = -5.0
Episode 812: Total Reward = -1.0
Episode 813: Total Reward = 2.0
Episode 814: Total Reward = 6.0
Episode 815: Total Reward = 4.0
Episode 816: Total Reward = -7.0
Episode 817: Total Reward = -4.0
Episode 818: Total Reward = -4.0
Episode 819: Total Reward = -7.0
Episode 820: Total Reward = 3.0
Episode 821: Total Reward = 5.0
Episode 822: Total Reward = -8.0
Episode 823: Total Reward = -1.0
Episode 824: Total Reward = 2.0
Episode 825: Total Reward = -2.0
Episode 826: Total Reward = -13.0
Episode 827: Total Reward = -7.0
Episode 828: Total Reward = -7.0
Episode 829: Total Reward = -7.0
Episode 830: Total Reward = 7.0
Episode 831: Total Reward = 6.0
Episode 832: Total Reward = 2.0
Episode 833: Total Reward = -10.0
Episode 834: Total Reward = 6.0
Episode 835: Total Reward = 0.0
Episode 836: Total Reward = 1.0
Episode 837: Total Reward = -8.0
Episode 838: Total Reward = 0.0
Episode 839: Total Reward = 5.0
Episode 840: Total Reward = -3.0
Episode 841: Total Reward = 4.0
Episode 842: Total Reward = 0.0
Episode 843: Total Reward = 0.0
Episode 844: Total Reward = -7.0
Episode 845: Total Reward = 0.0
Episode 846: Total Reward = 1.0
Episode 847: Total Reward = 4.0
Episode 848: Total Reward = 1.0
Episode 849: Total Reward = 6.0
Episode 850: Total Reward = 1.0
Episode 851: Total Reward = 1.0
Episode 852: Total Reward = 10.0
Episode 853: Total Reward = -4.0
Episode 854: Total Reward = -13.0
Episode 855: Total Reward = 0.0
Episode 856: Total Reward = -11.0
Episode 857: Total Reward = 0.0
Episode 858: Total Reward = 2.0
Episode 859: Total Reward = -3.0
Episode 860: Total Reward = 4.0
Episode 861: Total Reward = -1.0
Episode 862: Total Reward = -6.0
Episode 863: Total Reward = -2.0
Episode 864: Total Reward = 2.0
Episode 865: Total Reward = 2.0
Episode 866: Total Reward = -6.0
Episode 867: Total Reward = 7.0
Episode 868: Total Reward = 5.0
Episode 869: Total Reward = -2.0
Episode 870: Total Reward = -1.0
Episode 871: Total Reward = 5.0
Episode 872: Total Reward = -4.0
Episode 873: Total Reward = -9.0
Episode 874: Total Reward = 0.0
Episode 875: Total Reward = 9.0
Episode 876: Total Reward = 5.0
Episode 877: Total Reward = 0.0
Episode 878: Total Reward = -8.0
Episode 879: Total Reward = -9.0
Episode 880: Total Reward = 1.0
Episode 881: Total Reward = 9.0
Episode 882: Total Reward = -10.0
Episode 883: Total Reward = -6.0
Episode 884: Total Reward = -2.0
Episode 885: Total Reward = -1.0
Episode 886: Total Reward = 6.0
Episode 887: Total Reward = 1.0
Episode 888: Total Reward = -13.0
Episode 889: Total Reward = -5.0
Episode 890: Total Reward = 1.0
Episode 891: Total Reward = 3.0
Episode 892: Total Reward = -9.0
Episode 893: Total Reward = -3.0
Episode 894: Total Reward = 3.0
Episode 895: Total Reward = 7.0
Episode 896: Total Reward = -4.0
Episode 897: Total Reward = 10.0
Episode 898: Total Reward = 4.0
Episode 899: Total Reward = 0.0
Episode 900: Total Reward = 17.0
Episode 901: Total Reward = 2.0
Episode 902: Total Reward = -2.0
Episode 903: Total Reward = -4.0
Episode 904: Total Reward = -3.0
Episode 905: Total Reward = 1.0
Episode 906: Total Reward = 1.0
Episode 907: Total Reward = 1.0
Episode 908: Total Reward = 5.0
Episode 909: Total Reward = -6.0
Episode 910: Total Reward = 3.0
Episode 911: Total Reward = 0.0
Episode 912: Total Reward = -13.0
Episode 913: Total Reward = -2.0
Episode 914: Total Reward = -2.0
Episode 915: Total Reward = -10.0
Episode 916: Total Reward = 4.0
Episode 917: Total Reward = -18.0
Episode 918: Total Reward = 5.0
Episode 919: Total Reward = 0.0
Episode 920: Total Reward = -1.0
Episode 921: Total Reward = -1.0
Episode 922: Total Reward = -1.0
Episode 923: Total Reward = 4.0
Episode 924: Total Reward = -4.0
Episode 925: Total Reward = -22.0
Episode 926: Total Reward = -21.0
Episode 927: Total Reward = -3.0
Episode 928: Total Reward = 5.0
Episode 929: Total Reward = -4.0
Episode 930: Total Reward = -8.0
Episode 931: Total Reward = 7.0
Episode 932: Total Reward = -1.0
Episode 933: Total Reward = 4.0
Episode 934: Total Reward = 0.0
Episode 935: Total Reward = -9.0
Episode 936: Total Reward = -2.0
Episode 937: Total Reward = -18.0
Episode 938: Total Reward = -1.0
Episode 939: Total Reward = -1.0
Episode 940: Total Reward = 0.0
Episode 941: Total Reward = -3.0
Episode 942: Total Reward = -2.0
Episode 943: Total Reward = 2.0
Episode 944: Total Reward = -2.0
Episode 945: Total Reward = -3.0
Episode 946: Total Reward = 0.0
Episode 947: Total Reward = -12.0
Episode 948: Total Reward = -3.0
Episode 949: Total Reward = -7.0
Episode 950: Total Reward = 0.0
Episode 951: Total Reward = 2.0
Episode 952: Total Reward = 1.0
Episode 953: Total Reward = -2.0
Episode 954: Total Reward = -3.0
Episode 955: Total Reward = 4.0
Episode 956: Total Reward = -4.0
Episode 957: Total Reward = 1.0
Episode 958: Total Reward = 11.0
Episode 959: Total Reward = -2.0
Episode 960: Total Reward = 2.0
Episode 961: Total Reward = 5.0
Episode 962: Total Reward = -16.0
Episode 963: Total Reward = 2.0
Episode 964: Total Reward = -6.0
Episode 965: Total Reward = -8.0
Episode 966: Total Reward = 1.0
Episode 967: Total Reward = 1.0
Episode 968: Total Reward = 1.0
Episode 969: Total Reward = -9.0
Episode 970: Total Reward = -4.0
Episode 971: Total Reward = -1.0
Episode 972: Total Reward = 2.0
Episode 973: Total Reward = -2.0
Episode 974: Total Reward = -8.0
Episode 975: Total Reward = -3.0
Episode 976: Total Reward = -2.0
Episode 977: Total Reward = 4.0
Episode 978: Total Reward = 8.0
Episode 979: Total Reward = 4.0
Episode 980: Total Reward = -1.0
Episode 981: Total Reward = 3.0
Episode 982: Total Reward = -1.0
Episode 983: Total Reward = -1.0
Episode 984: Total Reward = -4.0
Episode 985: Total Reward = 2.0
Episode 986: Total Reward = 2.0
Episode 987: Total Reward = -5.0
Episode 988: Total Reward = -7.0
Episode 989: Total Reward = -4.0
Episode 990: Total Reward = -2.0
Episode 991: Total Reward = -3.0
Episode 992: Total Reward = -13.0
Episode 993: Total Reward = -3.0
Episode 994: Total Reward = 2.0
Episode 995: Total Reward = -5.0
Episode 996: Total Reward = -1.0
Episode 997: Total Reward = -6.0
Episode 998: Total Reward = -7.0
Episode 999: Total Reward = -2.0
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>WARNING:py.warnings:/tmp/ipykernel_8720/2585660467.py:149: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown
  plt.show()

</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Episode 1000: Total Reward = 0.0
Total Reward: -100.0
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">AttributeError</span>                            Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[13], line 43</span>
<span class="ansi-green-intense-fg ansi-bold">     40</span> env<span style="color: rgb(98,98,98)">.</span>close()
<span class="ansi-green-intense-fg ansi-bold">     42</span> <span style="color: rgb(95,135,135)"># Create and play video clip using the frames and given fps</span>
<span class="ansi-green-fg">---&gt; 43</span> clip <span style="color: rgb(98,98,98)">=</span> mpy<span style="color: rgb(98,98,98)">.</span>ImageSequenceClip(frames, fps<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(98,98,98)">30</span>)
<span class="ansi-green-intense-fg ansi-bold">     44</span> clip<span style="color: rgb(98,98,98)">.</span>ipython_display(rd_kwargs<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(0,135,0)">dict</span>(logger<span style="color: rgb(98,98,98)">=</span><span class="ansi-bold" style="color: rgb(0,135,0)">None</span>))

File <span class="ansi-green-fg">~/miniconda3/envs/ReinforcementLearning/lib/python3.11/site-packages/moviepy/video/io/ImageSequenceClip.py:84</span>, in <span class="ansi-cyan-fg">ImageSequenceClip.__init__</span><span class="ansi-blue-fg">(self, sequence, fps, durations, with_mask, ismask, load_images)</span>
<span class="ansi-green-intense-fg ansi-bold">     82</span>    size <span style="color: rgb(98,98,98)">=</span> imread(sequence[<span style="color: rgb(98,98,98)">0</span>])<span style="color: rgb(98,98,98)">.</span>shape
<span class="ansi-green-intense-fg ansi-bold">     83</span> <span class="ansi-bold" style="color: rgb(0,135,0)">else</span>:
<span class="ansi-green-fg">---&gt; 84</span>    size <span style="color: rgb(98,98,98)">=</span> sequence[<span style="color: rgb(98,98,98)">0</span>]<span style="color: rgb(98,98,98)">.</span>shape
<span class="ansi-green-intense-fg ansi-bold">     86</span> <span class="ansi-bold" style="color: rgb(0,135,0)">for</span> image <span class="ansi-bold" style="color: rgb(175,0,255)">in</span> sequence:
<span class="ansi-green-intense-fg ansi-bold">     87</span>     image1<span style="color: rgb(98,98,98)">=</span>image

<span class="ansi-red-fg">AttributeError</span>: 'list' object has no attribute 'shape'</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=8b0f6da4-ad5f-440f-ac53-b275639c0f39">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Potential Improvements:
Frame Stacking: Stack multiple consecutive frames to give the agent a sense of motion.
Reward Clipping: Clip rewards to a certain range to stabilize training.
Normalization: Normalize input images and rewards.
Resize and grayscale images: To reduce training time and compute</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=41e6c30b-08c0-4723-a294-97290163b180">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[15]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">agent</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">"SAC_initial"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=027943e2-94de-49c2-b8f2-673e9dc55d9f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Hyperparameter-Sweep-Soft-Actor-Critic-(SAC)(RAM)">Hyperparameter Sweep Soft-Actor-Critic (SAC)(RAM)<a class="anchor-link" href="#Hyperparameter-Sweep-Soft-Actor-Critic-(SAC)(RAM)"></a></h4>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=faec58f3-8700-4a0c-ac54-afb39f7d19e4">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=9ffd0081-ff11-46b1-90d7-0af938f21e76">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Enable anomaly detection for debugging</span>
<span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">set_detect_anomaly</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Set device</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Using device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Set random seeds for reproducibility</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="c1"># Define the Policy Network for Discrete Actions</span>
<span class="k">class</span> <span class="nc">PolicyNetworkRAM</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="c1"># Define network layers</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">last_size</span> <span class="o">=</span> <span class="n">input_size</span>
        <span class="k">for</span> <span class="n">hidden_size</span> <span class="ow">in</span> <span class="n">hidden_sizes</span><span class="p">:</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">last_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
            <span class="n">last_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="c1"># Output layer for logits</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">last_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
        
        <span class="c1"># Optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Output logits for Categorical distribution</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">update_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">q_values</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Update the policy network.</span>
<span class="sd">        Args:</span>
<span class="sd">            states (Tensor): Current states [batch_size, state_dims]</span>
<span class="sd">            actions (Tensor): Actions taken [batch_size, 1]</span>
<span class="sd">            q_values (Tensor): Q-values corresponding to actions [batch_size]</span>
<span class="sd">        Returns:</span>
<span class="sd">            float: Policy loss value</span>
<span class="sd">        """</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">states</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">)</span>
        <span class="n">log_probs</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">actions</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># [batch_size]</span>
        <span class="n">entropy</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">entropy</span><span class="p">()</span>  <span class="c1"># [batch_size]</span>
        <span class="c1"># Policy loss with entropy regularization</span>
        <span class="n">policy_loss</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">log_probs</span> <span class="o">-</span> <span class="n">q_values</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">policy_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">policy_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

<span class="c1"># Define the Q-Network</span>
<span class="k">class</span> <span class="nc">QNetworkRAM</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">num_actions</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Define network layers</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">last_size</span> <span class="o">=</span> <span class="n">input_size</span>
        <span class="k">for</span> <span class="n">hidden_size</span> <span class="ow">in</span> <span class="n">hidden_sizes</span><span class="p">:</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">last_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
            <span class="n">last_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="c1"># Output layer for Q-values</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">last_size</span><span class="p">,</span> <span class="n">num_actions</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
        
        <span class="c1"># Loss function and optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># Output Q-values for each action</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
    
    <span class="k">def</span> <span class="nf">update_q_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">loss</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Update Q-network parameters.</span>
<span class="sd">        Args:</span>
<span class="sd">            parameters (iterable): Network parameters to update.</span>
<span class="sd">            loss (Tensor): Computed loss.</span>
<span class="sd">        Returns:</span>
<span class="sd">            float: Q-network loss value</span>
<span class="sd">        """</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="c1"># Gradient clipping</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">max_norm</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

<span class="c1"># Define the Replay Buffer</span>
<span class="k">class</span> <span class="nc">ReplayBuffer</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">capacity</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">capacity</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">push</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">terminated</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">terminated</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">state_batch</span><span class="p">,</span> <span class="n">action_batch</span><span class="p">,</span> <span class="n">reward_batch</span><span class="p">,</span> <span class="n">next_state_batch</span><span class="p">,</span> <span class="n">terminated_batch</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">samples</span><span class="p">)</span>
        
        <span class="c1"># Convert lists to single NumPy arrays for efficiency</span>
        <span class="n">state_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span>
        <span class="n">action_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">action_batch</span><span class="p">)</span>
        <span class="n">reward_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">reward_batch</span><span class="p">)</span>
        <span class="n">next_state_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">next_state_batch</span><span class="p">)</span>
        <span class="n">terminated_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">terminated_batch</span><span class="p">)</span>
        
        <span class="c1"># Convert to tensors and move to device</span>
        <span class="n">state_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># [batch_size, state_dims]</span>
        <span class="n">action_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">action_batch</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># [batch_size, 1]</span>
        <span class="n">reward_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">reward_batch</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># [batch_size, 1]</span>
        <span class="n">next_state_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">next_state_batch</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># [batch_size, state_dims]</span>
        <span class="n">terminated_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">terminated_batch</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># [batch_size, 1]</span>
        
        <span class="k">return</span> <span class="n">state_batch</span><span class="p">,</span> <span class="n">action_batch</span><span class="p">,</span> <span class="n">reward_batch</span><span class="p">,</span> <span class="n">next_state_batch</span><span class="p">,</span> <span class="n">terminated_batch</span>
    
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="p">)</span>

<span class="c1"># Define the SAC Agent for Discrete Actions</span>
<span class="k">class</span> <span class="nc">SACAgentRAM</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="c1"># Parse hyperparameters from config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">alpha</span>  <span class="c1"># Entropy temperature</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">tau</span>  <span class="c1"># Target smoothing coefficient</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_update_interval</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">target_update_interval</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">automatic_alpha</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">automatic_alpha</span>
        
        <span class="c1"># Validate observation space</span>
        <span class="n">continuous</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="n">continuous</span><span class="p">,</span> <span class="s1">'Observation space must be continuous with shape (n,)'</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"State dimensions: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    
        <span class="c1"># Validate action space</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Discrete</span><span class="p">),</span> <span class="s1">'Action space must be discrete'</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Number of actions: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        
        <span class="c1"># Parse hidden_sizes from string to tuple if necessary</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_sizes</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">hidden_sizes</span> <span class="o">=</span> <span class="n">ast</span><span class="o">.</span><span class="n">literal_eval</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_sizes</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">hidden_sizes</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_sizes</span>
        
        <span class="c1"># Initialize Replay Buffer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="o">=</span> <span class="n">ReplayBuffer</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">replay_size</span><span class="p">)</span>
        
        <span class="c1"># Initialize Policy Network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span> <span class="o">=</span> <span class="n">PolicyNetworkRAM</span><span class="p">(</span>
            <span class="n">input_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span><span class="p">,</span>
            <span class="n">hidden_sizes</span><span class="o">=</span><span class="n">hidden_sizes</span><span class="p">,</span>
            <span class="n">output_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_policy</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Initialize Q-Networks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span> <span class="o">=</span> <span class="n">QNetworkRAM</span><span class="p">(</span>
            <span class="n">input_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span><span class="p">,</span>
            <span class="n">hidden_sizes</span><span class="o">=</span><span class="n">hidden_sizes</span><span class="p">,</span>
            <span class="n">num_actions</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_q</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span> <span class="o">=</span> <span class="n">QNetworkRAM</span><span class="p">(</span>
            <span class="n">input_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span><span class="p">,</span>
            <span class="n">hidden_sizes</span><span class="o">=</span><span class="n">hidden_sizes</span><span class="p">,</span>
            <span class="n">num_actions</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_q</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Initialize Target Q-Networks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span> <span class="o">=</span> <span class="n">QNetworkRAM</span><span class="p">(</span>
            <span class="n">input_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span><span class="p">,</span>
            <span class="n">hidden_sizes</span><span class="o">=</span><span class="n">hidden_sizes</span><span class="p">,</span>
            <span class="n">num_actions</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_q</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span> <span class="o">=</span> <span class="n">QNetworkRAM</span><span class="p">(</span>
            <span class="n">input_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span><span class="p">,</span>
            <span class="n">hidden_sizes</span><span class="o">=</span><span class="n">hidden_sizes</span><span class="p">,</span>
            <span class="n">num_actions</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_q</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Synchronize target networks with main Q-networks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
        
        <span class="c1"># Automatic entropy tuning</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">automatic_alpha</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">target_entropy</span> <span class="o">=</span> <span class="o">-</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.98</span>  <span class="c1"># Slightly lower than maximum</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">alpha_optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">log_alpha</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_policy</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"Automatic alpha tuning enabled."</span><span class="p">)</span>
        
        <span class="c1"># Store environment</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">env</span> <span class="o">=</span> <span class="n">env</span>
    
    <span class="k">def</span> <span class="nf">policy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">evaluate</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Select action based on current policy.</span>
<span class="sd">        Args:</span>
<span class="sd">            state (array-like): Current state.</span>
<span class="sd">            evaluate (bool): If True, select the best action deterministically.</span>
<span class="sd">        Returns:</span>
<span class="sd">            int: Selected action.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># [1, state_dims]</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>  <span class="c1"># [1, num_actions]</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">evaluate</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">probs</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="c1"># Validate action</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">action</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Sampled action </span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="s2"> is out of bounds."</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">action</span>
    
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">updates</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Update the SAC agent's networks.</span>
<span class="sd">        Args:</span>
<span class="sd">            updates (int): Current update step count.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
            <span class="k">return</span>
        
        <span class="c1"># Sample a minibatch from replay buffer</span>
        <span class="n">state_batch</span><span class="p">,</span> <span class="n">action_batch</span><span class="p">,</span> <span class="n">reward_batch</span><span class="p">,</span> <span class="n">next_state_batch</span><span class="p">,</span> <span class="n">terminated_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        
        <span class="c1"># Compute target Q-values</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="c1"># Get logits and probabilities from the policy network for next states</span>
            <span class="n">next_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="p">(</span><span class="n">next_state_batch</span><span class="p">)</span>
            <span class="n">next_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">next_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
            <span class="n">next_log_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">next_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
            
            <span class="c1"># Get target Q-values from target networks</span>
            <span class="n">target_q1_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span><span class="p">(</span><span class="n">next_state_batch</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
            <span class="n">target_q2_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span><span class="p">(</span><span class="n">next_state_batch</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
            <span class="n">target_q_values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">target_q1_values</span><span class="p">,</span> <span class="n">target_q2_values</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
            
            <span class="c1"># Compute expected Q-values for next states</span>
            <span class="n">expected_q</span> <span class="o">=</span> <span class="p">(</span><span class="n">next_probs</span> <span class="o">*</span> <span class="p">(</span><span class="n">target_q_values</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">next_log_probs</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># [batch_size, 1]</span>
            
            <span class="c1"># Compute target Q</span>
            <span class="n">q_target</span> <span class="o">=</span> <span class="n">reward_batch</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">terminated_batch</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">expected_q</span>  <span class="c1"># [batch_size, 1]</span>
        
        <span class="c1"># Compute current Q-values from both Q-networks</span>
        <span class="n">current_q1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">action_batch</span><span class="p">)</span>  <span class="c1"># [batch_size, 1]</span>
        <span class="n">current_q2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">action_batch</span><span class="p">)</span>  <span class="c1"># [batch_size, 1]</span>
        
        <span class="c1"># Compute Q-network losses</span>
        <span class="n">q1_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">current_q1</span><span class="p">,</span> <span class="n">q_target</span><span class="p">)</span>
        <span class="n">q2_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">current_q2</span><span class="p">,</span> <span class="n">q_target</span><span class="p">)</span>
        
        <span class="c1"># Update Q-networks</span>
        <span class="n">q1_loss_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">update_q_network</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">q1_loss</span><span class="p">)</span>
        <span class="n">q2_loss_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">update_q_network</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">q2_loss</span><span class="p">)</span>
        
        <span class="c1"># Compute policy loss</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="c1"># Get Q-values from Q-networks</span>
            <span class="n">q1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
            <span class="n">q2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
            <span class="n">min_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">q1</span><span class="p">,</span> <span class="n">q2</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
        
        <span class="c1"># Update policy network</span>
        <span class="n">policy_loss_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="o">.</span><span class="n">update_policy</span><span class="p">(</span><span class="n">state_batch</span><span class="p">,</span> <span class="n">action_batch</span><span class="p">,</span> <span class="n">min_q</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">action_batch</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        
        <span class="c1"># Optional: Update alpha for entropy temperature</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">automatic_alpha</span><span class="p">:</span>
            <span class="c1"># Recompute log_probs for entropy adjustment</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
            <span class="n">log_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># [batch_size, num_actions]</span>
            <span class="n">entropy</span> <span class="o">=</span> <span class="o">-</span> <span class="p">(</span><span class="n">log_probs</span> <span class="o">*</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            
            <span class="n">alpha_loss</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">entropy</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_entropy</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            
            <span class="bp">self</span><span class="o">.</span><span class="n">alpha_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">alpha_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">alpha_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            
            <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_alpha</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Updated alpha: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Alpha Loss: </span><span class="si">{</span><span class="n">alpha_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        
        <span class="c1"># Update target networks</span>
        <span class="k">if</span> <span class="n">updates</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_update_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">soft_update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">soft_update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"Target networks updated."</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">q1_loss_value</span><span class="p">,</span> <span class="n">q2_loss_value</span><span class="p">,</span> <span class="n">policy_loss_value</span>  <span class="c1"># Optionally return loss values for logging</span>
    
    <span class="k">def</span> <span class="nf">soft_update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">target_net</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Perform soft update of target network parameters.</span>
<span class="sd">        Args:</span>
<span class="sd">            net (nn.Module): Main network.</span>
<span class="sd">            target_net (nn.Module): Target network.</span>
<span class="sd">        """</span>
        <span class="k">for</span> <span class="n">param</span><span class="p">,</span> <span class="n">target_param</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">target_net</span><span class="o">.</span><span class="n">parameters</span><span class="p">()):</span>
            <span class="n">target_param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">*</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">)</span> <span class="o">*</span> <span class="n">target_param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">train_agent</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_episodes</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="p">,</span> <span class="n">criterion_episodes</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Train the SAC agent.</span>
<span class="sd">        Args:</span>
<span class="sd">            max_episodes (int): Maximum number of episodes for training.</span>
<span class="sd">            stop_criterion (function): Function to determine stopping condition.</span>
<span class="sd">            criterion_episodes (int): Number of episodes to evaluate the stopping criterion.</span>
<span class="sd">        """</span>
        <span class="n">total_rewards</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">updates</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_episodes</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
            <span class="n">terminated</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">truncated</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">episode_reward</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">steps</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">while</span> <span class="ow">not</span> <span class="p">(</span><span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">)</span> <span class="ow">and</span> <span class="n">steps</span> <span class="o">&lt;</span> <span class="mi">10000</span><span class="p">:</span>  <span class="c1"># Prevent infinite loops</span>
                <span class="c1"># Select action by following behaviour policy</span>
                <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

                <span class="c1"># Send the action to the environment</span>
                <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

                <span class="c1"># Add experience to replay buffer</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">push</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">terminated</span><span class="p">)</span>

                <span class="c1"># Update state</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
                <span class="n">episode_reward</span> <span class="o">+=</span> <span class="n">reward</span>
                <span class="n">steps</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="c1"># Update Q-network and policy</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">updates</span><span class="p">)</span>
                <span class="n">updates</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># Append the reward for this episode</span>
            <span class="n">total_rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">episode_reward</span><span class="p">)</span>

            <span class="c1"># Log metrics to W&amp;B</span>
            <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">({</span>
                <span class="s1">'episode'</span><span class="p">:</span> <span class="n">episode</span><span class="p">,</span>
                <span class="s1">'episode_reward'</span><span class="p">:</span> <span class="n">episode_reward</span><span class="p">,</span>
                <span class="s1">'steps'</span><span class="p">:</span> <span class="n">steps</span><span class="p">,</span>
                <span class="s1">'updates'</span><span class="p">:</span> <span class="n">updates</span><span class="p">,</span>
                <span class="s1">'alpha'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">automatic_alpha</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span>
                <span class="c1"># Optionally, log losses if returned</span>
                <span class="c1"># 'q1_loss': q1_loss_value,</span>
                <span class="c1"># 'q2_loss': q2_loss_value,</span>
                <span class="c1"># 'policy_loss': policy_loss_value,</span>
            <span class="p">})</span>

            <span class="c1"># Print progress</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Episode </span><span class="si">{</span><span class="n">episode</span><span class="si">}</span><span class="s2">: Reward = </span><span class="si">{</span><span class="n">episode_reward</span><span class="si">}</span><span class="s2">, Steps = </span><span class="si">{</span><span class="n">steps</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

            <span class="c1"># Check stopping criterion</span>
            <span class="k">if</span> <span class="n">episode</span> <span class="o">&gt;=</span> <span class="n">criterion_episodes</span><span class="p">:</span>
                <span class="n">recent_rewards</span> <span class="o">=</span> <span class="n">total_rewards</span><span class="p">[</span><span class="o">-</span><span class="n">criterion_episodes</span><span class="p">:]</span>
                <span class="k">if</span> <span class="n">stop_criterion</span><span class="p">(</span><span class="n">recent_rewards</span><span class="p">):</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Stopping criterion satisfied after </span><span class="si">{</span><span class="n">episode</span><span class="si">}</span><span class="s2"> episodes"</span><span class="p">)</span>
                    <span class="k">break</span>

        <span class="c1"># Plot rewards received during training</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">dpi</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">total_rewards</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">total_rewards</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Rewards per Episode'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Episode'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Rewards'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Training Rewards over Episodes'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower right'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Save the model parameters.</span>
<span class="sd">        Args:</span>
<span class="sd">            path (str): File path to save the model.</span>
<span class="sd">        """</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
            <span class="s1">'policy_net'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'q_net1'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'q_net2'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'target_q_net1'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'target_q_net2'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
        <span class="p">},</span> <span class="n">path</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Model saved to </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Load the model parameters.</span>
<span class="sd">        Args:</span>
<span class="sd">            path (str): File path to load the model from.</span>
<span class="sd">        """</span>
        <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'policy_net'</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'q_net1'</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'q_net2'</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'target_q_net1'</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'target_q_net2'</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Model loaded from </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Define the Sweep Agent Wrapper</span>
<span class="k">class</span> <span class="nc">AgentSAC</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="c1"># Instantiate SACAgentRAM with environment and config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">agent</span> <span class="o">=</span> <span class="n">SACAgentRAM</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_episodes</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="p">,</span> <span class="n">criterion_episodes</span><span class="p">):</span>
        <span class="c1"># Delegate training to SACAgentRAM</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">agent</span><span class="o">.</span><span class="n">train_agent</span><span class="p">(</span><span class="n">max_episodes</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="p">,</span> <span class="n">criterion_episodes</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="c1"># Delegate model saving to SACAgentRAM</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">agent</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="c1"># Delegate model loading to SACAgentRAM</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">agent</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

<span class="c1"># Define the Sweep Agent Function</span>
<span class="k">def</span> <span class="nf">sweep_agent</span><span class="p">():</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Initialize a new wandb run</span>
        <span class="k">with</span> <span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">()</span> <span class="k">as</span> <span class="n">run</span><span class="p">:</span>
            <span class="n">config</span> <span class="o">=</span> <span class="n">wandb</span><span class="o">.</span><span class="n">config</span>

            <span class="c1"># Create the environment with RAM observation type</span>
            <span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">'ALE/Boxing-v5'</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">"rgb_array_list"</span><span class="p">,</span> <span class="n">obs_type</span><span class="o">=</span><span class="s2">"ram"</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"Observation Space Shape:"</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"Action Space:"</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="p">)</span>

            <span class="c1"># Ensure the observation is a 128-length vector</span>
            <span class="k">assert</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">128</span><span class="p">,),</span> <span class="s2">"Observation space must be a 128-length vector."</span>

            <span class="c1"># Instantiate AgentSAC with current wandb config</span>
            <span class="n">agent</span> <span class="o">=</span> <span class="n">AgentSAC</span><span class="p">(</span><span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>

            <span class="c1"># Define stopping criterion (optional)</span>
            <span class="k">def</span> <span class="nf">stopping_criterion</span><span class="p">(</span><span class="n">rewards</span><span class="p">):</span>
                <span class="c1"># Example: stop if average reward over last 5 episodes &gt;= 100</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rewards</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">100</span>

            <span class="c1"># Start training</span>
            <span class="n">agent</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
                <span class="n">max_episodes</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">num_episodes</span><span class="p">,</span>
                <span class="n">stop_criterion</span><span class="o">=</span><span class="n">stopping_criterion</span><span class="p">,</span>
                <span class="n">criterion_episodes</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">criterion_episodes</span>
            <span class="p">)</span>

            <span class="c1"># Save the trained model</span>
            <span class="n">agent</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">'sac_discrete_boxing_ram.pth'</span><span class="p">)</span>

            <span class="c1"># Close the environment after training</span>
            <span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="c1"># Log the error to wandb</span>
        <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">({</span><span class="s2">"error"</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)})</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"An error occurred: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="c1"># Ensure the environment is closed in case of an error</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">pass</span>

<span class="c1"># Define the Sweep Configuration for SAC</span>
<span class="n">sweep_configuration_sac</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"method"</span><span class="p">:</span> <span class="s2">"random"</span><span class="p">,</span>  <span class="c1"># Options: "grid", "random", "bayes"</span>
    <span class="s2">"metric"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"episode_reward"</span><span class="p">,</span>  <span class="c1"># The metric to optimize</span>
        <span class="s2">"goal"</span><span class="p">:</span> <span class="s2">"maximize"</span>         <span class="c1"># Whether to "minimize" or "maximize"</span>
    <span class="p">},</span>
    <span class="s2">"parameters"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"lr_policy"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Learning rate for the policy network</span>
            <span class="s2">"distribution"</span><span class="p">:</span> <span class="s2">"log_uniform"</span><span class="p">,</span>
            <span class="s2">"min"</span><span class="p">:</span> <span class="mf">1e-5</span><span class="p">,</span>
            <span class="s2">"max"</span><span class="p">:</span> <span class="mf">1e-3</span>
        <span class="p">},</span>
        <span class="s2">"lr_q"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Learning rate for the Q-networks</span>
            <span class="s2">"distribution"</span><span class="p">:</span> <span class="s2">"log_uniform"</span><span class="p">,</span>
            <span class="s2">"min"</span><span class="p">:</span> <span class="mf">1e-5</span><span class="p">,</span>
            <span class="s2">"max"</span><span class="p">:</span> <span class="mf">1e-3</span>
        <span class="p">},</span>
        <span class="s2">"gamma"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Discount factor for future rewards</span>
            <span class="s2">"distribution"</span><span class="p">:</span> <span class="s2">"uniform"</span><span class="p">,</span>
            <span class="s2">"min"</span><span class="p">:</span> <span class="mf">0.95</span><span class="p">,</span>
            <span class="s2">"max"</span><span class="p">:</span> <span class="mf">0.99</span>
        <span class="p">},</span>
        <span class="s2">"alpha"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Entropy temperature (only if automatic_alpha is False)</span>
            <span class="s2">"distribution"</span><span class="p">:</span> <span class="s2">"uniform"</span><span class="p">,</span>
            <span class="s2">"min"</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
            <span class="s2">"max"</span><span class="p">:</span> <span class="mf">0.5</span>
        <span class="p">},</span>
        <span class="s2">"tau"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Soft update coefficient for target networks</span>
            <span class="s2">"distribution"</span><span class="p">:</span> <span class="s2">"uniform"</span><span class="p">,</span>
            <span class="s2">"min"</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span>
            <span class="s2">"max"</span><span class="p">:</span> <span class="mf">0.01</span>
        <span class="p">},</span>
        <span class="s2">"batch_size"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Mini-batch size for updates</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">]</span>  <span class="c1"># Three discrete values</span>
        <span class="p">},</span>
        <span class="s2">"replay_size"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Replay buffer size</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="mi">20000</span><span class="p">]</span>  <span class="c1"># Three discrete values</span>
        <span class="p">},</span>
        <span class="s2">"hidden_sizes"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Architecture of hidden layers</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="s2">"(64,64)"</span><span class="p">,</span> <span class="s2">"(128,128)"</span><span class="p">,</span> <span class="s2">"(64,64,64)"</span><span class="p">,</span> <span class="s2">"(128,128,128)"</span><span class="p">]</span>  
        <span class="p">},</span>
        <span class="s2">"target_update_interval"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Frequency of target network updates</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Fixed to 1 for SAC</span>
        <span class="p">},</span>
        <span class="s2">"num_episodes"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Total number of training episodes</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mi">500</span><span class="p">]</span>  <span class="c1"># Fixed to 500</span>
        <span class="p">},</span>
        <span class="s2">"criterion_episodes"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Number of episodes for stopping criterion</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">]</span>  <span class="c1"># Fixed to 5</span>
        <span class="p">},</span>
        <span class="s2">"automatic_alpha"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Whether to use automatic entropy tuning</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span>  <span class="c1"># Toggle between automatic and manual</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c1"># Initialize the sweep</span>
<span class="n">sweep_id</span> <span class="o">=</span> <span class="n">wandb</span><span class="o">.</span><span class="n">sweep</span><span class="p">(</span><span class="n">sweep</span><span class="o">=</span><span class="n">sweep_configuration_sac</span><span class="p">,</span> <span class="n">project</span><span class="o">=</span><span class="s1">'SAC_Discrete_RAM'</span><span class="p">)</span>

<span class="c1"># Launch the Sweep with Limited Runs</span>
<span class="c1"># Adjust 'count' based on your computational resources</span>
<span class="n">wandb</span><span class="o">.</span><span class="n">agent</span><span class="p">(</span><span class="n">sweep_id</span><span class="p">,</span> <span class="n">function</span><span class="o">=</span><span class="n">sweep_agent</span><span class="p">,</span> <span class="n">count</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=e51a4c5a-856f-43e4-9945-c0f07f622f43">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>I am also going to add Weights and biases into the equation So I can monitor and log all experiments</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=c41de25f-da2a-4c25-afc4-d138d553de7b">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">wandb</span> tristancarlisle/SAC_Discrete_RAM/sweeps/tc9vx463
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
<iframe src="https://wandb.ai/tristancarlisle/SAC_Discrete_RAM/sweeps/tc9vx463?jupyter=true" style="border:none;width:100%;height:420px;"></iframe>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=21f0496d-b30a-4a6c-9f66-c3f104b99d08">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">be7dbdba13c56adea3d21db27fce4bc75f0271e2</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=84cd8eb9-2fbc-449d-8545-5ce858f8950e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">wandb</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=0f5a899b-ebc8-41e5-8288-85176463a202">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">swig</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Requirement already satisfied: swig in /home/tristan/miniconda3/envs/ReinforcementLearning/lib/python3.11/site-packages (4.2.1)
Note: you may need to restart the kernel to use updated packages.
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=ce449b60-1884-4c42-b6d8-4b35b151b68d">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[18]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#%%writefile SAC_spedup_and_vectorised.py</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">T</span>

<span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="kn">import</span> <span class="nn">moviepy.editor</span> <span class="k">as</span> <span class="nn">mpy</span>
<span class="kn">from</span> <span class="nn">torch.cuda.amp</span> <span class="kn">import</span> <span class="n">autocast</span><span class="p">,</span> <span class="n">GradScaler</span>
<span class="kn">import</span> <span class="nn">wandb</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=635b67f2-1cbe-4fa8-a706-183f86125db5">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>SAC Modified</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=fceb3c20-204d-49eb-88bd-ebd45d00ff08">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">T</span>

<span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="kn">import</span> <span class="nn">moviepy.editor</span> <span class="k">as</span> <span class="nn">mpy</span>
<span class="kn">from</span> <span class="nn">torch.cuda.amp</span> <span class="kn">import</span> <span class="n">autocast</span><span class="p">,</span> <span class="n">GradScaler</span>
<span class="kn">import</span> <span class="nn">wandb</span>

<span class="c1"># Set device to GPU if available</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Using device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Set random seeds for reproducibility (optional)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Replay buffer for off-policy learning</span>
<span class="k">class</span> <span class="nc">ReplayBuffer</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">capacity</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">capacity</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">push</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">terminated</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">terminated</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">state_batch</span><span class="p">,</span> <span class="n">action_batch</span><span class="p">,</span> <span class="n">reward_batch</span><span class="p">,</span> <span class="n">next_state_batch</span><span class="p">,</span> <span class="n">terminated_batch</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">samples</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">state_batch</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">action_batch</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">reward_batch</span><span class="p">),</span>
                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">next_state_batch</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">terminated_batch</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="p">)</span>

<span class="c1"># Soft Actor-Critic agent for discrete action spaces with mixed precision</span>
<span class="k">class</span> <span class="nc">SACAgent</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
                 <span class="n">lr_policy</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">lr_q</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">replay_size</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                 <span class="n">target_update_interval</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">tau</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span> <span class="n">load_path</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">envs</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">vector</span><span class="o">.</span><span class="n">AsyncVectorEnv</span><span class="p">(</span><span class="n">env_fns</span><span class="p">)</span> <span class="c1"># created async vectorised environment to increase speed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_envs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">env_fns</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>  <span class="c1"># Entropy temperature</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">=</span> <span class="n">tau</span>  <span class="c1"># Target smoothing coefficient</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_update_interval</span> <span class="o">=</span> <span class="n">target_update_interval</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">envs</span><span class="o">.</span><span class="n">single_observation_space</span><span class="o">.</span><span class="n">shape</span>
        
        <span class="c1"># Replay buffer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="o">=</span> <span class="n">ReplayBuffer</span><span class="p">(</span><span class="n">replay_size</span><span class="p">)</span>
        
        <span class="c1"># Policy network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span> <span class="o">=</span> <span class="n">PolicyNetwork</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_shape</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span> <span class="n">lr_policy</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Q-networks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span> <span class="o">=</span> <span class="n">QNetwork</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_shape</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span> <span class="n">lr_q</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span> <span class="o">=</span> <span class="n">QNetwork</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_shape</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span> <span class="n">lr_q</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Target Q-networks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span> <span class="o">=</span> <span class="n">QNetwork</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_shape</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span> <span class="n">lr_q</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span> <span class="o">=</span> <span class="n">QNetwork</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_shape</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span> <span class="n">lr_q</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Copy parameters from Q-networks to target networks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
        
        <span class="c1"># Loss function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
        
        <span class="c1"># Mixed precision scaler</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span> <span class="o">=</span> <span class="n">GradScaler</span><span class="p">()</span>

        <span class="c1">#model load </span>
        <span class="k">if</span> <span class="n">load_path</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">load_path</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">load_path</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Model loaded from </span><span class="si">{</span><span class="n">load_path</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">select_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">evaluate</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># (1, k, H, W)</span>
        <span class="k">if</span> <span class="n">evaluate</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">action</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                <span class="n">action</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">action</span>
    
    <span class="k">def</span> <span class="nf">update_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">updates</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
            <span class="k">return</span>
        
        <span class="n">state_batch</span><span class="p">,</span> <span class="n">action_batch</span><span class="p">,</span> <span class="n">reward_batch</span><span class="p">,</span> <span class="n">next_state_batch</span><span class="p">,</span> <span class="n">terminated_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        
        <span class="c1"># Convert batches to tensors</span>
        <span class="n">state_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># (batch_size, k, H, W)</span>
        <span class="n">next_state_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">next_state_batch</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">action_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">action_batch</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">reward_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">reward_batch</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">terminated_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">terminated_batch</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Normalize rewards</span>
        <span class="n">reward_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">reward_batch</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Reward clipping</span>
        
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="c1"># Next action probabilities and log probabilities</span>
            <span class="k">with</span> <span class="n">autocast</span><span class="p">():</span>
                <span class="n">next_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="p">(</span><span class="n">next_state_batch</span><span class="p">)</span>
                <span class="n">next_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">next_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">next_log_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">next_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                
                <span class="c1"># Compute target Q-values</span>
                <span class="n">target_q1_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span><span class="p">(</span><span class="n">next_state_batch</span><span class="p">)</span>
                <span class="n">target_q2_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span><span class="p">(</span><span class="n">next_state_batch</span><span class="p">)</span>
                <span class="n">target_q_values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">target_q1_values</span><span class="p">,</span> <span class="n">target_q2_values</span><span class="p">)</span>
                <span class="n">next_q</span> <span class="o">=</span> <span class="p">(</span><span class="n">next_probs</span> <span class="o">*</span> <span class="p">(</span><span class="n">target_q_values</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">next_log_probs</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                
                <span class="c1"># Compute target values</span>
                <span class="n">q_target</span> <span class="o">=</span> <span class="n">reward_batch</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">terminated_batch</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">next_q</span>
        
        <span class="c1"># Compute current Q-values</span>
        <span class="k">with</span> <span class="n">autocast</span><span class="p">():</span>
            <span class="n">current_q1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">action_batch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">current_q2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">action_batch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        
            <span class="c1"># Compute Q-network losses</span>
            <span class="n">q1_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">current_q1</span><span class="p">,</span> <span class="n">q_target</span><span class="p">)</span>
            <span class="n">q2_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">current_q2</span><span class="p">,</span> <span class="n">q_target</span><span class="p">)</span>
        
        <span class="c1"># Update Q-networks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">q1_loss</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">optimizer</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">q2_loss</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">optimizer</span><span class="p">)</span>
        
        <span class="c1"># Update policy network</span>
        <span class="k">with</span> <span class="n">autocast</span><span class="p">():</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span>
            <span class="n">probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">log_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            
            <span class="n">q1_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span>
            <span class="n">q2_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="p">(</span><span class="n">state_batch</span><span class="p">)</span>
            <span class="n">min_q_values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">q1_values</span><span class="p">,</span> <span class="n">q2_values</span><span class="p">)</span>
            
            <span class="n">policy_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">probs</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">log_probs</span> <span class="o">-</span> <span class="n">min_q_values</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">policy_loss</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="o">.</span><span class="n">optimizer</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
        
        <span class="c1"># Update target networks</span>
        <span class="k">if</span> <span class="n">updates</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_update_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">soft_update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">soft_update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span><span class="p">)</span>
            
        <span class="k">return</span> <span class="n">q1_loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">q2_loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">policy_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="c1">#just for logging</span>
    
    <span class="k">def</span> <span class="nf">soft_update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">target_net</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">param</span><span class="p">,</span> <span class="n">target_param</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">target_net</span><span class="o">.</span><span class="n">parameters</span><span class="p">()):</span>
            <span class="n">target_param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">*</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span><span class="p">)</span> <span class="o">*</span> <span class="n">target_param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_episodes</span><span class="p">,</span> <span class="n">max_steps_per_episode</span><span class="p">,</span> <span class="n">updates_per_step</span><span class="p">,</span> <span class="n">eval_interval</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
        <span class="n">total_rewards</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">updates</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># Just adding this so If I run a keyboard interruption the model is still saved</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># have to alter pretty heavily so we can run multiple envs </span>
            <span class="c1">#want to track average losses </span>
            <span class="n">q1_losses</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">q2_losses</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">policy_losses</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">states</span><span class="p">,</span> <span class="n">infos</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">envs</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
            <span class="n">episode_rewards</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_envs</span><span class="p">)</span>
            <span class="n">episode_lengths</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_envs</span><span class="p">)</span>
            <span class="n">episode_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_envs</span><span class="p">)</span>
            <span class="n">total_episodes</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">while</span> <span class="n">total_episodes</span> <span class="o">&lt;</span> <span class="n">num_episodes</span><span class="p">:</span>
                <span class="n">actions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_action</span><span class="p">(</span><span class="n">states</span><span class="p">)</span>
                <span class="n">next_states</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">terminateds</span><span class="p">,</span> <span class="n">truncateds</span><span class="p">,</span> <span class="n">infos</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">envs</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>
                <span class="n">episode_rewards</span> <span class="o">+=</span> <span class="n">rewards</span>
                <span class="n">episode_lengths</span> <span class="o">+=</span> <span class="mi">1</span>
                
                <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_envs</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">push</span><span class="p">(</span><span class="n">states</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">actions</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">rewards</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">next_states</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">terminateds</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
                
                <span class="n">states</span> <span class="o">=</span> <span class="n">next_states</span>
                
                <span class="n">q1_loss</span><span class="p">,</span> <span class="n">q2_loss</span><span class="p">,</span> <span class="n">policy_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_parameters</span><span class="p">(</span><span class="n">updates</span><span class="p">)</span>
                <span class="n">updates</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="k">if</span> <span class="n">q1_loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="c1">#just make sure its not none before we add them to the log</span>
                    <span class="n">q1_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">q1_loss</span><span class="p">)</span>
                    <span class="n">q2_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">q2_loss</span><span class="p">)</span>
                    <span class="n">policy_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">policy_loss</span><span class="p">)</span>
                
                <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">done</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">terminateds</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">done</span> <span class="ow">or</span> <span class="n">episode_lengths</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">max_steps_per_episode</span><span class="p">:</span>
                        <span class="n">total_rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">episode_rewards</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
                        <span class="c1">#just add wandb logging </span>
                        <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">({</span>
                        <span class="s1">'episode'</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">total_rewards</span><span class="p">),</span>
                        <span class="s1">'episode_reward'</span><span class="p">:</span> <span class="n">episode_rewards</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                        <span class="s1">'episode_length'</span><span class="p">:</span> <span class="n">episode_lengths</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                        <span class="s1">'average_q1_loss'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">q1_losses</span><span class="p">)</span> <span class="k">if</span> <span class="n">q1_losses</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
                        <span class="s1">'average_q2_loss'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">q2_losses</span><span class="p">)</span> <span class="k">if</span> <span class="n">q2_losses</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
                        <span class="s1">'average_policy_loss'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">policy_losses</span><span class="p">)</span> <span class="k">if</span> <span class="n">policy_losses</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
                    <span class="p">})</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Episode </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">total_rewards</span><span class="p">)</span><span class="si">}</span><span class="s2">: Total Reward = </span><span class="si">{</span><span class="n">episode_rewards</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
                        <span class="n">episode_rewards</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
                        <span class="n">episode_lengths</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
                        <span class="n">episode_counts</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                        <span class="n">total_episodes</span> <span class="o">+=</span> <span class="mi">1</span>

                        <span class="c1"># need to reset losses</span>
                        <span class="n">q1_losses</span> <span class="o">=</span> <span class="p">[]</span>
                        <span class="n">q2_losses</span> <span class="o">=</span> <span class="p">[]</span>
                        <span class="n">policy_losses</span> <span class="o">=</span> <span class="p">[]</span>
                        
                        <span class="c1"># I also wanted to add a evaluation step every n intervals so I dont train for 5 days and the lil agent is no good</span>
                        <span class="k">if</span> <span class="n">total_episodes</span> <span class="o">%</span> <span class="n">eval_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">total_episodes</span><span class="p">)</span>
                        
                        <span class="k">if</span> <span class="n">total_episodes</span> <span class="o">&gt;=</span> <span class="n">num_episodes</span><span class="p">:</span>
                            <span class="k">break</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">plot_rewards</span><span class="p">(</span><span class="n">total_rewards</span><span class="p">)</span>        
        <span class="k">except</span> <span class="ne">KeyboardInterrupt</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"Training interrupted. Saving model..."</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">'checkpoint.pth'</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"Model saved."</span><span class="p">)</span>
            <span class="c1"># Optionally plot the rewards collected so far</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">plot_rewards</span><span class="p">(</span><span class="n">total_rewards</span><span class="p">)</span>

        
    <span class="c1">#just made the plotting a function so I could call it instead</span>
    <span class="k">def</span> <span class="nf">plot_rewards</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">total_rewards</span><span class="p">):</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">dpi</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">total_rewards</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Episode'</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Total Reward'</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Training Rewards over Episodes'</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">episode_num</span><span class="p">):</span><span class="c1">#its basically the same as the evaluation we use at the end but just log it to WandB as well</span>
        <span class="n">eval_env</span> <span class="o">=</span> <span class="n">make_env</span><span class="p">()()</span> 
        <span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">eval_env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="n">terminated</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">truncated</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">frames</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">while</span> <span class="ow">not</span> <span class="p">(</span><span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">):</span>
            <span class="n">frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">eval_env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">'rgb_array'</span><span class="p">))</span>
            <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_action</span><span class="p">([</span><span class="n">state</span><span class="p">],</span> <span class="n">evaluate</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">eval_env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
            <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">reward</span>

        <span class="n">eval_env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="n">video</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">frames</span><span class="p">)</span>
        <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">({</span>
            <span class="s1">'evaluation_reward'</span><span class="p">:</span> <span class="n">total_reward</span><span class="p">,</span>
            <span class="s1">'evaluation_episode'</span><span class="p">:</span> <span class="n">episode_num</span><span class="p">,</span>
            <span class="s1">'evaluation_video'</span><span class="p">:</span> <span class="n">wandb</span><span class="o">.</span><span class="n">Video</span><span class="p">(</span><span class="n">video</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">"mp4"</span><span class="p">)</span>
        <span class="p">})</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Evaluation Episode </span><span class="si">{</span><span class="n">episode_num</span><span class="si">}</span><span class="s2">: Total Reward = </span><span class="si">{</span><span class="n">total_reward</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>




    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
            <span class="s1">'policy_net'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'q_net1'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'q_net2'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'target_q_net1'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'target_q_net2'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
        <span class="p">},</span> <span class="n">path</span><span class="p">)</span>

        <span class="n">wandb</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">path</span><span class="p">)</span> <span class="c1">#log path</span>
    
    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'policy_net'</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_net1</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'q_net1'</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_net2</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'q_net2'</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net1</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'target_q_net1'</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_net2</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'target_q_net2'</span><span class="p">])</span>

<span class="c1"># Policy network for SAC with simplified architecture</span>
<span class="k">class</span> <span class="nc">PolicyNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>  <span class="c1"># Entropy temperature coefficient</span>
        
        <span class="c1"># Simplified CNN layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>  <span class="c1"># Reduced filters from 32 to 16</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>              <span class="c1"># Reduced filters from 64 to 32</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="p">)</span>
        
        <span class="c1"># Compute the size after CNN layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flattened_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_flattened_size</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
        
        <span class="c1"># Reduced fully connected layers</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flattened_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        
        <span class="c1"># Output layer for action probabilities</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">output_size</span><span class="p">))</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_get_flattened_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">dummy_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">input_shape</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">conv_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_net</span><span class="p">(</span><span class="n">dummy_input</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">conv_out</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logits</span>  <span class="c1"># Logits for categorical distribution</span>
    
    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">)</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
        <span class="n">log_prob</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">action</span><span class="p">,</span> <span class="n">log_prob</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">probs</span>

<span class="c1"># Q-Network for SAC with simplified architecture</span>
<span class="k">class</span> <span class="nc">QNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">num_actions</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="c1"># Simplified CNN layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>  <span class="c1"># Reduced filters from 32 to 16</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>              <span class="c1"># Reduced filters from 64 to 32</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="p">)</span>
        
        <span class="c1"># Compute the size after CNN layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flattened_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_flattened_size</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
        
        <span class="c1"># Reduced fully connected layers</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flattened_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        
        <span class="c1"># Output layer for Q-values for each action</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">num_actions</span><span class="p">))</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_get_flattened_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">dummy_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">input_shape</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">conv_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_net</span><span class="p">(</span><span class="n">dummy_input</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">conv_out</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">q_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">q_values</span>  <span class="c1"># Q-values for each action</span>

<span class="c1"># Create the environment with preprocessing and frame stacking</span>
<span class="k">def</span> <span class="nf">make_env</span><span class="p">():</span>
    <span class="k">def</span> <span class="nf">_init</span><span class="p">():</span>
        <span class="c1"># Original environment</span>
        <span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">'ALE/Boxing-v5'</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">"human"</span><span class="p">)</span>
        <span class="c1"># Preprocess frames</span>
        <span class="n">env</span> <span class="o">=</span> <span class="n">PreprocessFrame</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">84</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">84</span><span class="p">,</span> <span class="n">grayscale</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># Increased frame skip</span>
        <span class="n">env</span> <span class="o">=</span> <span class="n">FrameSkip</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">skip</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
        <span class="c1"># Frame stack</span>
        <span class="n">env</span> <span class="o">=</span> <span class="n">FrameStack</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
        <span class="c1"># Reduce action space</span>
        <span class="n">action_mapping</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># Indices of actions: NOOP, UP, RIGHT, LEFT, DOWN, FIRE</span>
        <span class="n">env</span> <span class="o">=</span> <span class="n">ActionSpaceReducer</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">action_mapping</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">env</span>
    <span class="k">return</span> <span class="n">_init</span>

<span class="c1"># multiple environment instances</span>
<span class="n">num_envs</span> <span class="o">=</span> <span class="mi">4</span>  
<span class="n">env_fns</span> <span class="o">=</span> <span class="p">[</span><span class="n">make_env</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_envs</span><span class="p">)]</span>

<span class="c1"># Hyperparameters</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.99</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">hidden_sizes</span> <span class="o">=</span> <span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="p">)</span>  <span class="c1"># Reduced hidden layer size</span>
<span class="n">lr_policy</span> <span class="o">=</span> <span class="mf">1e-4</span>
<span class="n">lr_q</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">replay_size</span> <span class="o">=</span> <span class="mi">100000</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>  <span class="c1"># Increased batch size ccause it took way to long</span>
<span class="n">target_update_interval</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">tau</span> <span class="o">=</span> <span class="mf">0.005</span>
<span class="n">num_episodes</span> <span class="o">=</span> <span class="mi">500</span>  <span class="c1"># Reduced number of episodes took too long</span>
<span class="n">max_steps_per_episode</span> <span class="o">=</span> <span class="mi">500</span>  <span class="c1"># Reduced max steps per episode took too long</span>
<span class="n">updates_per_step</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">project</span><span class="o">=</span><span class="s1">'SAC-Boxing'</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="p">{</span>
    <span class="s1">'gamma'</span><span class="p">:</span> <span class="n">gamma</span><span class="p">,</span>
    <span class="s1">'alpha'</span><span class="p">:</span> <span class="n">alpha</span><span class="p">,</span>
    <span class="s1">'hidden_sizes'</span><span class="p">:</span> <span class="n">hidden_sizes</span><span class="p">,</span>
    <span class="s1">'lr_policy'</span><span class="p">:</span> <span class="n">lr_policy</span><span class="p">,</span>
    <span class="s1">'lr_q'</span><span class="p">:</span> <span class="n">lr_q</span><span class="p">,</span>
    <span class="s1">'replay_size'</span><span class="p">:</span> <span class="n">replay_size</span><span class="p">,</span>
    <span class="s1">'batch_size'</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">,</span>
    <span class="s1">'target_update_interval'</span><span class="p">:</span> <span class="n">target_update_interval</span><span class="p">,</span>
    <span class="s1">'tau'</span><span class="p">:</span> <span class="n">tau</span><span class="p">,</span>
    <span class="s1">'num_episodes'</span><span class="p">:</span> <span class="n">num_episodes</span><span class="p">,</span>
    <span class="s1">'max_steps_per_episode'</span><span class="p">:</span> <span class="n">max_steps_per_episode</span><span class="p">,</span>
    <span class="s1">'updates_per_step'</span><span class="p">:</span> <span class="n">updates_per_step</span><span class="p">,</span>
    <span class="s1">'num_envs'</span><span class="p">:</span> <span class="n">num_envs</span><span class="p">,</span>
<span class="p">})</span>
<span class="c1"># Initialize the SAC agent (multiple environments this run though )</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">SACAgent</span><span class="p">(</span><span class="n">env_fns</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">lr_policy</span><span class="p">,</span> <span class="n">lr_q</span><span class="p">,</span> <span class="n">replay_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                 <span class="n">target_update_interval</span><span class="p">,</span> <span class="n">tau</span><span class="p">)</span>

<span class="c1"># Train the agent</span>
<span class="n">agent</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">num_episodes</span><span class="p">,</span> <span class="n">max_steps_per_episode</span><span class="p">,</span> <span class="n">updates_per_step</span><span class="p">)</span>

<span class="c1"># Visualize one episode</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">make_env</span><span class="p">()()</span>
<span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="n">terminated</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">truncated</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">frames</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">while</span> <span class="ow">not</span> <span class="p">(</span><span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">):</span>
    <span class="n">frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">'rgb_array'</span><span class="p">))</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">select_action</span><span class="p">([</span><span class="n">state</span><span class="p">],</span> <span class="n">evaluate</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
    <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">reward</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total Reward: </span><span class="si">{</span><span class="n">total_reward</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Close the environment</span>
<span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="c1"># Create and play video clip using the frames and given fps</span>
<span class="n">clip</span> <span class="o">=</span> <span class="n">mpy</span><span class="o">.</span><span class="n">ImageSequenceClip</span><span class="p">(</span><span class="n">frames</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">clip</span><span class="o">.</span><span class="n">ipython_display</span><span class="p">(</span><span class="n">rd_kwargs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">logger</span><span class="o">=</span><span class="kc">None</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=38f67b67-6f2d-4509-b7d0-f558dce1e011">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Proximal-Policy-Optimization-(PPO)">Proximal Policy Optimization (PPO)<a class="anchor-link" href="#Proximal-Policy-Optimization-(PPO)"></a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=3d824e59-9a6e-4b63-aa97-e79b1d87bc10">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Modifications</p>
<ol>
<li>PPOAgent Class</li>
</ol>
<p>Initialization:</p>
<p>Replaced SACAgent with PPOAgent.
Added parameters specific to PPO like lam (GAE lambda), clip_epsilon, entropy_coef, etc.
Removed the replay buffer since PPO is an on-policy algorithm.
select_action Method:</p>
<p>Returns not just the action but also the action probabilities, state value, log probability, and entropy.
Uses the PolicyValueNetwork to get action probabilities and state value.
compute_gae Method:</p>
<p>Computes Generalized Advantage Estimation (GAE) for the collected rollouts.
update Method:</p>
<p>Performs PPO updates using the collected rollouts.
Calculates policy loss using the clipped surrogate objective.
Calculates value loss using mean squared error.
Includes entropy bonus to encourage exploration.
train Method:</p>
<p>Collects rollouts by interacting with the environment.
Stores experiences in RolloutStorage.
After each rollout, computes advantages and returns.
Calls the update method to update the policy and value networks.
Logs training metrics to W&amp;B.</p>
<ol start="2">
<li>PolicyValueNetwork Class</li>
</ol>
<p>Combines both the policy network and the value network into a single network with shared layers.
Outputs action probabilities (after applying softmax) and state value.
Uses convolutional layers followed by fully connected layers.
3. RolloutStorage Class
Stores collected experiences during rollouts.
Keeps track of states, actions, rewards, values, log probabilities, dones, advantages, and returns.
Provides methods to add data and clear the storage.
4. Environment Setup
Increased num_envs to 8 for better sample efficiency.
Kept the same preprocessing steps as before.
5. W&amp;B Integration
Changed the project name to 'PPO-Boxing'.
Logged additional metrics such as policy loss, value loss, and entropy.
Continued logging episode rewards and lengths.
Logged evaluation videos at specified intervals.
6. Training Parameters
Adjusted hyperparameters suitable for PPO:
Set batch_size to 256.
Set rollout_length to 128.
Adjusted entropy_coef and vf_coef.
7. Evaluation
Modified the evaluate method within PPOAgent to work with the new agent structure.
Ensured that evaluation episodes are logged to W&amp;B with videos.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=c9b3a6ee-7819-4caa-b5e6-c73612013f0d">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Key Changes:
Objective Function:</p>
<p>Transition from a standard Actor-Critic loss to the PPO v2 clipped surrogate objective.
Advantage Estimation:</p>
<p>Implement Generalized Advantage Estimation (GAE) for computing advantages.
Policy Update:</p>
<p>Modify the policy update to incorporate the clipped surrogate objective.
Rollout Collection:</p>
<p>Accumulate rollouts (trajectories) before performing updates, aligning with PPO's batch update mechanism.
Data Normalization:</p>
<p>Normalize advantages to stabilize training.
Batch Processing:</p>
<p>Update the networks using mini-batches extracted from the collected rollouts.
Logging and Evaluation:</p>
<p>Integrate logging mechanisms to monitor training progress and perform periodic evaluations.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=185d42ef-061a-451e-80e6-7f2dac7cff58">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Proximal-Policy-Optimization-(PPO)-Implementation">Proximal Policy Optimization (PPO) Implementation<a class="anchor-link" href="#Proximal-Policy-Optimization-(PPO)-Implementation"></a></h3>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=252a560b-c156-4a8a-93df-6dc79552ce79">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Proximal-Policy-Optimization-(PPO)-RAM-Observations">Proximal Policy Optimization (PPO) RAM Observations<a class="anchor-link" href="#Proximal-Policy-Optimization-(PPO)-RAM-Observations"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=fcca5453-c5d6-45dc-9d67-beced461770f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Set device</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>

<span class="c1"># Set random seeds for reproducibility</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="c1"># Policy network for approximating policy function </span>
<span class="k">class</span> <span class="nc">PolicyNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">output_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">output_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Value network for approximating value function</span>
<span class="k">class</span> <span class="nc">ValueNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=1cc6d466-934c-46af-9cab-9f0f67d97953">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Rollout storage for PPO</span>
<span class="k">class</span> <span class="nc">RolloutStorage</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">log_prob</span><span class="p">,</span> <span class="n">done</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_probs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">log_prob</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dones</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">done</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">clear</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">states</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_probs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dones</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">advantages</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">returns</span> <span class="o">=</span> <span class="p">[]</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=6e4e7a73-342d-49e5-91dc-8121807c131b">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Create the environment with RAM observation type</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">'ALE/Boxing-v5'</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">"rgb_array"</span><span class="p">,</span> <span class="n">obs_type</span><span class="o">=</span><span class="s2">"ram"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Observation Space High:"</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">high</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Observation Space Low:"</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">low</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Observation Space Shape:"</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Ensure the observation is a 128-length vector</span>
<span class="k">assert</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">128</span><span class="p">,),</span> <span class="s2">"Observation space must be a 128-length vector."</span>

<span class="c1"># Define hyperparameters with updated hidden_sizes</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.99</span>
<span class="n">lam</span> <span class="o">=</span> <span class="mf">0.95</span>
<span class="n">hidden_sizes</span> <span class="o">=</span> <span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>  <span class="c1"># Updated to include three hidden layers</span>
<span class="n">lr_policy</span> <span class="o">=</span> <span class="mf">3e-4</span>
<span class="n">lr_value</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">clip_epsilon</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">entropy_coef</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">vf_coef</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">max_grad_norm</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">num_episodes</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">rollout_length</span> <span class="o">=</span> <span class="mi">128</span>    <span class="c1"># Number of steps to collect before an update</span>
<span class="n">eval_interval</span> <span class="o">=</span> <span class="mi">50</span>      <span class="c1"># Evaluate every 50 episodes</span>
<span class="n">criterion_episodes</span> <span class="o">=</span> <span class="mi">5</span>  <span class="c1"># Number of episodes to consider for stopping criterion</span>

<span class="c1"># Initialize W&amp;B with updated hidden_sizes</span>
<span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
    <span class="n">project</span><span class="o">=</span><span class="s1">'PPO-Boxing'</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">'PPO_v2_Boxing_Ram'</span><span class="p">,</span>
    <span class="n">config</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">'gamma'</span><span class="p">:</span> <span class="n">gamma</span><span class="p">,</span>
        <span class="s1">'lam'</span><span class="p">:</span> <span class="n">lam</span><span class="p">,</span>
        <span class="s1">'hidden_sizes'</span><span class="p">:</span> <span class="n">hidden_sizes</span><span class="p">,</span>  <span class="c1"># Updated hidden_sizes</span>
        <span class="s1">'lr_policy'</span><span class="p">:</span> <span class="n">lr_policy</span><span class="p">,</span>
        <span class="s1">'lr_value'</span><span class="p">:</span> <span class="n">lr_value</span><span class="p">,</span>
        <span class="s1">'clip_epsilon'</span><span class="p">:</span> <span class="n">clip_epsilon</span><span class="p">,</span>
        <span class="s1">'epochs'</span><span class="p">:</span> <span class="n">epochs</span><span class="p">,</span>
        <span class="s1">'batch_size'</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">,</span>
        <span class="s1">'entropy_coef'</span><span class="p">:</span> <span class="n">entropy_coef</span><span class="p">,</span>
        <span class="s1">'vf_coef'</span><span class="p">:</span> <span class="n">vf_coef</span><span class="p">,</span>
        <span class="s1">'max_grad_norm'</span><span class="p">:</span> <span class="n">max_grad_norm</span><span class="p">,</span>
        <span class="s1">'num_episodes'</span><span class="p">:</span> <span class="n">num_episodes</span><span class="p">,</span>
        <span class="s1">'rollout_length'</span><span class="p">:</span> <span class="n">rollout_length</span><span class="p">,</span>
        <span class="s1">'eval_interval'</span><span class="p">:</span> <span class="n">eval_interval</span><span class="p">,</span>
        <span class="s1">'criterion_episodes'</span><span class="p">:</span> <span class="n">criterion_episodes</span>
    <span class="p">}</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=e3eb00fd-1221-4304-b1c2-9be399f98f50">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">PPOAgent</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">lam</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> 
                 <span class="n">lr_policy</span><span class="o">=</span><span class="mf">3e-4</span><span class="p">,</span> <span class="n">lr_value</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">clip_epsilon</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> 
                 <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">entropy_coef</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">vf_coef</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">max_grad_norm</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="c1"># Initialize environment and hyperparameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">env</span> <span class="o">=</span> <span class="n">env</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lam</span> <span class="o">=</span> <span class="n">lam</span>  <span class="c1"># GAE lambda</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clip_epsilon</span> <span class="o">=</span> <span class="n">clip_epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span> <span class="o">=</span> <span class="n">epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">entropy_coef</span> <span class="o">=</span> <span class="n">entropy_coef</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vf_coef</span> <span class="o">=</span> <span class="n">vf_coef</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_grad_norm</span> <span class="o">=</span> <span class="n">max_grad_norm</span>

        <span class="c1"># Get action and state dimensions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># 128-length vector</span>

        <span class="c1"># Initialize policy and value networks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policynet</span> <span class="o">=</span> <span class="n">PolicyNetwork</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valuenet</span> <span class="o">=</span> <span class="n">ValueNetwork</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Initialize optimizers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policynet</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr_policy</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value_optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">valuenet</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr_value</span><span class="p">)</span>

        <span class="c1"># Initialize rollout storage</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">storage</span> <span class="o">=</span> <span class="n">RolloutStorage</span><span class="p">()</span>
 <span class="c1">########################################################################################################################################################################################################    </span>
    <span class="k">def</span> <span class="nf">select_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">evaluate</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Add batch dimension and move to device</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policynet</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">evaluate</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">probs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
        <span class="n">log_prob</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="n">entropy</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">entropy</span><span class="p">()</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">valuenet</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">action</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">log_prob</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">entropy</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">value</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="c1">########################################################################################################################################################################################################     </span>
    <span class="k">def</span> <span class="nf">compute_gae</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">dones</span><span class="p">):</span>
        <span class="n">advantages</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">gae</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">values</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># Append 0 for terminal state</span>
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rewards</span><span class="p">))):</span>
            <span class="n">delta</span> <span class="o">=</span> <span class="n">rewards</span><span class="p">[</span><span class="n">step</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">values</span><span class="p">[</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">dones</span><span class="p">[</span><span class="n">step</span><span class="p">])</span> <span class="o">-</span> <span class="n">values</span><span class="p">[</span><span class="n">step</span><span class="p">]</span>
            <span class="n">gae</span> <span class="o">=</span> <span class="n">delta</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">lam</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">dones</span><span class="p">[</span><span class="n">step</span><span class="p">])</span> <span class="o">*</span> <span class="n">gae</span>
            <span class="n">advantages</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">gae</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">advantages</span>
<span class="c1">########################################################################################################################################################################################################     </span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Convert rollout storage to tensors</span>
        <span class="n">states</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">states</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">actions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">actions</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">old_log_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">log_probs</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">returns</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">returns</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">advantages</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">advantages</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Normalize advantages</span>
        <span class="n">advantages</span> <span class="o">=</span> <span class="p">(</span><span class="n">advantages</span> <span class="o">-</span> <span class="n">advantages</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">advantages</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>

        <span class="c1"># Prepare dataset for mini-batch updates</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">TensorDataset</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">old_log_probs</span><span class="p">,</span> <span class="n">returns</span><span class="p">,</span> <span class="n">advantages</span><span class="p">)</span>
        <span class="n">loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">policy_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">value_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">entropies</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Perform multiple epochs of updates</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">epochs</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
                <span class="n">b_states</span><span class="p">,</span> <span class="n">b_actions</span><span class="p">,</span> <span class="n">b_old_log_probs</span><span class="p">,</span> <span class="n">b_returns</span><span class="p">,</span> <span class="n">b_advantages</span> <span class="o">=</span> <span class="n">batch</span>

                <span class="c1"># Forward pass through policy network</span>
                <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policynet</span><span class="p">(</span><span class="n">b_states</span><span class="p">)</span>
                <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">)</span>
                <span class="n">new_log_probs</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">b_actions</span><span class="p">)</span>
                <span class="n">entropy</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">entropy</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

                <span class="c1"># Compute ratio for PPO clipping</span>
                <span class="n">ratio</span> <span class="o">=</span> <span class="p">(</span><span class="n">new_log_probs</span> <span class="o">-</span> <span class="n">b_old_log_probs</span><span class="p">)</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>  <span class="c1"># r(theta)</span>
                <span class="n">surr1</span> <span class="o">=</span> <span class="n">ratio</span> <span class="o">*</span> <span class="n">b_advantages</span>  <span class="c1"># r(theta) * A</span>
                <span class="n">surr2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">ratio</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_epsilon</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_epsilon</span><span class="p">)</span> <span class="o">*</span> <span class="n">b_advantages</span>  <span class="c1"># Clipped</span>
                <span class="n">policy_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">surr1</span><span class="p">,</span> <span class="n">surr2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>  <span class="c1"># PPO clipped objective</span>

                <span class="c1"># Compute value loss</span>
                <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">valuenet</span><span class="p">(</span><span class="n">b_states</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">value_loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">b_returns</span><span class="p">)</span>

                <span class="c1"># Total loss</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">policy_loss</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">vf_coef</span> <span class="o">*</span> <span class="n">value_loss</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">entropy_coef</span> <span class="o">*</span> <span class="n">entropy</span>

                <span class="c1"># Backpropagation</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">policy_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">value_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

                <span class="c1"># Gradient clipping</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policynet</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_grad_norm</span><span class="p">)</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">valuenet</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_grad_norm</span><span class="p">)</span>

                <span class="c1"># Update networks</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">policy_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">value_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="c1"># Logging losses</span>
                <span class="n">policy_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">policy_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
                <span class="n">value_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
                <span class="n">entropies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">entropy</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

        <span class="c1"># Clear rollout storage after updates</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>

        <span class="c1"># Log average losses to W&amp;B</span>
        <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">({</span>
            <span class="s1">'Policy Loss'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">policy_losses</span><span class="p">),</span>
            <span class="s1">'Value Loss'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">value_losses</span><span class="p">),</span>
            <span class="s1">'Entropy'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">entropies</span><span class="p">)</span>
        <span class="p">})</span>

        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">policy_losses</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">value_losses</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">entropies</span><span class="p">)</span>
<span class="c1">########################################################################################################################################################################################################     </span>
    <span class="k">def</span> <span class="nf">train_agent</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_episodes</span><span class="p">,</span> <span class="n">rollout_length</span><span class="p">,</span> <span class="n">eval_interval</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">criterion_episodes</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="n">total_rewards</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">moving_average</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">criterion_episodes</span><span class="p">)</span>
    
        <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_episodes</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="c1"># Reset environment and get initial state</span>
            <span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>  <span class="c1"># ccheck state is a 1D vector of length 128</span>
            <span class="n">episode_reward</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">episode_length</span> <span class="o">=</span> <span class="mi">0</span>
    
            <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rollout_length</span><span class="p">):</span>
                <span class="c1"># Select action using current policy</span>
                <span class="n">action</span><span class="p">,</span> <span class="n">log_prob</span><span class="p">,</span> <span class="n">entropy</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_action</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                
                <span class="c1"># Execute action in the environment</span>
                <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
                <span class="n">next_state</span> <span class="o">=</span> <span class="n">next_state</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>  <span class="c1"># Ensure next_state is a 1D vector of length 128</span>
    
                <span class="c1"># Store experience in rollout</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">log_prob</span><span class="p">,</span> <span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">)</span>
    
                <span class="c1"># Update state and cumulative reward</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
                <span class="n">episode_reward</span> <span class="o">+=</span> <span class="n">reward</span>
                <span class="n">episode_length</span> <span class="o">+=</span> <span class="mi">1</span>
    
                <span class="c1"># If episode is done, exit the loop</span>
                <span class="k">if</span> <span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">:</span>
                    <span class="k">break</span>
    
            <span class="c1"># Append the reward for this episode</span>
            <span class="n">total_rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">episode_reward</span><span class="p">)</span>
            <span class="n">moving_average</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">episode_reward</span><span class="p">)</span>
    
            <span class="c1"># Compute returns and advantages after rollout</span>
            <span class="n">rewards</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">rewards</span><span class="p">)</span>
            <span class="n">values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
            <span class="n">dones</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">dones</span><span class="p">)</span>
            <span class="n">advantages</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_gae</span><span class="p">(</span><span class="n">rewards</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">dones</span><span class="p">)</span>
            <span class="n">returns</span> <span class="o">=</span> <span class="n">advantages</span> <span class="o">+</span> <span class="n">values</span>  <span class="c1"># Element-wise addition using NumPy arrays</span>
    
            <span class="c1"># Store advantages and returns in rollout storage for updating</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">advantages</span> <span class="o">=</span> <span class="n">advantages</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">returns</span> <span class="o">=</span> <span class="n">returns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    
            <span class="c1"># Perform PPO update using collected rollouts</span>
            <span class="n">avg_policy_loss</span><span class="p">,</span> <span class="n">avg_value_loss</span><span class="p">,</span> <span class="n">avg_entropy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
    
            <span class="c1"># Log episode reward to W&amp;B</span>
            <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">({</span>
                <span class="s1">'Episode'</span><span class="p">:</span> <span class="n">episode</span><span class="p">,</span>
                <span class="s1">'Reward'</span><span class="p">:</span> <span class="n">episode_reward</span><span class="p">,</span>
                <span class="s1">'Episode Length'</span><span class="p">:</span> <span class="n">episode_length</span>
            <span class="p">})</span>
    
            <span class="c1"># Print progress</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Episode </span><span class="si">{</span><span class="n">episode</span><span class="si">}</span><span class="s2">: Reward = </span><span class="si">{</span><span class="n">episode_reward</span><span class="si">}</span><span class="s2">, Length = </span><span class="si">{</span><span class="n">episode_length</span><span class="si">}</span><span class="s2">, "</span>
                  <span class="sa">f</span><span class="s2">"Policy Loss = </span><span class="si">{</span><span class="n">avg_policy_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Value Loss = </span><span class="si">{</span><span class="n">avg_value_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Entropy = </span><span class="si">{</span><span class="n">avg_entropy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    
            <span class="c1"># Check stopping criterion</span>
            <span class="k">if</span> <span class="n">stop_criterion</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">stop_criterion</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">moving_average</span><span class="p">)):</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Stopping criterion satisfied after </span><span class="si">{</span><span class="n">episode</span><span class="si">}</span><span class="s2"> episodes."</span><span class="p">)</span>
                <span class="k">break</span>
    
            <span class="c1"># Periodic evaluation</span>
            <span class="k">if</span> <span class="n">episode</span> <span class="o">%</span> <span class="n">eval_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">episode_num</span><span class="o">=</span><span class="n">episode</span><span class="p">)</span>
    
        <span class="c1"># Plot rewards after training</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">plot_rewards</span><span class="p">(</span><span class="n">total_rewards</span><span class="p">)</span>

<span class="c1">########################################################################################################################################################################################################     </span>
    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">episode_num</span><span class="p">):</span>
        <span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="n">terminated</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">truncated</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">frames</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">while</span> <span class="ow">not</span> <span class="p">(</span><span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">):</span>
            <span class="c1"># Render environment frame and store for video</span>
            <span class="n">frame</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>
            <span class="n">frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>

            <span class="c1"># Select action deterministically</span>
            <span class="n">action</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_action</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">evaluate</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
            <span class="n">next_state</span> <span class="o">=</span> <span class="n">next_state</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

            <span class="c1"># Update state and cumulative reward</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
            <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">reward</span>
        <span class="n">v</span><span class="o">=</span> <span class="n">VideoRecorderRAM</span><span class="p">(</span><span class="s1">'PPO'</span><span class="p">)</span>
        <span class="n">v</span><span class="o">.</span><span class="n">frames</span><span class="o">=</span><span class="n">frames</span>
        <span class="n">vfilename</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'PPO_RAM_epsiode_</span><span class="si">{</span><span class="n">episode_num</span><span class="si">}</span><span class="s1">.mp4'</span>
        <span class="n">v</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">vfilename</span><span class="p">)</span>
        <span class="n">video_path</span><span class="o">=</span><span class="s2">"PPO/"</span> <span class="o">+</span> <span class="n">vfilename</span>
        <span class="c1"># Save video of the evaluation episode</span>
        <span class="c1">#video = np.stack(frames)</span>
        <span class="c1">#video_path = f"evaluation_episode_{episode_num}.mp4"</span>
        <span class="c1">#mpy_clip = mpy.ImageSequenceClip(list(video), fps=30)</span>
        <span class="c1">#mpy_clip.write_videofile(video_path, codec="libx264")</span>

        <span class="c1"># Log evaluation results and video to W&amp;B</span>
        <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">({</span>
            <span class="s1">'Evaluation Episode'</span><span class="p">:</span> <span class="n">episode_num</span><span class="p">,</span>
            <span class="s1">'Evaluation Reward'</span><span class="p">:</span> <span class="n">total_reward</span><span class="p">,</span>
            <span class="s1">'Evaluation Video'</span><span class="p">:</span> <span class="n">wandb</span><span class="o">.</span><span class="n">Video</span><span class="p">(</span><span class="n">video_path</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">"mp4"</span><span class="p">)</span>
        <span class="p">})</span>

        <span class="c1"># Logging evaluation result</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Evaluation Episode </span><span class="si">{</span><span class="n">episode_num</span><span class="si">}</span><span class="s2">: Total Reward = </span><span class="si">{</span><span class="n">total_reward</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="c1">######################################################################################################################################################################################################## </span>
    <span class="k">def</span> <span class="nf">plot_rewards</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">total_rewards</span><span class="p">):</span>
        <span class="c1"># Plot the rewards received during training</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">dpi</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">total_rewards</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Rewards per Episode'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Episode'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Total Reward'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Training Rewards over Episodes'</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="c1">########################################################################################################################################################################################################     </span>
    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="c1"># Save network weights to a file</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
            <span class="s1">'policy_net'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">policynet</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'value_net'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">valuenet</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
        <span class="p">},</span> <span class="n">path</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Model saved to </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="c1">########################################################################################################################################################################################################     </span>
    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="c1"># Load network weights from a file</span>
        <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policynet</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'policy_net'</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valuenet</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'value_net'</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Model loaded from </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="c1">######################################################################################################################################################################################################## </span>
<span class="c1"># Initialize PPOAgent with updated hidden_sizes</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">PPOAgent</span><span class="p">(</span>
    <span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">,</span>
    <span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span>
    <span class="n">lam</span><span class="o">=</span><span class="n">lam</span><span class="p">,</span>
    <span class="n">hidden_sizes</span><span class="o">=</span><span class="n">hidden_sizes</span><span class="p">,</span>  <span class="c1"># (128, 128, 128)</span>
    <span class="n">lr_policy</span><span class="o">=</span><span class="n">lr_policy</span><span class="p">,</span>
    <span class="n">lr_value</span><span class="o">=</span><span class="n">lr_value</span><span class="p">,</span>
    <span class="n">clip_epsilon</span><span class="o">=</span><span class="n">clip_epsilon</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">entropy_coef</span><span class="o">=</span><span class="n">entropy_coef</span><span class="p">,</span>
    <span class="n">vf_coef</span><span class="o">=</span><span class="n">vf_coef</span><span class="p">,</span>
    <span class="n">max_grad_norm</span><span class="o">=</span><span class="n">max_grad_norm</span>
<span class="p">)</span>

<span class="c1"># Define stopping criterion (optional)</span>
<span class="k">def</span> <span class="nf">stopping_criterion</span><span class="p">(</span><span class="n">rewards</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rewards</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">100</span>  <span class="c1"># Example: stop if average reward over last 5 episodes &gt;= 100</span>

<span class="c1"># Start training</span>
<span class="n">agent</span><span class="o">.</span><span class="n">train_agent</span><span class="p">(</span>
    <span class="n">max_episodes</span><span class="o">=</span><span class="n">num_episodes</span><span class="p">,</span>
    <span class="n">rollout_length</span><span class="o">=</span><span class="n">rollout_length</span><span class="p">,</span>
    <span class="n">eval_interval</span><span class="o">=</span><span class="n">eval_interval</span><span class="p">,</span>
    <span class="n">stop_criterion</span><span class="o">=</span><span class="n">stopping_criterion</span><span class="p">,</span>
    <span class="n">criterion_episodes</span><span class="o">=</span><span class="n">criterion_episodes</span>
<span class="p">)</span>

<span class="c1"># Close the environment after training</span>
<span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=80f30317-d49c-420a-b3cb-0954eac17773">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[5]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">wandb</span> tristancarlisle/PPO-Boxing/runs/x8enwys0
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
<iframe src="https://wandb.ai/tristancarlisle/PPO-Boxing/runs/x8enwys0?jupyter=true" style="border:none;width:100%;height:420px;"></iframe>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=f8c36d14-99db-4388-82df-b673b263d879">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">PPO</span> <span class="n">also</span> <span class="n">Won</span> <span class="n">no</span> <span class="n">knowout</span> <span class="n">though</span> 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=75ccf3ab-7801-4f2b-b936-ee88a5d3de65">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Proximal-Policy-Optimization-(PPO)-Image-Observations">Proximal Policy Optimization (PPO) Image Observations<a class="anchor-link" href="#Proximal-Policy-Optimization-(PPO)-Image-Observations"></a></h4>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=ed595ac5-a824-478d-bb8e-bfcd3c9aaf9e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="Policy-Value-Network">Policy Value Network<a class="anchor-link" href="#Policy-Value-Network"></a></h5><p>Similar to the Dueling structure</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=5fded590-ba78-4fc9-8ed0-c65eac9378ed">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># from REINFORCE actor-critic prac 9 </span>
<span class="c1">#changed dramatically for images though </span>
<span class="k">class</span> <span class="nc">PolicyNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">num_actions</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>

        <span class="c1">#Conv feature extraction section</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>    
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
        <span class="n">conv_out_size</span>
        <span class="c1">#Fully connectlayer</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shared_fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">conv_out_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
        <span class="p">)</span>
        
        <span class="c1"># Policy head</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">num_actions</span><span class="p">)</span>
        
        <span class="c1"># Value head</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shared_fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">action_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">state_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">action_probs</span><span class="p">,</span> <span class="n">state_value</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=738dd496-ba0f-4545-acd2-0254b42368d0">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="PPO-Agent">PPO Agent<a class="anchor-link" href="#PPO-Agent"></a></h5>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=99f78f76-c2d6-4c7e-b3bd-3f65929693d8">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[36]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">PPOAgent</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">lam</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span><span class="mi">128</span><span class="p">),</span>
                 <span class="n">lr_policy</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">lr_value</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">clip_epsilon</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">episodes</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                 <span class="n">entropy_coef</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">vf_coef</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">max_grad_norm</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lam</span> <span class="o">=</span> <span class="n">lam</span>  <span class="c1"># GAE lambda</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clip_epsilon</span> <span class="o">=</span> <span class="n">clip_epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">episodes</span> <span class="o">=</span> <span class="n">episodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">entropy_coef</span> <span class="o">=</span> <span class="n">entropy_coef</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vf_coef</span> <span class="o">=</span> <span class="n">vf_coef</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_grad_norm</span> <span class="o">=</span> <span class="n">max_grad_norm</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span>
        
        <span class="c1"># Policy and Value network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span> <span class="o">=</span> <span class="n">PolicyValueNetwork</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_shape</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr_policy</span><span class="p">)</span>
        
        <span class="c1"># Rollout storage</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">storage</span> <span class="o">=</span> <span class="n">RolloutStorage</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">select_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Add batch dimension</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">action_probs</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">probs</span><span class="o">=</span><span class="n">action_probs</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">evaluate</span><span class="p">:</span>
                <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">action_probs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">action</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">action</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">action_probs</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">value</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dist</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">action</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dist</span><span class="o">.</span><span class="n">entropy</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="k">def</span> <span class="nf">compute_gae</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">dones</span><span class="p">):</span>
        <span class="n">advantages</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">gae</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">values</span> <span class="o">=</span> <span class="n">values</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rewards</span><span class="p">))):</span>
            <span class="n">delta</span> <span class="o">=</span> <span class="n">rewards</span><span class="p">[</span><span class="n">step</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">values</span><span class="p">[</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">dones</span><span class="p">[</span><span class="n">step</span><span class="p">])</span> <span class="o">-</span> <span class="n">values</span><span class="p">[</span><span class="n">step</span><span class="p">]</span>
            <span class="n">gae</span> <span class="o">=</span> <span class="n">delta</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">lam</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">dones</span><span class="p">[</span><span class="n">step</span><span class="p">])</span> <span class="o">*</span> <span class="n">gae</span>
            <span class="n">advantages</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">gae</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">advantages</span>
    
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">states</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">states</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">actions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">actions</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">old_log_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">log_probs</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">returns</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">returns</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">advantages</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">advantages</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Normalize advantages</span>
        <span class="n">advantages</span> <span class="o">=</span> <span class="p">(</span><span class="n">advantages</span> <span class="o">-</span> <span class="n">advantages</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">advantages</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>
        
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">TensorDataset</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">old_log_probs</span><span class="p">,</span> <span class="n">returns</span><span class="p">,</span> <span class="n">advantages</span><span class="p">)</span>
        <span class="n">loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> 
        
        <span class="n">total_policy_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">total_value_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">total_entropy</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
            <span class="n">b_states</span><span class="p">,</span> <span class="n">b_actions</span><span class="p">,</span> <span class="n">b_old_log_probs</span><span class="p">,</span> <span class="n">b_returns</span><span class="p">,</span> <span class="n">b_advantages</span> <span class="o">=</span> <span class="n">batch</span>
            
            <span class="n">action_probs</span><span class="p">,</span> <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="p">(</span><span class="n">b_states</span><span class="p">)</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">probs</span><span class="o">=</span><span class="n">action_probs</span><span class="p">)</span>
            <span class="n">entropy</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">entropy</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            <span class="n">new_log_probs</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">b_actions</span><span class="p">)</span>
            
            <span class="c1"># Ratio for PPO clipping</span>
            <span class="n">ratio</span> <span class="o">=</span> <span class="p">(</span><span class="n">new_log_probs</span> <span class="o">-</span> <span class="n">b_old_log_probs</span><span class="p">)</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>
            <span class="n">surr1</span> <span class="o">=</span> <span class="n">ratio</span> <span class="o">*</span> <span class="n">b_advantages</span>
            <span class="n">surr2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">ratio</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_epsilon</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_epsilon</span><span class="p">)</span> <span class="o">*</span> <span class="n">b_advantages</span>
            <span class="n">policy_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">surr1</span><span class="p">,</span> <span class="n">surr2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            
            <span class="c1"># Value function loss</span>
            <span class="n">value_loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">values</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">b_returns</span><span class="p">)</span><span class="c1"># have to squeeze values again</span>
            
            <span class="c1"># Total loss</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">policy_loss</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">vf_coef</span> <span class="o">*</span> <span class="n">value_loss</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">entropy_coef</span> <span class="o">*</span> <span class="n">entropy</span>
            
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_grad_norm</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            
            <span class="n">total_policy_loss</span> <span class="o">+=</span> <span class="n">policy_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">total_value_loss</span> <span class="o">+=</span> <span class="n">value_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">total_entropy</span> <span class="o">+=</span> <span class="n">entropy</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        
        <span class="n">num_updates</span> <span class="o">=</span>  <span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="p">)</span>
        <span class="n">avg_policy_loss</span> <span class="o">=</span> <span class="n">total_policy_loss</span> <span class="o">/</span> <span class="n">num_updates</span>
        <span class="n">avg_value_loss</span> <span class="o">=</span> <span class="n">total_value_loss</span> <span class="o">/</span> <span class="n">num_updates</span>
        <span class="n">avg_entropy</span> <span class="o">=</span> <span class="n">total_entropy</span> <span class="o">/</span> <span class="n">num_updates</span>
        
        <span class="c1"># Clear storage</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
        
        <span class="k">return</span> <span class="n">avg_policy_loss</span><span class="p">,</span> <span class="n">avg_value_loss</span><span class="p">,</span> <span class="n">avg_entropy</span>
    
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_episodes</span><span class="p">,</span> <span class="n">max_steps_per_episode</span><span class="p">,</span> <span class="n">rollout_length</span><span class="p">,</span> <span class="n">eval_interval</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
        <span class="n">total_rewards</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">episode_reward</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">episode_length</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">total_episodes</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">step</span> <span class="o">=</span> <span class="mi">0</span>
            
           <span class="k">while</span> <span class="n">total_episodes</span> <span class="o">&lt;</span> <span class="n">num_episodes</span><span class="p">:</span>
                <span class="c1"># Collect rollout</span>
                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rollout_length</span><span class="p">):</span>
                    <span class="n">action</span><span class="p">,</span> <span class="n">action_probs</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">log_prob</span><span class="p">,</span> <span class="n">entropy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_action</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                    <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
                    
                    <span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">log_prob</span><span class="p">,</span> <span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">)</span>
                    
                    <span class="n">episode_reward</span> <span class="o">+=</span> <span class="n">reward</span>
                    <span class="n">episode_length</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">step</span> <span class="o">+=</span> <span class="mi">1</span>
                    
                    <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
                    

                    <span class="k">if</span> <span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span> <span class="ow">or</span> <span class="n">episode_length</span> <span class="o">&gt;=</span> <span class="n">max_steps_per_episode</span><span class="p">:</span>
                        <span class="n">total_rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">episode_reward</span><span class="p">)</span>
                        
                        <span class="c1"># Log to W&amp;B</span>
                        <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">({</span>
                            <span class="s1">'episode'</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">total_rewards</span><span class="p">),</span>
                            <span class="s1">'episode_reward'</span><span class="p">:</span> <span class="n">episode_rewards</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                            <span class="s1">'episode_length'</span><span class="p">:</span> <span class="n">episode_lengths</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                        <span class="p">})</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Episode </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">total_rewards</span><span class="p">)</span><span class="si">}</span><span class="s2">: Total Reward = </span><span class="si">{</span><span class="n">episode_rewards</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
                        <span class="n">episode_rewards</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
                        <span class="n">episode_lengths</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
                        <span class="n">total_episodes</span> <span class="o">+=</span> <span class="mi">1</span>

                        <span class="c1">#added to check how training is going so I can stop it its no good. I just aet to half way first</span>
                        <span class="k">if</span> <span class="n">total_episodes</span> <span class="o">%</span> <span class="n">eval_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">total_episodes</span><span class="p">)</span>
                        
                        <span class="c1">#end training after max number of episodes</span>
                        <span class="k">if</span> <span class="n">total_episodes</span> <span class="o">&gt;=</span> <span class="n">num_episodes</span><span class="p">:</span>
                            <span class="k">break</span>
        
                
                <span class="c1"># Compute returns and advantages</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="n">_</span><span class="p">,</span> <span class="n">next_value</span> <span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
                    <span class="n">next_value</span> <span class="o">=</span> <span class="n">next_value</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="c1">#back to cpu to convert to numpy :| , also have to resqueeze</span>
                <span class="n">advantages</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_gae</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">rewards</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">values</span> <span class="o">+</span> <span class="p">[</span><span class="n">next_value</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">dones</span><span class="p">)</span>
                <span class="n">returns</span> <span class="o">=</span> <span class="p">[</span><span class="n">adv</span> <span class="o">+</span> <span class="n">val</span> <span class="k">for</span> <span class="n">adv</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">advantages</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">values</span><span class="p">)]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">advantages</span> <span class="o">=</span> <span class="n">advantages</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">returns</span> <span class="o">=</span> <span class="n">returns</span>
                
                <span class="c1"># Update policy and value networks</span>
                <span class="n">avg_policy_loss</span><span class="p">,</span> <span class="n">avg_value_loss</span><span class="p">,</span> <span class="n">avg_entropy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
                
                <span class="c1"># Log to W&amp;B</span>
                <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">({</span>
                    <span class="s1">'policy_loss'</span><span class="p">:</span> <span class="n">avg_policy_loss</span><span class="p">,</span>
                    <span class="s1">'value_loss'</span><span class="p">:</span> <span class="n">avg_value_loss</span><span class="p">,</span>
                    <span class="s1">'entropy'</span><span class="p">:</span> <span class="n">avg_entropy</span><span class="p">,</span>
                <span class="p">})</span>
                
            <span class="c1"># Plot rewards</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">plot_rewards</span><span class="p">(</span><span class="n">total_rewards</span><span class="p">)</span>

        <span class="c1">#I kept interupting training and I wanted to see a plot so I added a keyboard exception so if I cntrl c I can see how the training was going </span>
        <span class="c1">#I also save the check point so I can continue where I left off </span>
        <span class="k">except</span> <span class="ne">KeyboardInterrupt</span><span class="p">:</span> 
            <span class="nb">print</span><span class="p">(</span><span class="s2">"training interrupted saving model"</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">'ppo_checkpoint.pth'</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"model saved."</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">plot_rewards</span><span class="p">(</span><span class="n">total_rewards</span><span class="p">)</span>
    
    <span class="c1">#just made the plotting a function so I could call it instead</span>
    <span class="k">def</span> <span class="nf">plot_rewards</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">total_rewards</span><span class="p">):</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">dpi</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">total_rewards</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Episode'</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Total Reward'</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Training Rewards over Episodes'</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="c1">#turned the evaluation section into a function because I got sick of redoing it </span>
    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">episode_num</span><span class="p">):</span>
        <span class="n">eval_env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">'ALE/Boxing-v5'</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">"rgb_array"</span><span class="p">,</span> <span class="n">obs_type</span><span class="o">=</span><span class="s2">"grayscale"</span><span class="p">)</span>
        <span class="n">eval_env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">wrappers</span><span class="o">.</span><span class="n">ResizeObservation</span><span class="p">(</span><span class="n">eval_env</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="mi">84</span><span class="p">))</span>
        <span class="n">eval_env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">wrappers</span><span class="o">.</span><span class="n">NormalizeObservation</span><span class="p">(</span><span class="n">eval_env</span><span class="p">)</span>
        
        <span class="n">state</span> <span class="o">=</span> <span class="n">eval_env</span><span class="o">.</span><span class="n">reset</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">terminated</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">truncated</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">frames</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">while</span> <span class="ow">not</span> <span class="p">(</span><span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">):</span>
            <span class="n">frame</span> <span class="o">=</span> <span class="n">eval_env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">'rgb_array'</span><span class="p">)</span>
            <span class="n">frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>
            <span class="n">action</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_action</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">evaluate</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">eval_env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
            <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">reward</span>

        <span class="n">eval_env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="n">video</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">frames</span><span class="p">)</span>
        <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">({</span>
            <span class="s1">'evaluation_reward'</span><span class="p">:</span> <span class="n">total_reward</span><span class="p">,</span>
            <span class="s1">'evaluation_episode'</span><span class="p">:</span> <span class="n">episode_num</span><span class="p">,</span>
            <span class="s1">'evaluation_video'</span><span class="p">:</span> <span class="n">wandb</span><span class="o">.</span><span class="n">Video</span><span class="p">(</span><span class="n">video</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">"mp4"</span><span class="p">)</span>
        <span class="p">})</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Evaluation Episode </span><span class="si">{</span><span class="n">episode_num</span><span class="si">}</span><span class="s2">: Total Reward = </span><span class="si">{</span><span class="n">total_reward</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    
    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">path</span><span class="p">)</span>
        <span class="n">wandb</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">))</span><span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.99</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
Finishing last run (ID:4eqecqx3) before initializing another...
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>VBox(children=(Label(value='0.005 MB of 0.005 MB uploaded\r'), FloatProgress(value=1.0, max=1.0)))</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
<style>
    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}
    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }
    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }
    </style>
<div class="wandb-row"><div class="wandb-col"><h3>Run history:</h3><br/><table class="wandb"><tr><td>episode</td><td></td></tr><tr><td>episode_reward</td><td></td></tr><tr><td>epsilon threshold</td><td></td></tr><tr><td>steps</td><td></td></tr></table><br/></div><div class="wandb-col"><h3>Run summary:</h3><br/><table class="wandb"><tr><td>episode</td><td>99</td></tr><tr><td>episode_reward</td><td>-15</td></tr><tr><td>epsilon threshold</td><td>0.0767</td></tr><tr><td>steps</td><td>178600</td></tr></table><br/></div></div>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
 View run <strong style="color:#cdcd00">DDQN dueling</strong> at: <a href="https://wandb.ai/tristancarlisle/DQN/runs/4eqecqx3" target="_blank">https://wandb.ai/tristancarlisle/DQN/runs/4eqecqx3</a><br/> View project at: <a href="https://wandb.ai/tristancarlisle/DQN" target="_blank">https://wandb.ai/tristancarlisle/DQN</a><br/>Synced 5 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
Find logs at: <code>./wandb/run-20241014_212918-4eqecqx3/logs</code>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
Successfully finished last run (ID:4eqecqx3). Initializing new run:<br/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
Tracking run with wandb version 0.18.3
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
Run data is saved locally in <code>/home/tristan/UniStuff/ReinforcementLearning/Assignment/wandb/run-20241015_101007-p9pe6sx9</code>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
Syncing run <strong><a href="https://wandb.ai/tristancarlisle/PPO-Boxing/runs/p9pe6sx9" target="_blank">smart-surf-1</a></strong> to <a href="https://wandb.ai/tristancarlisle/PPO-Boxing" target="_blank">Weights &amp; Biases</a> (<a href="https://wandb.me/run" target="_blank">docs</a>)<br/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
 View project at <a href="https://wandb.ai/tristancarlisle/PPO-Boxing" target="_blank">https://wandb.ai/tristancarlisle/PPO-Boxing</a>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
 View run at <a href="https://wandb.ai/tristancarlisle/PPO-Boxing/runs/p9pe6sx9" target="_blank">https://wandb.ai/tristancarlisle/PPO-Boxing/runs/p9pe6sx9</a>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[36], line 331</span>
<span class="ansi-green-intense-fg ansi-bold">    312</span> wandb<span style="color: rgb(98,98,98)">.</span>init(project<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(175,0,0)">'</span><span style="color: rgb(175,0,0)">PPO-Boxing</span><span style="color: rgb(175,0,0)">'</span>, config<span style="color: rgb(98,98,98)">=</span>{
<span class="ansi-green-intense-fg ansi-bold">    313</span>     <span style="color: rgb(175,0,0)">'</span><span style="color: rgb(175,0,0)">gamma</span><span style="color: rgb(175,0,0)">'</span>: gamma,
<span class="ansi-green-intense-fg ansi-bold">    314</span>     <span style="color: rgb(175,0,0)">'</span><span style="color: rgb(175,0,0)">lam</span><span style="color: rgb(175,0,0)">'</span>: lam,
<span class="ansi-green-fg">   (...)</span>
<span class="ansi-green-intense-fg ansi-bold">    327</span>     <span style="color: rgb(175,0,0)">'</span><span style="color: rgb(175,0,0)">num_envs</span><span style="color: rgb(175,0,0)">'</span>: num_envs,
<span class="ansi-green-intense-fg ansi-bold">    328</span> })
<span class="ansi-green-intense-fg ansi-bold">    330</span> <span style="color: rgb(95,135,135)"># Initialize the PPO agent</span>
<span class="ansi-green-fg">--&gt; 331</span> agent <span style="color: rgb(98,98,98)">=</span> PPOAgent(
<span class="ansi-green-intense-fg ansi-bold">    332</span>     env_fns,
<span class="ansi-green-intense-fg ansi-bold">    333</span>     gamma<span style="color: rgb(98,98,98)">=</span>gamma,
<span class="ansi-green-intense-fg ansi-bold">    334</span>     lam<span style="color: rgb(98,98,98)">=</span>lam,
<span class="ansi-green-intense-fg ansi-bold">    335</span>     hidden_sizes<span style="color: rgb(98,98,98)">=</span>hidden_sizes,
<span class="ansi-green-intense-fg ansi-bold">    336</span>     lr_policy<span style="color: rgb(98,98,98)">=</span>lr_policy,
<span class="ansi-green-intense-fg ansi-bold">    337</span>     lr_value<span style="color: rgb(98,98,98)">=</span>lr_value,
<span class="ansi-green-intense-fg ansi-bold">    338</span>     clip_epsilon<span style="color: rgb(98,98,98)">=</span>clip_epsilon,
<span class="ansi-green-intense-fg ansi-bold">    339</span>     epochs<span style="color: rgb(98,98,98)">=</span>epochs,
<span class="ansi-green-intense-fg ansi-bold">    340</span>     batch_size<span style="color: rgb(98,98,98)">=</span>batch_size,
<span class="ansi-green-intense-fg ansi-bold">    341</span>     entropy_coef<span style="color: rgb(98,98,98)">=</span>entropy_coef,
<span class="ansi-green-intense-fg ansi-bold">    342</span>     vf_coef<span style="color: rgb(98,98,98)">=</span>vf_coef,
<span class="ansi-green-intense-fg ansi-bold">    343</span>     max_grad_norm<span style="color: rgb(98,98,98)">=</span>max_grad_norm
<span class="ansi-green-intense-fg ansi-bold">    344</span> )
<span class="ansi-green-intense-fg ansi-bold">    346</span> <span style="color: rgb(95,135,135)"># Train the agent</span>
<span class="ansi-green-intense-fg ansi-bold">    347</span> agent<span style="color: rgb(98,98,98)">.</span>train(num_episodes, max_steps_per_episode, rollout_length)

Cell <span class="ansi-green-fg">In[36], line 6</span>, in <span class="ansi-cyan-fg">PPOAgent.__init__</span><span class="ansi-blue-fg">(self, env_fns, gamma, lam, hidden_sizes, lr_policy, lr_value, clip_epsilon, epochs, batch_size, entropy_coef, vf_coef, max_grad_norm)</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span> <span class="ansi-bold" style="color: rgb(0,135,0)">def</span> <span style="color: rgb(0,0,255)">__init__</span>(<span style="color: rgb(0,135,0)">self</span>, env_fns, gamma<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(98,98,98)">0.99</span>, lam<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(98,98,98)">0.95</span>, hidden_sizes<span style="color: rgb(98,98,98)">=</span>(<span style="color: rgb(98,98,98)">128</span>,<span style="color: rgb(98,98,98)">128</span>),
<span class="ansi-green-intense-fg ansi-bold">      3</span>              lr_policy<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(98,98,98)">1e-4</span>, lr_value<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(98,98,98)">1e-3</span>, clip_epsilon<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(98,98,98)">0.2</span>, epochs<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(98,98,98)">10</span>, batch_size<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(98,98,98)">128</span>,
<span class="ansi-green-intense-fg ansi-bold">      4</span>              entropy_coef<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(98,98,98)">0.01</span>, vf_coef<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(98,98,98)">0.5</span>, max_grad_norm<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(98,98,98)">0.5</span>):
<span class="ansi-green-fg">----&gt; 6</span>     <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>envs <span style="color: rgb(98,98,98)">=</span> gym<span style="color: rgb(98,98,98)">.</span>vector<span style="color: rgb(98,98,98)">.</span>AsyncVectorEnv(env_fns)
<span class="ansi-green-intense-fg ansi-bold">      7</span>     <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>num_envs <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">len</span>(env_fns)
<span class="ansi-green-intense-fg ansi-bold">      8</span>     <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>gamma <span style="color: rgb(98,98,98)">=</span> gamma

File <span class="ansi-green-fg">~/miniconda3/envs/ReinforcementLearning/lib/python3.11/site-packages/gymnasium/vector/async_vector_env.py:105</span>, in <span class="ansi-cyan-fg">AsyncVectorEnv.__init__</span><span class="ansi-blue-fg">(self, env_fns, observation_space, action_space, shared_memory, copy, context, daemon, worker)</span>
<span class="ansi-green-intense-fg ansi-bold">    103</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>shared_memory <span style="color: rgb(98,98,98)">=</span> shared_memory
<span class="ansi-green-intense-fg ansi-bold">    104</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>copy <span style="color: rgb(98,98,98)">=</span> copy
<span class="ansi-green-fg">--&gt; 105</span> dummy_env <span style="color: rgb(98,98,98)">=</span> env_fns[<span style="color: rgb(98,98,98)">0</span>]()
<span class="ansi-green-intense-fg ansi-bold">    106</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>metadata <span style="color: rgb(98,98,98)">=</span> dummy_env<span style="color: rgb(98,98,98)">.</span>metadata
<span class="ansi-green-intense-fg ansi-bold">    108</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> (observation_space <span class="ansi-bold" style="color: rgb(175,0,255)">is</span> <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>) <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> (action_space <span class="ansi-bold" style="color: rgb(175,0,255)">is</span> <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>):

Cell <span class="ansi-green-fg">In[36], line 284</span>, in <span class="ansi-cyan-fg">make_env.&lt;locals&gt;._init</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">    282</span> <span class="ansi-bold" style="color: rgb(0,135,0)">def</span> <span style="color: rgb(0,0,255)">_init</span>():
<span class="ansi-green-intense-fg ansi-bold">    283</span>     env <span style="color: rgb(98,98,98)">=</span> gym<span style="color: rgb(98,98,98)">.</span>make(<span style="color: rgb(175,0,0)">'</span><span style="color: rgb(175,0,0)">ALE/Boxing-v5</span><span style="color: rgb(175,0,0)">'</span>, render_mode<span style="color: rgb(98,98,98)">=</span><span class="ansi-bold" style="color: rgb(0,135,0)">None</span>)
<span class="ansi-green-fg">--&gt; 284</span>     env <span style="color: rgb(98,98,98)">=</span> PreprocessFrame(env, height<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(98,98,98)">84</span>, width<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(98,98,98)">84</span>, grayscale<span style="color: rgb(98,98,98)">=</span><span class="ansi-bold" style="color: rgb(0,135,0)">True</span>)
<span class="ansi-green-intense-fg ansi-bold">    285</span>     env <span style="color: rgb(98,98,98)">=</span> FrameSkip(env, skip<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(98,98,98)">4</span>)
<span class="ansi-green-intense-fg ansi-bold">    286</span>     env <span style="color: rgb(98,98,98)">=</span> FrameStack(env, k<span style="color: rgb(98,98,98)">=</span><span style="color: rgb(98,98,98)">4</span>)

<span class="ansi-red-fg">NameError</span>: name 'PreprocessFrame' is not defined</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=107a3f39-3083-4f62-a9ad-b2d5c0bd4e7f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Added a rollout storage function for PPO to keep track</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=0ee4f47d-c6d2-423a-9468-b5b406f0573a">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">RolloutStorage</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">log_prob</span><span class="p">,</span> <span class="n">done</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_probs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">log_prob</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dones</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">done</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">clear</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">states</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_probs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dones</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">advantages</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">returns</span> <span class="o">=</span> <span class="p">[]</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=2798c429-08ed-45b9-a820-e22371713c59">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h5 id="Env-build,-logging-and-evaluation">Env build, logging and evaluation<a class="anchor-link" href="#Env-build,-logging-and-evaluation"></a></h5>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=5e6c140f-e10d-45e5-ad40-54793a4dcfda">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Create the environment with preprocessing and frame stacking</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">'ALE/Boxing-v5'</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">"rgb_array"</span><span class="p">,</span><span class="n">obs_type</span><span class="o">=</span><span class="s2">"grayscale"</span><span class="p">)</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">wrappers</span><span class="o">.</span><span class="n">ResizeObservation</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="mi">84</span><span class="p">))</span>    <span class="c1"># Resize to 84x84</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">wrappers</span><span class="o">.</span><span class="n">NormalizeObservation</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
<span class="n">env</span> <span class="o">=</span>  <span class="n">gym</span><span class="o">.</span><span class="n">wrappers</span><span class="o">.</span><span class="n">FrameStack</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">num_stack</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.99</span>
<span class="n">lam</span> <span class="o">=</span> <span class="mf">0.95</span>
<span class="n">hidden_sizes</span> <span class="o">=</span> <span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
<span class="n">lr_policy</span> <span class="o">=</span> <span class="mf">1e-4</span>
<span class="n">lr_value</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">clip_epsilon</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">entropy_coef</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">vf_coef</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">max_grad_norm</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">num_episodes</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">max_steps_per_episode</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">rollout_length</span> <span class="o">=</span> <span class="mi">128</span>

<span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">project</span><span class="o">=</span><span class="s1">'PPO-Boxing'</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="p">{</span>
    <span class="s1">'gamma'</span><span class="p">:</span> <span class="n">gamma</span><span class="p">,</span>
    <span class="s1">'lam'</span><span class="p">:</span> <span class="n">lam</span><span class="p">,</span>
    <span class="s1">'hidden_sizes'</span><span class="p">:</span> <span class="n">hidden_sizes</span><span class="p">,</span>
    <span class="s1">'lr_policy'</span><span class="p">:</span> <span class="n">lr_policy</span><span class="p">,</span>
    <span class="s1">'lr_value'</span><span class="p">:</span> <span class="n">lr_value</span><span class="p">,</span>
    <span class="s1">'clip_epsilon'</span><span class="p">:</span> <span class="n">clip_epsilon</span><span class="p">,</span>
    <span class="s1">'batch_size'</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">,</span>
    <span class="s1">'entropy_coef'</span><span class="p">:</span> <span class="n">entropy_coef</span><span class="p">,</span>
    <span class="s1">'vf_coef'</span><span class="p">:</span> <span class="n">vf_coef</span><span class="p">,</span>
    <span class="s1">'max_grad_norm'</span><span class="p">:</span> <span class="n">max_grad_norm</span><span class="p">,</span>
    <span class="s1">'num_episodes'</span><span class="p">:</span> <span class="n">num_episodes</span><span class="p">,</span>
    <span class="s1">'max_steps_per_episode'</span><span class="p">:</span> <span class="n">max_steps_per_episode</span><span class="p">,</span>
    <span class="s1">'rollout_length'</span><span class="p">:</span> <span class="n">rollout_length</span><span class="p">,</span>
<span class="p">})</span>

<span class="c1"># Initialize the PPO agent</span>
<span class="n">PPOagent</span> <span class="o">=</span> <span class="n">PPOAgent</span><span class="p">(</span>
    <span class="n">env</span><span class="p">,</span>
    <span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span>
    <span class="n">lam</span><span class="o">=</span><span class="n">lam</span><span class="p">,</span>
    <span class="n">hidden_sizes</span><span class="o">=</span><span class="n">hidden_sizes</span><span class="p">,</span>
    <span class="n">lr_policy</span><span class="o">=</span><span class="n">lr_policy</span><span class="p">,</span>
    <span class="n">lr_value</span><span class="o">=</span><span class="n">lr_value</span><span class="p">,</span>
    <span class="n">clip_epsilon</span><span class="o">=</span><span class="n">clip_epsilon</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">entropy_coef</span><span class="o">=</span><span class="n">entropy_coef</span><span class="p">,</span>
    <span class="n">vf_coef</span><span class="o">=</span><span class="n">vf_coef</span><span class="p">,</span>
    <span class="n">max_grad_norm</span><span class="o">=</span><span class="n">max_grad_norm</span>
<span class="p">)</span>


<span class="c1"># Train the agent</span>
<span class="n">PPOagent</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">num_episodes</span><span class="p">,</span> <span class="n">max_steps_per_episode</span><span class="p">,</span> <span class="n">rollout_length</span><span class="p">)</span>

<span class="c1"># Visualize one episode</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">make_env</span><span class="p">()()</span>
<span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="n">terminated</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">truncated</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">frames</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">while</span> <span class="ow">not</span> <span class="p">(</span><span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">):</span>
    <span class="n">frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">'rgb_array'</span><span class="p">))</span>
    <span class="n">action</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">select_action</span><span class="p">([</span><span class="n">state</span><span class="p">])</span>
    <span class="n">state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">reward</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Total Reward: </span><span class="si">{</span><span class="n">total_reward</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Close the environment</span>
<span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="c1"># Create and play video clip using the frames and given fps</span>
<span class="c1">#clip = mpy.ImageSequenceClip(frames, fps=30)</span>
<span class="c1">#clip.ipython_display(rd_kwargs=dict(logger=None))</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=18e0bc23-ccc5-44a1-a034-74080f42cc75">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Hyperparameter-Sweep-PPO-(RAM)">Hyperparameter Sweep PPO (RAM)<a class="anchor-link" href="#Hyperparameter-Sweep-PPO-(RAM)"></a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=7be65fc1-4e92-4dc0-a128-10073aac07b4">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Set device</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>

<span class="c1"># Set random seeds for reproducibility</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">RolloutStorage</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">log_prob</span><span class="p">,</span> <span class="n">done</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_probs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">log_prob</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dones</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">done</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">clear</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">states</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_probs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dones</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">advantages</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">returns</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># 3. Define the Policy and Value Networks</span>
<span class="k">class</span> <span class="nc">PolicyNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">output_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">output_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">ValueNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=a86dbc2b-0607-4525-b169-5b66c27eebcc">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 1. Define the Sweep Configuration</span>
<span class="n">sweep_configuration</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"method"</span><span class="p">:</span> <span class="s2">"random"</span><span class="p">,</span>  <span class="c1"># Options: "grid", "random", "bayes"</span>
    <span class="s2">"metric"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"Evaluation Reward"</span><span class="p">,</span>  <span class="c1"># The metric to optimize</span>
        <span class="s2">"goal"</span><span class="p">:</span> <span class="s2">"maximize"</span>             <span class="c1"># Whether to "minimize" or "maximize"</span>
    <span class="p">},</span>
    <span class="s2">"parameters"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">"gamma"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Discount factor for future rewards</span>
            <span class="s2">"distribution"</span><span class="p">:</span> <span class="s2">"uniform"</span><span class="p">,</span>
            <span class="s2">"min"</span><span class="p">:</span> <span class="mf">0.90</span><span class="p">,</span>
            <span class="s2">"max"</span><span class="p">:</span> <span class="mf">0.99</span>
        <span class="p">},</span>
        <span class="s2">"lam"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># GAE lambda</span>
            <span class="s2">"distribution"</span><span class="p">:</span> <span class="s2">"uniform"</span><span class="p">,</span>
            <span class="s2">"min"</span><span class="p">:</span> <span class="mf">0.90</span><span class="p">,</span>
            <span class="s2">"max"</span><span class="p">:</span> <span class="mf">0.99</span>
        <span class="p">},</span>
        <span class="s2">"lr_policy"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Learning rate for the policy network</span>
            <span class="s2">"distribution"</span><span class="p">:</span> <span class="s2">"uniform"</span><span class="p">,</span>
            <span class="s2">"min"</span><span class="p">:</span> <span class="mf">1e-5</span><span class="p">,</span>
            <span class="s2">"max"</span><span class="p">:</span> <span class="mf">1e-3</span>
        <span class="p">},</span>
        <span class="s2">"lr_value"</span><span class="p">:</span> <span class="p">{</span>   <span class="c1"># Learning rate for the value network</span>
            <span class="s2">"distribution"</span><span class="p">:</span> <span class="s2">"uniform"</span><span class="p">,</span>
            <span class="s2">"min"</span><span class="p">:</span> <span class="mf">1e-5</span><span class="p">,</span>
            <span class="s2">"max"</span><span class="p">:</span> <span class="mf">1e-3</span>
        <span class="p">},</span>
        <span class="s2">"clip_epsilon"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># PPO clipping parameter</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">]</span>
        <span class="p">},</span>
        <span class="s2">"hidden_sizes"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Architecture of hidden layers</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="s2">"(64,64,64)"</span><span class="p">,</span> <span class="s2">"(128,128,128)"</span><span class="p">,</span> <span class="s2">"(256,256,256)"</span><span class="p">]</span>
        <span class="p">},</span>
        <span class="s2">"entropy_coef"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Entropy regularization coefficient</span>
            <span class="s2">"distribution"</span><span class="p">:</span> <span class="s2">"uniform"</span><span class="p">,</span>
            <span class="s2">"min"</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
            <span class="s2">"max"</span><span class="p">:</span> <span class="mf">0.1</span>
        <span class="p">},</span>
        <span class="s2">"vf_coef"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Value function loss coefficient</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>
        <span class="p">},</span>
        <span class="s2">"batch_size"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Mini-batch size for updates</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">]</span>
        <span class="p">},</span>
        <span class="s2">"epochs"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Number of PPO update epochs</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
        <span class="p">},</span>
        <span class="s2">"max_grad_norm"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Gradient clipping norm</span>
            <span class="s2">"distribution"</span><span class="p">:</span> <span class="s2">"uniform"</span><span class="p">,</span>
            <span class="s2">"min"</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">,</span>
            <span class="s2">"max"</span><span class="p">:</span> <span class="mf">1.0</span>
        <span class="p">},</span>
        <span class="s2">"num_episodes"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Total number of training episodes</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mi">500</span><span class="p">,</span> <span class="mi">1000</span><span class="p">]</span>
        <span class="p">},</span>
        <span class="s2">"rollout_length"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Number of steps to collect before an update</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">]</span>
        <span class="p">},</span>
        <span class="s2">"eval_interval"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Interval (in episodes) for evaluations</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
        <span class="p">},</span>
        <span class="s2">"criterion_episodes"</span><span class="p">:</span> <span class="p">{</span>  <span class="c1"># Number of episodes to consider for stopping criterion</span>
            <span class="s2">"values"</span><span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c1"># Initialize the sweep</span>
<span class="n">sweep_id</span> <span class="o">=</span> <span class="n">wandb</span><span class="o">.</span><span class="n">sweep</span><span class="p">(</span><span class="n">sweep</span><span class="o">=</span><span class="n">sweep_configuration</span><span class="p">,</span> <span class="n">project</span><span class="o">=</span><span class="s1">'PPO-Boxing'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=17cceac5-f264-4251-ab3c-925205cd0f4d">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># 4. Define the PPO Agent</span>
<span class="k">class</span> <span class="nc">PPOAgent</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="c1"># Initialize environment and hyperparameters from wandb config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">env</span> <span class="o">=</span> <span class="n">env</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lam</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">lam</span>  <span class="c1"># GAE lambda</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clip_epsilon</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">clip_epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">entropy_coef</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">entropy_coef</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vf_coef</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">vf_coef</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_grad_norm</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">max_grad_norm</span>

        <span class="c1"># Get action and state dimensions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># 128-length vector</span>

        <span class="c1"># Parse hidden_sizes from string to tuple</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_sizes</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">hidden_sizes</span> <span class="o">=</span> <span class="n">ast</span><span class="o">.</span><span class="n">literal_eval</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_sizes</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">hidden_sizes</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_sizes</span>

        <span class="c1"># Initialize policy and value networks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policynet</span> <span class="o">=</span> <span class="n">PolicyNetwork</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valuenet</span> <span class="o">=</span> <span class="n">ValueNetwork</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dims</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_sizes</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Initialize optimizers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policynet</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_policy</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value_optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">valuenet</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">lr_value</span><span class="p">)</span>

        <span class="c1"># Initialize rollout storage</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">storage</span> <span class="o">=</span> <span class="n">RolloutStorage</span><span class="p">()</span>
<span class="c1">########################################################################################################################################################################################################    </span>
    <span class="k">def</span> <span class="nf">select_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">evaluate</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Add batch dimension and move to device</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policynet</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">evaluate</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">probs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
        <span class="n">log_prob</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="n">entropy</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">entropy</span><span class="p">()</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">valuenet</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">action</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">log_prob</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">entropy</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">value</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="c1">########################################################################################################################################################################################################      </span>
    <span class="k">def</span> <span class="nf">compute_gae</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">dones</span><span class="p">):</span>
        <span class="n">advantages</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">gae</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">values</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># Append 0 for terminal state</span>
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rewards</span><span class="p">))):</span>
            <span class="n">delta</span> <span class="o">=</span> <span class="n">rewards</span><span class="p">[</span><span class="n">step</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">values</span><span class="p">[</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">dones</span><span class="p">[</span><span class="n">step</span><span class="p">])</span> <span class="o">-</span> <span class="n">values</span><span class="p">[</span><span class="n">step</span><span class="p">]</span>
            <span class="n">gae</span> <span class="o">=</span> <span class="n">delta</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">lam</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">dones</span><span class="p">[</span><span class="n">step</span><span class="p">])</span> <span class="o">*</span> <span class="n">gae</span>
            <span class="n">advantages</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">gae</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">advantages</span>
  <span class="c1">########################################################################################################################################################################################################    </span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Convert rollout storage to tensors</span>
        <span class="n">states</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">states</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">actions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">actions</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">old_log_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">log_probs</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">returns</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">returns</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">advantages</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">advantages</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Debugging: Print the sizes of each tensor</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"States size: </span><span class="si">{</span><span class="n">states</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Actions size: </span><span class="si">{</span><span class="n">actions</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Old Log Probs size: </span><span class="si">{</span><span class="n">old_log_probs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Returns size: </span><span class="si">{</span><span class="n">returns</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Advantages size: </span><span class="si">{</span><span class="n">advantages</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="c1"># Normalize advantages</span>
        <span class="n">advantages</span> <span class="o">=</span> <span class="p">(</span><span class="n">advantages</span> <span class="o">-</span> <span class="n">advantages</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">advantages</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>

        <span class="c1"># Prepare dataset for mini-batch updates</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">TensorDataset</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">old_log_probs</span><span class="p">,</span> <span class="n">returns</span><span class="p">,</span> <span class="n">advantages</span><span class="p">)</span>
        <span class="n">loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">policy_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">value_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">entropies</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Perform multiple epochs of updates</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">epochs</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
                <span class="n">b_states</span><span class="p">,</span> <span class="n">b_actions</span><span class="p">,</span> <span class="n">b_old_log_probs</span><span class="p">,</span> <span class="n">b_returns</span><span class="p">,</span> <span class="n">b_advantages</span> <span class="o">=</span> <span class="n">batch</span>

                <span class="c1"># Forward pass through policy network</span>
                <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policynet</span><span class="p">(</span><span class="n">b_states</span><span class="p">)</span>
                <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">)</span>
                <span class="n">new_log_probs</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">b_actions</span><span class="p">)</span>
                <span class="n">entropy</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">entropy</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

                <span class="c1"># Compute ratio for PPO clipping</span>
                <span class="n">ratio</span> <span class="o">=</span> <span class="p">(</span><span class="n">new_log_probs</span> <span class="o">-</span> <span class="n">b_old_log_probs</span><span class="p">)</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>  <span class="c1"># r(theta)</span>
                <span class="n">surr1</span> <span class="o">=</span> <span class="n">ratio</span> <span class="o">*</span> <span class="n">b_advantages</span>  <span class="c1"># r(theta) * A</span>
                <span class="n">surr2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">ratio</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_epsilon</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_epsilon</span><span class="p">)</span> <span class="o">*</span> <span class="n">b_advantages</span>  <span class="c1"># Clipped</span>
                <span class="n">policy_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">surr1</span><span class="p">,</span> <span class="n">surr2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>  <span class="c1"># PPO clipped objective</span>

                <span class="c1"># Compute value loss</span>
                <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">valuenet</span><span class="p">(</span><span class="n">b_states</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">value_loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">b_returns</span><span class="p">)</span>

                <span class="c1"># Total loss</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">policy_loss</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">vf_coef</span> <span class="o">*</span> <span class="n">value_loss</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">entropy_coef</span> <span class="o">*</span> <span class="n">entropy</span>

                <span class="c1"># Backpropagation</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">policy_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">value_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

                <span class="c1"># Gradient clipping</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policynet</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_grad_norm</span><span class="p">)</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">valuenet</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_grad_norm</span><span class="p">)</span>

                <span class="c1"># Update networks</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">policy_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">value_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="c1"># Logging losses</span>
                <span class="n">policy_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">policy_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
                <span class="n">value_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
                <span class="n">entropies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">entropy</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

        <span class="c1"># Clear rollout storage after updates</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>

        <span class="c1"># Log average losses to W&amp;B</span>
        <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">({</span>
            <span class="s1">'Policy Loss'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">policy_losses</span><span class="p">),</span>
            <span class="s1">'Value Loss'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">value_losses</span><span class="p">),</span>
            <span class="s1">'Entropy'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">entropies</span><span class="p">)</span>
        <span class="p">})</span>

        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">policy_losses</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">value_losses</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">entropies</span><span class="p">)</span>
<span class="c1">########################################################################################################################################################################################################      </span>
    <span class="k">def</span> <span class="nf">train_agent</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_episodes</span><span class="p">,</span> <span class="n">rollout_length</span><span class="p">,</span> <span class="n">eval_interval</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">criterion_episodes</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="n">total_rewards</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">moving_average</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">criterion_episodes</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_episodes</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="c1"># Reset environment and get initial state</span>
            <span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>  <span class="c1"># making sure state is a 1D vector of length 128</span>
            <span class="n">episode_reward</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">episode_length</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rollout_length</span><span class="p">):</span>
                <span class="c1"># Select action using current policy</span>
                <span class="n">action</span><span class="p">,</span> <span class="n">log_prob</span><span class="p">,</span> <span class="n">entropy</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_action</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                
                <span class="c1"># Execute action in the environment</span>
                <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
                <span class="n">next_state</span> <span class="o">=</span> <span class="n">next_state</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>  <span class="c1"># Ensure next_state is a 1D vector of length 128</span>

                <span class="c1"># Store experience in rollout</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">log_prob</span><span class="p">,</span> <span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">)</span>

                <span class="c1"># Update state and cumulative reward</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
                <span class="n">episode_reward</span> <span class="o">+=</span> <span class="n">reward</span>
                <span class="n">episode_length</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="c1"># If episode is done, exit the loop</span>
                <span class="k">if</span> <span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">:</span>
                    <span class="k">break</span>

            <span class="c1"># Append the reward for this episode</span>
            <span class="n">total_rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">episode_reward</span><span class="p">)</span>
            <span class="n">moving_average</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">episode_reward</span><span class="p">)</span>

            <span class="c1"># Compute returns and advantages after rollout</span>
            <span class="n">rewards</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">rewards</span><span class="p">)</span>
            <span class="n">values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
            <span class="n">dones</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">dones</span><span class="p">)</span>
            <span class="n">advantages</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_gae</span><span class="p">(</span><span class="n">rewards</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">dones</span><span class="p">)</span>
            <span class="n">returns</span> <span class="o">=</span> <span class="n">advantages</span> <span class="o">+</span> <span class="n">values</span>  <span class="c1"># Element-wise addition using NumPy arrays</span>

            <span class="c1"># Store advantages and returns in rollout storage for updating</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">advantages</span> <span class="o">=</span> <span class="n">advantages</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">returns</span> <span class="o">=</span> <span class="n">returns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

            <span class="c1"># Perform PPO update using collected rollouts</span>
            <span class="n">avg_policy_loss</span><span class="p">,</span> <span class="n">avg_value_loss</span><span class="p">,</span> <span class="n">avg_entropy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>

            <span class="c1"># Log episode reward </span>
            <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">({</span>
                <span class="s1">'Episode'</span><span class="p">:</span> <span class="n">episode</span><span class="p">,</span>
                <span class="s1">'Reward'</span><span class="p">:</span> <span class="n">episode_reward</span><span class="p">,</span>
                <span class="s1">'Episode Length'</span><span class="p">:</span> <span class="n">episode_length</span>
            <span class="p">})</span>

            <span class="c1"># Print progress</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Episode </span><span class="si">{</span><span class="n">episode</span><span class="si">}</span><span class="s2">: Reward = </span><span class="si">{</span><span class="n">episode_reward</span><span class="si">}</span><span class="s2">, Length = </span><span class="si">{</span><span class="n">episode_length</span><span class="si">}</span><span class="s2">, "</span>
                  <span class="sa">f</span><span class="s2">"Policy Loss = </span><span class="si">{</span><span class="n">avg_policy_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Value Loss = </span><span class="si">{</span><span class="n">avg_value_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Entropy = </span><span class="si">{</span><span class="n">avg_entropy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

            <span class="c1"># Check stopping criterion</span>
            <span class="k">if</span> <span class="n">stop_criterion</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">stop_criterion</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">moving_average</span><span class="p">)):</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Stopping criterion satisfied after </span><span class="si">{</span><span class="n">episode</span><span class="si">}</span><span class="s2"> episodes."</span><span class="p">)</span>
                <span class="k">break</span>

            <span class="c1"># Periodic evaluation</span>
            <span class="k">if</span> <span class="n">episode</span> <span class="o">%</span> <span class="n">eval_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">episode_num</span><span class="o">=</span><span class="n">episode</span><span class="p">)</span>


<span class="c1">########################################################################################################################################################################################################      </span>
    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">episode_num</span><span class="p">):</span>
        <span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="n">terminated</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">truncated</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">frames</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">while</span> <span class="ow">not</span> <span class="p">(</span><span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">):</span>
            <span class="c1"># Render environment frame and store for video</span>
            <span class="n">frame</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">()</span> 
            <span class="n">frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>

            <span class="c1"># Select action deterministically</span>
            <span class="n">action</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_action</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">evaluate</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
            <span class="n">next_state</span> <span class="o">=</span> <span class="n">next_state</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

            <span class="c1"># Update state and cumulative reward</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
            <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">reward</span>

        <span class="c1"># Save video of the evaluation episode</span>
        <span class="n">video</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">frames</span><span class="p">)</span>
        <span class="n">video_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"evaluation_episode_</span><span class="si">{</span><span class="n">episode_num</span><span class="si">}</span><span class="s2">.mp4"</span>
        <span class="n">mpy_clip</span> <span class="o">=</span> <span class="n">mpy</span><span class="o">.</span><span class="n">ImageSequenceClip</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">video</span><span class="p">),</span> <span class="n">fps</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
        <span class="n">mpy_clip</span><span class="o">.</span><span class="n">write_videofile</span><span class="p">(</span><span class="n">video_path</span><span class="p">,</span> <span class="n">codec</span><span class="o">=</span><span class="s2">"libx264"</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">logger</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="c1"># Log evaluation results and video to W&amp;B</span>
        <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">({</span>
            <span class="s1">'Evaluation Episode'</span><span class="p">:</span> <span class="n">episode_num</span><span class="p">,</span>
            <span class="s1">'Evaluation Reward'</span><span class="p">:</span> <span class="n">total_reward</span><span class="p">,</span>
            <span class="s1">'Evaluation Video'</span><span class="p">:</span> <span class="n">wandb</span><span class="o">.</span><span class="n">Video</span><span class="p">(</span><span class="n">video_path</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">"mp4"</span><span class="p">)</span>
        <span class="p">})</span>

        <span class="c1"># Logging evaluation result</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Evaluation Episode </span><span class="si">{</span><span class="n">episode_num</span><span class="si">}</span><span class="s2">: Total Reward = </span><span class="si">{</span><span class="n">total_reward</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1">########################################################################################################################################################################################################      </span>
    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="c1"># Save network weights to a file</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
            <span class="s1">'policy_net'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">policynet</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'value_net'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">valuenet</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
        <span class="p">},</span> <span class="n">path</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Model saved to </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="c1">########################################################################################################################################################################################################      </span>
    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="c1"># Load network weights from a file</span>
        <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policynet</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'policy_net'</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valuenet</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'value_net'</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Model loaded from </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=1cdc7370-9f25-4343-96bf-2b7c383394bc">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=47ecc116-9c67-49b0-8a26-330c94d8b19c">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sweep_agent</span><span class="p">():</span>
    <span class="c1"># Initialize a new wandb run</span>
    <span class="k">with</span> <span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">()</span> <span class="k">as</span> <span class="n">run</span><span class="p">:</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">wandb</span><span class="o">.</span><span class="n">config</span>

        <span class="c1"># Create the environment with RAM observation type</span>
        <span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">'ALE/Boxing-v5'</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">"rgb_array"</span><span class="p">,</span> <span class="n">obs_type</span><span class="o">=</span><span class="s2">"ram"</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"Observation Space Shape:"</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        
        <span class="c1"># Ensure the observation is a 128-length vector</span>
        <span class="k">assert</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">128</span><span class="p">,),</span> <span class="s2">"Observation space must be a 128-length vector."</span>

        <span class="c1"># Initialise PPOAgent with current wandb config</span>
        <span class="n">agent</span> <span class="o">=</span> <span class="n">PPOAgent</span><span class="p">(</span><span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>

        <span class="c1"># Define stopping criterion</span>
        <span class="k">def</span> <span class="nf">stopping_criterion</span><span class="p">(</span><span class="n">rewards</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rewards</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">100</span> 

        <span class="c1"># Start training</span>
        <span class="n">agent</span><span class="o">.</span><span class="n">train_agent</span><span class="p">(</span>
            <span class="n">max_episodes</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">num_episodes</span><span class="p">,</span>
            <span class="n">rollout_length</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">rollout_length</span><span class="p">,</span>
            <span class="n">eval_interval</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">eval_interval</span><span class="p">,</span>
            <span class="n">stop_criterion</span><span class="o">=</span><span class="n">stopping_criterion</span><span class="p">,</span>
            <span class="n">criterion_episodes</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">criterion_episodes</span>
        <span class="p">)</span>

        <span class="c1"># Close the environment after training</span>
        <span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="c1"># 6. Launch the Sweep</span>
<span class="n">wandb</span><span class="o">.</span><span class="n">agent</span><span class="p">(</span><span class="n">sweep_id</span><span class="p">,</span> <span class="n">function</span><span class="o">=</span><span class="n">sweep_agent</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=133c7f82-9f5d-4277-b068-530f9cd8f35d">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">wandb</span>  tristancarlisle/PPO-Boxing/sweeps/crve6wfu
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0">
<iframe src="https://wandb.ai/tristancarlisle/PPO-Boxing/sweeps/crve6wfu?jupyter=true" style="border:none;width:100%;height:420px;"></iframe>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=609a549d-c72b-4619-a61b-7357705f292c">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div>
</main>
</body>
<script type="application/vnd.jupyter.widget-state+json">
{"state": {}, "version_major": 2, "version_minor": 0}
</script>
</html>
